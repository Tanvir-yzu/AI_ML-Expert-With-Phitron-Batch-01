{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##1.1 Lab 1: Singleton Pattern Implementation\n",
        "Objective: Understand and implement the Singleton design pattern with thread safety.\n",
        "Problem Statement: Create a thread-sa"
      ],
      "metadata": {
        "id": "dM01TZP0t1fS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QjdW3I3trLV",
        "outputId": "59df0beb-fa3e-4697-a5dc-b5241e5071a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0: Instance ID - 139009787526272\n",
            "Current Configuration:\n",
            "database_url: localhost:5432\n",
            "api_key: default_key\n",
            "max_connections: 10\n",
            "debug_mode: True\n",
            "thread_0_access: True\n",
            "----------------------------------------\n",
            "Thread 1: Instance ID - 139009787526272\n",
            "Current Configuration:\n",
            "database_url: localhost:5432\n",
            "api_key: default_key\n",
            "max_connections: 10\n",
            "debug_mode: True\n",
            "thread_0_access: True\n",
            "thread_1_access: True\n",
            "----------------------------------------\n",
            "Thread 2: Instance ID - 139009787526272\n",
            "Current Configuration:\n",
            "database_url: localhost:5432\n",
            "api_key: default_key\n",
            "max_connections: 10\n",
            "debug_mode: True\n",
            "thread_0_access: True\n",
            "thread_1_access: True\n",
            "thread_2_access: True\n",
            "----------------------------------------\n",
            "All threads completed. Final config from main:\n",
            "Current Configuration:\n",
            "database_url: localhost:5432\n",
            "api_key: default_key\n",
            "max_connections: 10\n",
            "debug_mode: True\n",
            "thread_0_access: True\n",
            "thread_1_access: True\n",
            "thread_2_access: True\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "class ConfigurationManager:\n",
        "    _instance = None\n",
        "    _lock = threading.Lock()\n",
        "\n",
        "    def __new__(cls):\n",
        "        with cls._lock:\n",
        "            if cls._instance is None:\n",
        "                cls._instance = super(ConfigurationManager, cls).__new__(cls)\n",
        "                cls._instance._initialized = False  # Flag to prevent re-init\n",
        "            return cls._instance\n",
        "\n",
        "    def __init__(self):\n",
        "        # Only initialize once\n",
        "        if not hasattr(self, '_initialized') or not self._initialized:\n",
        "            with type(self)._lock:\n",
        "                if not hasattr(self, '_initialized') or not self._initialized:\n",
        "                    self._initialize()\n",
        "                    self._initialized = True\n",
        "\n",
        "    def _initialize(self):\n",
        "        self._config: Dict[str, Any] = {\n",
        "            \"database_url\": \"localhost:5432\",\n",
        "            \"api_key\": \"default_key\",\n",
        "            \"max_connections\": 10,\n",
        "            \"debug_mode\": True\n",
        "        }\n",
        "\n",
        "    def get(self, key: str) -> Any:\n",
        "        return self._config.get(key)\n",
        "\n",
        "    def set(self, key: str, value: Any):\n",
        "        with self._lock:\n",
        "            self._config[key] = value\n",
        "\n",
        "    def display_config(self):\n",
        "        print(\"Current Configuration:\")\n",
        "        for key, value in self._config.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "\n",
        "# Test the Singleton Pattern\n",
        "def test_singleton(thread_id):\n",
        "    config = ConfigurationManager()\n",
        "    config.set(f\"thread_{thread_id}_access\", True)\n",
        "    print(f\"Thread {thread_id}: Instance ID - {id(config)}\")\n",
        "    config.display_config()\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "\n",
        "# Multi-threading test\n",
        "if __name__ == \"__main__\":\n",
        "    threads = []\n",
        "    for i in range(3):\n",
        "        thread = threading.Thread(target=test_singleton, args=(i,))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    # Wait for all threads to complete\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "    print(\"All threads completed. Final config from main:\")\n",
        "    ConfigurationManager().display_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 2: Factory Method Pattern\n",
        "Objective: Implement Factory Method pattern for creating different types of database connections.\n",
        "Problem Statement: Create a factory that can generate MySQL, PostgreSQL, and SQLite database\n",
        "connections based on configuration.\n"
      ],
      "metadata": {
        "id": "8WP-36eXu6zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python psycopg2-binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwUbOobhvxNP",
        "outputId": "91a0d3f4-b814-4b03-ec5b-311e9c9746be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.5.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
            "Downloading mysql_connector_python-9.5.0-cp312-cp312-manylinux_2_28_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary, mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.5.0 psycopg2-binary-2.9.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import sqlite3\n",
        "import mysql.connector\n",
        "import psycopg2\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "class DatabaseConnection(ABC):\n",
        "    @abstractmethod\n",
        "    def connect(self):\n",
        "        \"\"\"Establish connection to the database.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def execute_query(self, query: str):\n",
        "        \"\"\"Execute a query and return results.\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def close(self):\n",
        "        \"\"\"Close the database connection.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class MySQLConnection(DatabaseConnection):\n",
        "    def __init__(self, host: str, user: str, password: str, database: str):\n",
        "        self.host = host\n",
        "        self.user = user\n",
        "        self.password = password\n",
        "        self.database = database\n",
        "        self.connection = None\n",
        "\n",
        "    def connect(self):\n",
        "        if self.connection is None:\n",
        "            self.connection = mysql.connector.connect(\n",
        "                host=self.host,\n",
        "                user=self.user,\n",
        "                password=self.password,\n",
        "                database=self.database\n",
        "            )\n",
        "        return self.connection\n",
        "\n",
        "    def execute_query(self, query: str):\n",
        "        if self.connection is None:\n",
        "            self.connect()\n",
        "        cursor = self.connection.cursor()\n",
        "        cursor.execute(query)\n",
        "        return cursor.fetchall()\n",
        "\n",
        "    def close(self):\n",
        "        if self.connection and self.connection.is_connected():\n",
        "            self.connection.close()\n",
        "            self.connection = None\n",
        "\n",
        "\n",
        "class PostgreSQLConnection(DatabaseConnection):\n",
        "    def __init__(self, host: str, user: str, password: str, database: str):\n",
        "        self.host = host\n",
        "        self.user = user\n",
        "        self.password = password\n",
        "        self.database = database\n",
        "        self.connection = None\n",
        "\n",
        "    def connect(self):\n",
        "        if self.connection is None:\n",
        "            self.connection = psycopg2.connect(\n",
        "                host=self.host,\n",
        "                user=self.user,\n",
        "                password=self.password,\n",
        "                database=self.database\n",
        "            )\n",
        "        return self.connection\n",
        "\n",
        "    def execute_query(self, query: str):\n",
        "        if self.connection is None:\n",
        "            self.connect()\n",
        "        cursor = self.connection.cursor()\n",
        "        cursor.execute(query)\n",
        "        return cursor.fetchall()\n",
        "\n",
        "    def close(self):\n",
        "        if self.connection:\n",
        "            self.connection.close()\n",
        "            self.connection = None\n",
        "\n",
        "\n",
        "class SQLiteConnection(DatabaseConnection):\n",
        "    def __init__(self, db_path: str):\n",
        "        self.db_path = db_path\n",
        "        self.connection = None\n",
        "\n",
        "    def connect(self):\n",
        "        if self.connection is None:\n",
        "            self.connection = sqlite3.connect(self.db_path)\n",
        "        return self.connection\n",
        "\n",
        "    def execute_query(self, query: str):\n",
        "        if self.connection is None:\n",
        "            self.connect()\n",
        "        cursor = self.connection.cursor()\n",
        "        cursor.execute(query)\n",
        "        return cursor.fetchall()\n",
        "\n",
        "    def close(self):\n",
        "        if self.connection:\n",
        "            self.connection.close()\n",
        "            self.connection = None\n",
        "\n",
        "\n",
        "class DatabaseFactory:\n",
        "    @staticmethod\n",
        "    def create_connection(db_type: str, **kwargs) -> DatabaseConnection:\n",
        "        db_type = db_type.lower().strip()\n",
        "\n",
        "        if db_type == \"mysql\":\n",
        "            return MySQLConnection(\n",
        "                host=kwargs.get('host', 'localhost'),\n",
        "                user=kwargs.get('user', 'root'),\n",
        "                password=kwargs.get('password', ''),\n",
        "                database=kwargs.get('database', 'test')\n",
        "            )\n",
        "        elif db_type == \"postgresql\":\n",
        "            return PostgreSQLConnection(\n",
        "                host=kwargs.get('host', 'localhost'),\n",
        "                user=kwargs.get('user', 'postgres'),\n",
        "                password=kwargs.get('password', ''),\n",
        "                database=kwargs.get('database', 'test')\n",
        "            )\n",
        "        elif db_type == \"sqlite\":\n",
        "            return SQLiteConnection(\n",
        "                db_path=kwargs.get('db_path', ':memory:')\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported database type: {db_type}\")\n",
        "\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    # Create MySQL connection\n",
        "    mysql_db = DatabaseFactory.create_connection(\n",
        "        \"mysql\",\n",
        "        host=\"localhost\",\n",
        "        user=\"root\",\n",
        "        password=\"password\",\n",
        "        database=\"test_db\"\n",
        "    )\n",
        "\n",
        "    # Create SQLite in-memory connection\n",
        "    sqlite_db = DatabaseFactory.create_connection(\"sqlite\", db_path=\":memory:\")\n",
        "\n",
        "    # Print connection types\n",
        "    print(f\"MySQL Connection: {type(mysql_db).__name__}\")\n",
        "    print(f\"SQLite Connection: {type(sqlite_db).__name__}\")\n",
        "\n",
        "    # Example usage (uncomment to test queries)\n",
        "    \"\"\"\n",
        "    mysql_db.connect()\n",
        "    # result = mysql_db.execute_query(\"SELECT VERSION()\")\n",
        "    # print(\"MySQL Version:\", result)\n",
        "\n",
        "    sqlite_db.connect()\n",
        "    sqlite_db.execute_query(\"CREATE TABLE IF NOT EXISTS test (id INTEGER)\")\n",
        "    sqlite_db.execute_query(\"INSERT INTO test (id) VALUES (1)\")\n",
        "    result = sqlite_db.execute_query(\"SELECT * FROM test\")\n",
        "    print(\"SQLite Result:\", result)\n",
        "\n",
        "    mysql_db.close()\n",
        "    sqlite_db.close()\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZCcE4UDvbnz",
        "outputId": "717b7dc9-3f40-4f9a-fceb-2325c8194607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MySQL Connection: MySQLConnection\n",
            "SQLite Connection: SQLiteConnection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 3: Observer Pattern\n",
        "Objective: Implement Observer pattern for event notification system.\n",
        "Problem Statement: Create a stock market system where multiple displays observe price changes.\n"
      ],
      "metadata": {
        "id": "z6uz4qTKwBN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "# === Observer Interface ===\n",
        "class Observer(ABC):\n",
        "    @abstractmethod\n",
        "    def update(self, stock_name: str, price: float):\n",
        "        pass\n",
        "\n",
        "\n",
        "# === Subject Interface ===\n",
        "class Subject(ABC):\n",
        "    @abstractmethod\n",
        "    def register_observer(self, observer: Observer):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def remove_observer(self, observer: Observer):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def notify_observers(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "# === Concrete Subject: StockMarket ===\n",
        "class StockMarket(Subject):\n",
        "    def __init__(self):\n",
        "        self._observers: List[Observer] = []\n",
        "        self._stock_prices: Dict[str, float] = {}\n",
        "\n",
        "    def register_observer(self, observer: Observer):\n",
        "        if observer not in self._observers:\n",
        "            self._observers.append(observer)\n",
        "\n",
        "    def remove_observer(self, observer: Observer):\n",
        "        if observer in self._observers:\n",
        "            self._observers.remove(observer)\n",
        "\n",
        "    def notify_observers(self):\n",
        "        for observer in self._observers:\n",
        "            for stock, price in self._stock_prices.items():\n",
        "                observer.update(stock, price)\n",
        "\n",
        "    def set_stock_price(self, stock_name: str, price: float):\n",
        "        was_updated = stock_name not in self._stock_prices or self._stock_prices[stock_name] != price\n",
        "        self._stock_prices[stock_name] = price\n",
        "        if was_updated:\n",
        "            self.notify_observers()  # Only notify if price changed\n",
        "\n",
        "    def get_stock_price(self, stock_name: str) -> float:\n",
        "        return self._stock_prices.get(stock_name, 0.0)\n",
        "\n",
        "\n",
        "# === Concrete Observer 1: Desktop Display ===\n",
        "class StockDisplay(Observer):\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name.strip()\n",
        "        self.displayed_stocks: Dict[str, float] = {}\n",
        "\n",
        "    def update(self, stock_name: str, price: float):\n",
        "        self.displayed_stocks[stock_name] = price\n",
        "        self.display()\n",
        "\n",
        "    def display(self):\n",
        "        print(f\"\\n{self.name} Display:\")\n",
        "        if not self.displayed_stocks:\n",
        "            print(\"  No stocks to display.\")\n",
        "        else:\n",
        "            for stock, price in self.displayed_stocks.items():\n",
        "                print(f\"  {stock}: ${price:.2f}\")\n",
        "\n",
        "\n",
        "# === Concrete Observer 2: Mobile App ===\n",
        "class MobileApp(Observer):\n",
        "    def __init__(self, app_name: str):\n",
        "        self.app_name = app_name.strip()\n",
        "        self.notifications: List[str] = []\n",
        "\n",
        "    def update(self, stock_name: str, price: float):\n",
        "        notification = f\"Stock {stock_name} updated to ${price:.2f}\"\n",
        "        self.notifications.append(notification)\n",
        "        print(f\"[{self.app_name}] {notification}\")\n",
        "\n",
        "\n",
        "# === Test the Observer Pattern ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Create stock market\n",
        "    market = StockMarket()\n",
        "\n",
        "    # Create observers\n",
        "    desktop_display = StockDisplay(\"Desktop\")\n",
        "    mobile_app = MobileApp(\"StockTracker Mobile\")\n",
        "\n",
        "    # Register observers\n",
        "    market.register_observer(desktop_display)\n",
        "    market.register_observer(mobile_app)\n",
        "\n",
        "    # Update stock prices\n",
        "    print(\"=== Stock Market Updates ===\")\n",
        "    market.set_stock_price(\"AAPL\", 150.25)\n",
        "    market.set_stock_price(\"GOOGL\", 2750.80)\n",
        "    market.set_stock_price(\"TSLA\", 850.75)\n",
        "\n",
        "    # Remove one observer and update again\n",
        "    market.remove_observer(mobile_app)\n",
        "    print(\"\\n=== After removing mobile app ===\")\n",
        "    market.set_stock_price(\"MSFT\", 305.60)\n",
        "\n",
        "    # Optional: Show final desktop state\n",
        "    print(\"\\n=== Final Desktop View ===\")\n",
        "    desktop_display.display()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytXWptulwxxp",
        "outputId": "0755f58d-7fc4-44cb-e78e-e45248b8bdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Stock Market Updates ===\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "[StockTracker Mobile] Stock AAPL updated to $150.25\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "[StockTracker Mobile] Stock AAPL updated to $150.25\n",
            "[StockTracker Mobile] Stock GOOGL updated to $2750.80\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "  TSLA: $850.75\n",
            "[StockTracker Mobile] Stock AAPL updated to $150.25\n",
            "[StockTracker Mobile] Stock GOOGL updated to $2750.80\n",
            "[StockTracker Mobile] Stock TSLA updated to $850.75\n",
            "\n",
            "=== After removing mobile app ===\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "  TSLA: $850.75\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "  TSLA: $850.75\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "  TSLA: $850.75\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "  TSLA: $850.75\n",
            "  MSFT: $305.60\n",
            "\n",
            "=== Final Desktop View ===\n",
            "\n",
            "Desktop Display:\n",
            "  AAPL: $150.25\n",
            "  GOOGL: $2750.80\n",
            "  TSLA: $850.75\n",
            "  MSFT: $305.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 4: MVC Architecture\n",
        "Objective: Implement Model-View-Controller pattern for a user management system.\n",
        "Problem Statement: Create a simple user management system following MVC principles.\n"
      ],
      "metadata": {
        "id": "5X3D2xkdw7oG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "\n",
        "# ================= MODEL =================\n",
        "class UserModel:\n",
        "    def __init__(self):\n",
        "        self._users: List[Dict[str, Any]] = []\n",
        "        self._observers: List[Any] = []\n",
        "\n",
        "    def add_observer(self, observer):\n",
        "        if observer not in self._observers:\n",
        "            self._observers.append(observer)\n",
        "\n",
        "    def notify_observers(self):\n",
        "        for observer in self._observers:\n",
        "            observer.update()\n",
        "\n",
        "    def add_user(self, user_data: Dict[str, str]):\n",
        "        user_id = len(self._users) + 1\n",
        "        user_data['id'] = user_id\n",
        "        self._users.append(user_data.copy())\n",
        "        self.notify_observers()\n",
        "\n",
        "    def get_users(self) -> List[Dict[str, Any]]:\n",
        "        return [user.copy() for user in self._users]\n",
        "\n",
        "    def get_user(self, user_id: int) -> Optional[Dict[str, Any]]:\n",
        "        for user in self._users:\n",
        "            if user['id'] == user_id:\n",
        "                return user.copy()\n",
        "        return None\n",
        "\n",
        "    def update_user(self, user_id: int, user_data: Dict[str, str]) -> bool:\n",
        "        for i, user in enumerate(self._users):\n",
        "            if user['id'] == user_id:\n",
        "                self._users[i].update(user_data)\n",
        "                self.notify_observers()\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def delete_user(self, user_id: int) -> bool:\n",
        "        initial_len = len(self._users)\n",
        "        self._users = [user for user in self._users if user['id'] != user_id]\n",
        "        if len(self._users) < initial_len:\n",
        "            self.notify_observers()\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "# ================= VIEW =================\n",
        "class UserView:\n",
        "    def display_users(self, users: List[Dict[str, Any]]):\n",
        "        print(\"\\n=== User List ===\")\n",
        "        if not users:\n",
        "            print(\"  No users found.\")\n",
        "        else:\n",
        "            for user in users:\n",
        "                print(f\"  ID: {user['id']}, Name: {user['name']}, Email: {user['email']}\")\n",
        "        print(\"=================\\n\")\n",
        "\n",
        "    def display_user(self, user: Optional[Dict[str, Any]]):\n",
        "        if user:\n",
        "            print(f\"\\n=== User Details ===\")\n",
        "            print(f\"  ID: {user['id']}\")\n",
        "            print(f\"  Name: {user['name']}\")\n",
        "            print(f\"  Email: {user['email']}\")\n",
        "            print(\"===================\\n\")\n",
        "        else:\n",
        "            print(\"  User not found!\\n\")\n",
        "\n",
        "    def get_user_input(self) -> Dict[str, str]:\n",
        "        name = input(\"Enter user name: \").strip()\n",
        "        email = input(\"Enter user email: \").strip()\n",
        "        return {'name': name, 'email': email}\n",
        "\n",
        "    def show_message(self, message: str):\n",
        "        print(f\"Info: {message}\")\n",
        "\n",
        "\n",
        "# ================= CONTROLLER =================\n",
        "class UserController:\n",
        "    def __init__(self, model: UserModel, view: UserView):\n",
        "        self.model = model\n",
        "        self.view = view\n",
        "        self.model.add_observer(self)  # Controller observes Model\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"Called when model changes — refresh view\"\"\"\n",
        "        users = self.model.get_users()\n",
        "        self.view.display_users(users)\n",
        "\n",
        "    def add_user(self):\n",
        "        user_data = self.view.get_user_input()\n",
        "        self.model.add_user(user_data)\n",
        "        self.view.show_message(\"User added successfully!\")\n",
        "\n",
        "    def show_users(self):\n",
        "        users = self.model.get_users()\n",
        "        self.view.display_users(users)\n",
        "\n",
        "    def show_user(self, user_id: int):\n",
        "        user = self.model.get_user(user_id)\n",
        "        self.view.display_user(user)\n",
        "\n",
        "    def update_user(self, user_id: int):\n",
        "        user = self.model.get_user(user_id)\n",
        "        if user:\n",
        "            self.view.show_message(f\"Updating user {user['name']}\")\n",
        "            new_data = self.view.get_user_input()\n",
        "            self.model.update_user(user_id, new_data)\n",
        "            self.view.show_message(\"User updated successfully!\")\n",
        "        else:\n",
        "            self.view.show_message(\"User not found!\")\n",
        "\n",
        "    def delete_user(self, user_id: int):\n",
        "        if self.model.delete_user(user_id):\n",
        "            self.view.show_message(\"User deleted successfully!\")\n",
        "        else:\n",
        "            self.view.show_message(\"User not found!\")\n",
        "\n",
        "\n",
        "# ================= DEMO =================\n",
        "if __name__ == \"__main__\":\n",
        "    model = UserModel()\n",
        "    view = UserView()\n",
        "    controller = UserController(model, view)\n",
        "\n",
        "    print(\"=== MVC User Management System ===\\n\")\n",
        "\n",
        "    # Add users interactively\n",
        "    print(\"Add first user:\")\n",
        "    controller.add_user()\n",
        "\n",
        "    print(\"\\nAdd second user:\")\n",
        "    controller.add_user()\n",
        "\n",
        "    # Show all users\n",
        "    controller.show_users()\n",
        "\n",
        "    # Show specific user\n",
        "    controller.show_user(1)\n",
        "\n",
        "    # Update user\n",
        "    print(\"Update user ID 1:\")\n",
        "    controller.update_user(1)\n",
        "\n",
        "    # Delete user\n",
        "    print(\"Delete user ID 2:\")\n",
        "    controller.delete_user(2)\n",
        "\n",
        "    # Final state\n",
        "    print(\"Final user list:\")\n",
        "    controller.show_users()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1rF4YUhxN00",
        "outputId": "c259a0a8-a587-413f-b824-c9f507d6902a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MVC User Management System ===\n",
            "\n",
            "Add first user:\n",
            "Enter user name: Tanvir\n",
            "Enter user email: 2020tanvir1971@gmail.com\n",
            "\n",
            "=== User List ===\n",
            "  ID: 1, Name: Tanvir, Email: 2020tanvir1971@gmail.com\n",
            "=================\n",
            "\n",
            "Info: User added successfully!\n",
            "\n",
            "Add second user:\n",
            "Enter user name: roman\n",
            "Enter user email: roman@gmail.com\n",
            "\n",
            "=== User List ===\n",
            "  ID: 1, Name: Tanvir, Email: 2020tanvir1971@gmail.com\n",
            "  ID: 2, Name: roman, Email: roman@gmail.com\n",
            "=================\n",
            "\n",
            "Info: User added successfully!\n",
            "\n",
            "=== User List ===\n",
            "  ID: 1, Name: Tanvir, Email: 2020tanvir1971@gmail.com\n",
            "  ID: 2, Name: roman, Email: roman@gmail.com\n",
            "=================\n",
            "\n",
            "\n",
            "=== User Details ===\n",
            "  ID: 1\n",
            "  Name: Tanvir\n",
            "  Email: 2020tanvir1971@gmail.com\n",
            "===================\n",
            "\n",
            "Update user ID 1:\n",
            "Info: Updating user Tanvir\n",
            "Enter user name: Tanvir\n",
            "Enter user email: 2020tanvir1971@gmail.com\n",
            "\n",
            "=== User List ===\n",
            "  ID: 1, Name: Tanvir, Email: 2020tanvir1971@gmail.com\n",
            "  ID: 2, Name: roman, Email: roman@gmail.com\n",
            "=================\n",
            "\n",
            "Info: User updated successfully!\n",
            "Delete user ID 2:\n",
            "\n",
            "=== User List ===\n",
            "  ID: 1, Name: Tanvir, Email: 2020tanvir1971@gmail.com\n",
            "=================\n",
            "\n",
            "Info: User deleted successfully!\n",
            "Final user list:\n",
            "\n",
            "=== User List ===\n",
            "  ID: 1, Name: Tanvir, Email: 2020tanvir1971@gmail.com\n",
            "=================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 5: Layered Architecture\n",
        "Objective: Implement a 3-tier layered architecture for a library management system.\n",
        "Problem Statement: Create a library system with presentation, business logic, and data access layers."
      ],
      "metadata": {
        "id": "U-yhQrrFxo9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "\n",
        "# ================= DATA ACCESS LAYER =================\n",
        "class BookRepository:\n",
        "    def __init__(self):\n",
        "        self._books: List[Dict[str, Any]] = [\n",
        "            {'id': 1, 'title': 'Python Programming', 'author': 'John Doe', 'available': True},\n",
        "            {'id': 2, 'title': 'Software Architecture', 'author': 'Jane Smith', 'available': True},\n",
        "            {'id': 3, 'title': 'Design Patterns', 'author': 'Bob Johnson', 'available': False}\n",
        "        ]\n",
        "\n",
        "    def get_all_books(self) -> List[Dict[str, Any]]:\n",
        "        return [book.copy() for book in self._books]\n",
        "\n",
        "    def get_book_by_id(self, book_id: int) -> Optional[Dict[str, Any]]:\n",
        "        for book in self._books:\n",
        "            if book['id'] == book_id:\n",
        "                return book.copy()\n",
        "        return None\n",
        "\n",
        "    def get_available_books(self) -> List[Dict[str, Any]]:\n",
        "        return [book.copy() for book in self._books if book['available']]\n",
        "\n",
        "    def borrow_book(self, book_id: int) -> bool:\n",
        "        for book in self._books:\n",
        "            if book['id'] == book_id and book['available']:\n",
        "                book['available'] = False\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def return_book(self, book_id: int) -> bool:\n",
        "        for book in self._books:\n",
        "            if book['id'] == book_id and not book['available']:\n",
        "                book['available'] = True\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "\n",
        "# ================= BUSINESS LOGIC LAYER =================\n",
        "class LibraryService:\n",
        "    def __init__(self):\n",
        "        self.book_repo = BookRepository()\n",
        "\n",
        "    def display_all_books(self) -> List[Dict[str, Any]]:\n",
        "        return self.book_repo.get_all_books()\n",
        "\n",
        "    def display_available_books(self) -> List[Dict[str, Any]]:\n",
        "        return self.book_repo.get_available_books()\n",
        "\n",
        "    def borrow_book(self, book_id: int) -> Tuple[bool, str]:\n",
        "        book = self.book_repo.get_book_by_id(book_id)\n",
        "        if not book:\n",
        "            return False, \"Book not found.\"\n",
        "\n",
        "        if not book['available']:\n",
        "            return False, \"Book is already borrowed.\"\n",
        "\n",
        "        if self.book_repo.borrow_book(book_id):\n",
        "            return True, f\"Successfully borrowed '{book['title']}'.\"\n",
        "        else:\n",
        "            return False, \"Failed to borrow book.\"\n",
        "\n",
        "    def return_book(self, book_id: int) -> Tuple[bool, str]:\n",
        "        book = self.book_repo.get_book_by_id(book_id)\n",
        "        if not book:\n",
        "            return False, \"Book not found.\"\n",
        "\n",
        "        if book['available']:\n",
        "            return False, \"Book is already available.\"\n",
        "\n",
        "        if self.book_repo.return_book(book_id):\n",
        "            return True, f\"Successfully returned '{book['title']}'.\"\n",
        "        else:\n",
        "            return False, \"Failed to return book.\"\n",
        "\n",
        "\n",
        "# ================= PRESENTATION LAYER =================\n",
        "class LibraryUI:\n",
        "    def __init__(self):\n",
        "        self.library_service = LibraryService()\n",
        "\n",
        "    def display_menu(self):\n",
        "        print(\"\\n=== Library Management System ===\")\n",
        "        print(\"1. View all books\")\n",
        "        print(\"2. View available books\")\n",
        "        print(\"3. Borrow a book\")\n",
        "        print(\"4. Return a book\")\n",
        "        print(\"5. Exit\")\n",
        "\n",
        "    def display_books(self, books: List[Dict[str, Any]]):\n",
        "        if not books:\n",
        "            print(\"\\nNo books found.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n=== Book List ===\")\n",
        "        for book in books:\n",
        "            status = \"Available\" if book['available'] else \"Borrowed\"\n",
        "            print(f\"  ID: {book['id']}, Title: {book['title']}, \"\n",
        "                  f\"Author: {book['author']}, Status: {status}\")\n",
        "        print()\n",
        "\n",
        "    def run(self):\n",
        "        while True:\n",
        "            self.display_menu()\n",
        "            choice = input(\"Enter your choice (1-5): \").strip()\n",
        "\n",
        "            if choice == '1':\n",
        "                books = self.library_service.display_all_books()\n",
        "                self.display_books(books)\n",
        "\n",
        "            elif choice == '2':\n",
        "                books = self.library_service.display_available_books()\n",
        "                self.display_books(books)\n",
        "\n",
        "            elif choice == '3':\n",
        "                try:\n",
        "                    book_id = int(input(\"Enter book ID to borrow: \").strip())\n",
        "                    success, message = self.library_service.borrow_book(book_id)\n",
        "                    print(f\"→ {message}\")\n",
        "                except ValueError:\n",
        "                    print(\"Invalid ID. Please enter a number.\")\n",
        "\n",
        "            elif choice == '4':\n",
        "                try:\n",
        "                    book_id = int(input(\"Enter book ID to return: \").strip())\n",
        "                    success, message = self.library_service.return_book(book_id)\n",
        "                    print(f\"→ {message}\")\n",
        "                except ValueError:\n",
        "                    print(\"Invalid ID. Please enter a number.\")\n",
        "\n",
        "            elif choice == '5':\n",
        "                print(\"Thank you for using the Library Management System!\")\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "\n",
        "# ================= RUN APPLICATION =================\n",
        "if __name__ == \"__main__\":\n",
        "    ui = LibraryUI()\n",
        "    ui.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBWGr_I2x_UG",
        "outputId": "57b287e2-0f65-481b-8679-f2b088ba1fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Library Management System ===\n",
            "1. View all books\n",
            "2. View available books\n",
            "3. Borrow a book\n",
            "4. Return a book\n",
            "5. Exit\n",
            "Enter your choice (1-5): 3\n",
            "Enter book ID to borrow: 10\n",
            "→ Book not found.\n",
            "\n",
            "=== Library Management System ===\n",
            "1. View all books\n",
            "2. View available books\n",
            "3. Borrow a book\n",
            "4. Return a book\n",
            "5. Exit\n",
            "Enter your choice (1-5): 3\n",
            "Enter book ID to borrow: 1\n",
            "→ Successfully borrowed 'Python Programming'.\n",
            "\n",
            "=== Library Management System ===\n",
            "1. View all books\n",
            "2. View available books\n",
            "3. Borrow a book\n",
            "4. Return a book\n",
            "5. Exit\n",
            "Enter your choice (1-5): 5\n",
            "Thank you for using the Library Management System!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 6: Microservices Communication\n",
        "Objective: Implement inter-service communication in a microservices architecture.\n",
        "Problem Statement: Create user and order services that communicate via REST API"
      ],
      "metadata": {
        "id": "bKa76pU5yQse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, request\n",
        "import requests\n",
        "import threading\n",
        "import time\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "# ================= USER SERVICE =================\n",
        "class UserService:\n",
        "    def __init__(self, port: int = 5001):\n",
        "        self.app = Flask(__name__)\n",
        "        self.port = port\n",
        "        self.users: Dict[int, Dict[str, Any]] = {\n",
        "            1: {'id': 1, 'name': 'John Doe', 'email': 'john@example.com'},\n",
        "            2: {'id': 2, 'name': 'Jane Smith', 'email': 'jane@example.com'}\n",
        "        }\n",
        "        self.setup_routes()\n",
        "\n",
        "    def setup_routes(self):\n",
        "        @self.app.route('/users', methods=['GET'])\n",
        "        def get_users():\n",
        "            return jsonify(list(self.users.values()))\n",
        "\n",
        "        @self.app.route('/users/<int:user_id>', methods=['GET'])\n",
        "        def get_user(user_id):\n",
        "            user = self.users.get(user_id)\n",
        "            if user:\n",
        "                return jsonify(user)\n",
        "            return jsonify({'error': 'User not found'}), 404\n",
        "\n",
        "        @self.app.route('/users', methods=['POST'])\n",
        "        def create_user():\n",
        "            data = request.get_json()\n",
        "            if not data or 'name' not in data or 'email' not in data:\n",
        "                return jsonify({'error': 'Name and email required'}), 400\n",
        "\n",
        "            user_id = max(self.users.keys()) + 1\n",
        "            user = {\n",
        "                'id': user_id,\n",
        "                'name': data['name'],\n",
        "                'email': data['email']\n",
        "            }\n",
        "            self.users[user_id] = user\n",
        "            return jsonify(user), 201\n",
        "\n",
        "    def run(self):\n",
        "        self.app.run(port=self.port, debug=False, use_reloader=False)\n",
        "\n",
        "\n",
        "# ================= ORDER SERVICE =================\n",
        "class OrderService:\n",
        "    def __init__(self, port: int = 5002, user_service_url: str = 'http://localhost:5001'):\n",
        "        self.app = Flask(__name__)\n",
        "        self.port = port\n",
        "        self.user_service_url = user_service_url\n",
        "        self.orders: Dict[int, Dict[str, Any]] = {\n",
        "            1: {'id': 1, 'user_id': 1, 'product': 'Laptop', 'amount': 999.99},\n",
        "            2: {'id': 2, 'user_id': 2, 'product': 'Mouse', 'amount': 29.99}\n",
        "        }\n",
        "        self.setup_routes()\n",
        "\n",
        "    def setup_routes(self):\n",
        "        @self.app.route('/orders', methods=['GET'])\n",
        "        def get_orders():\n",
        "            return jsonify(list(self.orders.values()))\n",
        "\n",
        "        @self.app.route('/orders/<int:order_id>', methods=['GET'])\n",
        "        def get_order(order_id):\n",
        "            order = self.orders.get(order_id)\n",
        "            if not order:\n",
        "                return jsonify({'error': 'Order not found'}), 404\n",
        "\n",
        "            # Enrich order with user data\n",
        "            try:\n",
        "                user_response = requests.get(\n",
        "                    f\"{self.user_service_url}/users/{order['user_id']}\",\n",
        "                    timeout=2\n",
        "                )\n",
        "                if user_response.status_code == 200:\n",
        "                    order_with_user = order.copy()\n",
        "                    order_with_user['user'] = user_response.json()\n",
        "                    return jsonify(order_with_user)\n",
        "            except requests.RequestException:\n",
        "                pass  # Fallback: return order without user\n",
        "\n",
        "            return jsonify(order)\n",
        "\n",
        "        @self.app.route('/orders', methods=['POST'])\n",
        "        def create_order():\n",
        "            data = request.get_json()\n",
        "            required = ['user_id', 'product', 'amount']\n",
        "            if not data or any(k not in data for k in required):\n",
        "                return jsonify({'error': 'user_id, product, amount required'}), 400\n",
        "\n",
        "            # Validate user exists\n",
        "            try:\n",
        "                user_response = requests.get(\n",
        "                    f\"{self.user_service_url}/users/{data['user_id']}\",\n",
        "                    timeout=2\n",
        "                )\n",
        "                if user_response.status_code != 200:\n",
        "                    return jsonify({'error': 'User not found'}), 400\n",
        "            except requests.RequestException:\n",
        "                return jsonify({'error': 'User service unavailable'}), 503\n",
        "\n",
        "            order_id = max(self.orders.keys()) + 1\n",
        "            order = {\n",
        "                'id': order_id,\n",
        "                'user_id': data['user_id'],\n",
        "                'product': data['product'],\n",
        "                'amount': data['amount']\n",
        "            }\n",
        "            self.orders[order_id] = order\n",
        "            return jsonify(order), 201\n",
        "\n",
        "    def run(self):\n",
        "        self.app.run(port=self.port, debug=False, use_reloader=False)\n",
        "\n",
        "\n",
        "# ================= API GATEWAY =================\n",
        "class APIGateway:\n",
        "    def __init__(self, port: int = 5000):\n",
        "        self.app = Flask(__name__)\n",
        "        self.port = port\n",
        "        self.user_service_url = 'http://localhost:5001'\n",
        "        self.order_service_url = 'http://localhost:5002'\n",
        "        self.setup_routes()\n",
        "\n",
        "    def setup_routes(self):\n",
        "        @self.app.route('/api/users', methods=['GET', 'POST'])\n",
        "        @self.app.route('/api/users/<int:user_id>', methods=['GET'])\n",
        "        def users_proxy(user_id=None):\n",
        "            if request.method == 'GET':\n",
        "                url = f\"{self.user_service_url}/users\"\n",
        "                if user_id:\n",
        "                    url += f\"/{user_id}\"\n",
        "            else:  # POST\n",
        "                url = f\"{self.user_service_url}/users\"\n",
        "\n",
        "            return self._proxy_request(url)\n",
        "\n",
        "        @self.app.route('/api/orders', methods=['GET', 'POST'])\n",
        "        @self.app.route('/api/orders/<int:order_id>', methods=['GET'])\n",
        "        def orders_proxy(order_id=None):\n",
        "            if request.method == 'GET':\n",
        "                url = f\"{self.order_service_url}/orders\"\n",
        "                if order_id:\n",
        "                    url += f\"/{order_id}\"\n",
        "            else:  # POST\n",
        "                url = f\"{self.order_service_url}/orders\"\n",
        "\n",
        "            return self._proxy_request(url)\n",
        "\n",
        "    def _proxy_request(self, url: str):\n",
        "        try:\n",
        "            response = requests.request(\n",
        "                method=request.method,\n",
        "                url=url,\n",
        "                headers={k: v for k, v in request.headers if k != 'Host'},\n",
        "                data=request.get_data(),\n",
        "                params=request.args,\n",
        "                cookies=request.cookies,\n",
        "                allow_redirects=False,\n",
        "                timeout=5\n",
        "            )\n",
        "            return (response.content, response.status_code, response.headers.items())\n",
        "        except requests.RequestException as e:\n",
        "            service = \"User\" if \"users\" in url else \"Order\"\n",
        "            return jsonify({'error': f'{service} service unavailable'}), 503\n",
        "\n",
        "    def run(self):\n",
        "        self.app.run(port=self.port, debug=False, use_reloader=False)\n",
        "\n",
        "\n",
        "# ================= HELPER & MAIN =================\n",
        "def run_service(service):\n",
        "    service.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create services\n",
        "    user_service = UserService()\n",
        "    order_service = OrderService()\n",
        "    api_gateway = APIGateway()\n",
        "\n",
        "    services = [user_service, order_service, api_gateway]\n",
        "    threads = []\n",
        "\n",
        "    # Start all services in background\n",
        "    for service in services:\n",
        "        thread = threading.Thread(target=run_service, args=(service,))\n",
        "        thread.daemon = True\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    print(\"Microservices started. Testing in 2 seconds...\")\n",
        "    time.sleep(2)\n",
        "\n",
        "    base_url = \"http://localhost:5000/api\"\n",
        "\n",
        "    try:\n",
        "        # Test: Get all users\n",
        "        response = requests.get(f\"{base_url}/users\")\n",
        "        print(f\"Users: {response.json()}\")\n",
        "\n",
        "        # Test: Get order with user details\n",
        "        response = requests.get(f\"{base_url}/orders/1\")\n",
        "        print(f\"Order with user: {response.json()}\")\n",
        "\n",
        "        # Test: Create new user\n",
        "        new_user = {'name': 'Bob Wilson', 'email': 'bob@example.com'}\n",
        "        response = requests.post(f\"{base_url}/users\", json=new_user)\n",
        "        print(f\"Created user: {response.json()}\")\n",
        "\n",
        "        # Test: Create new order\n",
        "        new_order = {'user_id': 3, 'product': 'Keyboard', 'amount': 79.99}\n",
        "        response = requests.post(f\"{base_url}/orders\", json=new_order)\n",
        "        print(f\"Created order: {response.json()}\")\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error testing services: {e}\")\n",
        "\n",
        "    # Keep alive\n",
        "    try:\n",
        "        print(\"\\nServices running. Press Ctrl+C to stop.\")\n",
        "        while True:\n",
        "            time.sleep(1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nStopping services...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm0KoSVZyTVP",
        "outputId": "2f01b0f2-1dea-4f9f-a95e-944ae889a111"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            "Microservices started. Testing in 2 seconds...\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
            "Address already in use\n",
            "Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
            "Address already in use\n",
            "Port 5002 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"GET /users HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"GET /api/users HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"GET /users/1 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"GET /orders/1 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"GET /api/orders/1 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"\u001b[35m\u001b[1mPOST /users HTTP/1.1\u001b[0m\" 201 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"\u001b[35m\u001b[1mPOST /api/users HTTP/1.1\u001b[0m\" 201 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"GET /users/3 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"\u001b[35m\u001b[1mPOST /orders HTTP/1.1\u001b[0m\" 201 -\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2025 06:59:01] \"\u001b[35m\u001b[1mPOST /api/orders HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users: [{'email': 'john@example.com', 'id': 1, 'name': 'John Doe'}, {'email': 'jane@example.com', 'id': 2, 'name': 'Jane Smith'}, {'email': 'bob@example.com', 'id': 3, 'name': 'Bob Wilson'}]\n",
            "Order with user: {'amount': 999.99, 'id': 1, 'product': 'Laptop', 'user': {'email': 'john@example.com', 'id': 1, 'name': 'John Doe'}, 'user_id': 1}\n",
            "Created user: {'email': 'bob@example.com', 'id': 4, 'name': 'Bob Wilson'}\n",
            "Created order: {'amount': 79.99, 'id': 4, 'product': 'Keyboard', 'user_id': 3}\n",
            "\n",
            "Services running. Press Ctrl+C to stop.\n",
            "\n",
            "Stopping services...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 7: Event-Driven Architecture\n",
        "Objective: Implement an event-driven architecture using message queues.\n",
        "Problem Statement: Create a notification system that processes events asynchronously"
      ],
      "metadata": {
        "id": "4n1dVDc-zLX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Callable, Any\n",
        "from enum import Enum\n",
        "\n",
        "\n",
        "# ================= EVENT TYPE =================\n",
        "class EventType(Enum):\n",
        "    USER_REGISTERED = \"user_registered\"\n",
        "    ORDER_CREATED = \"order_created\"\n",
        "    PAYMENT_PROCESSED = \"payment_processed\"\n",
        "    ORDER_SHIPPED = \"order_shipped\"\n",
        "\n",
        "\n",
        "# ================= EVENT =================\n",
        "class Event:\n",
        "    def __init__(self, event_type: EventType, data: Dict[str, Any]):\n",
        "        self.event_type = event_type\n",
        "        self.data = data\n",
        "        self.timestamp = datetime.now()\n",
        "        self.id = f\"{event_type.value}_{int(time.time())}\"\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            'id': self.id,\n",
        "            'event_type': self.event_type.value,\n",
        "            'timestamp': self.timestamp.isoformat(),\n",
        "            'data': self.data\n",
        "        }\n",
        "\n",
        "\n",
        "# ================= EVENT BUS =================\n",
        "class EventBus:\n",
        "    def __init__(self):\n",
        "        self._subscribers: Dict[EventType, List[Callable[[Event], None]]] = {}\n",
        "        self._event_queue: List[Event] = []\n",
        "        self._is_running = False\n",
        "        self._lock = threading.Lock()\n",
        "        self._thread: Optional[threading.Thread] = None\n",
        "\n",
        "    def subscribe(self, event_type: EventType, callback: Callable[[Event], None]):\n",
        "        with self._lock:\n",
        "            if event_type not in self._subscribers:\n",
        "                self._subscribers[event_type] = []\n",
        "            if callback not in self._subscribers[event_type]:\n",
        "                self._subscribers[event_type].append(callback)\n",
        "\n",
        "    def unsubscribe(self, event_type: EventType, callback: Callable[[Event], None]):\n",
        "        with self._lock:\n",
        "            if event_type in self._subscribers:\n",
        "                self._subscribers[event_type] = [\n",
        "                    cb for cb in self._subscribers[event_type] if cb != callback\n",
        "                ]\n",
        "\n",
        "    def publish(self, event: Event):\n",
        "        with self._lock:\n",
        "            self._event_queue.append(event)\n",
        "\n",
        "    def _process_events(self):\n",
        "        while self._is_running:\n",
        "            event = None\n",
        "            with self._lock:\n",
        "                if self._event_queue:\n",
        "                    event = self._event_queue.pop(0)\n",
        "\n",
        "            if event:\n",
        "                if event.event_type in self._subscribers:\n",
        "                    for callback in self._subscribers[event.event_type]:\n",
        "                        try:\n",
        "                            callback(event)\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error in event handler {callback.__name__}: {e}\")\n",
        "            else:\n",
        "                time.sleep(0.01)  # Prevent busy-waiting\n",
        "\n",
        "    def start(self):\n",
        "        if not self._is_running:\n",
        "            self._is_running = True\n",
        "            self._thread = threading.Thread(target=self._process_events, daemon=True)\n",
        "            self._thread.start()\n",
        "            print(\"[EventBus] Started.\")\n",
        "\n",
        "    def stop(self):\n",
        "        self._is_running = False\n",
        "        if self._thread:\n",
        "            self._thread.join(timeout=2)\n",
        "        print(\"[EventBus] Stopped.\")\n",
        "\n",
        "\n",
        "# ================= SERVICES =================\n",
        "class EmailService:\n",
        "    def send_welcome_email(self, event: Event):\n",
        "        user = event.data.get('user', {})\n",
        "        email = user.get('email', 'unknown')\n",
        "        print(f\"[Email] Sending welcome email to {email}\")\n",
        "        time.sleep(0.5)\n",
        "        print(f\"[Email] Welcome email sent to {email}\")\n",
        "\n",
        "    def send_order_confirmation(self, event: Event):\n",
        "        order = event.data.get('order', {})\n",
        "        user = event.data.get('user', {})\n",
        "        print(f\"[Email] Sending order confirmation to {user.get('email')} for order #{order.get('id')}\")\n",
        "        time.sleep(0.4)\n",
        "\n",
        "    def send_shipping_notification(self, event: Event):\n",
        "        order = event.data.get('order', {})\n",
        "        user = event.data.get('user', {})\n",
        "        print(f\"[Email] Sending shipping notification to {user.get('email')} for order #{order.get('id')}\")\n",
        "        time.sleep(0.3)\n",
        "\n",
        "\n",
        "class SMSService:\n",
        "    def send_welcome_sms(self, event: Event):\n",
        "        user = event.data.get('user', {})\n",
        "        phone = user.get('phone', 'unknown')\n",
        "        print(f\"[SMS] Sending welcome SMS to {phone}\")\n",
        "        time.sleep(0.3)\n",
        "        print(f\"[SMS] Welcome SMS sent to {phone}\")\n",
        "\n",
        "    def send_order_sms(self, event: Event):\n",
        "        order = event.data.get('order', {})\n",
        "        user = event.data.get('user', {})\n",
        "        print(f\"[SMS] Sending order update to {user.get('phone')} for order #{order.get('id')}\")\n",
        "        time.sleep(0.2)\n",
        "\n",
        "\n",
        "class AnalyticsService:\n",
        "    def track_user_registration(self, event: Event):\n",
        "        user = event.data.get('user', {})\n",
        "        print(f\"[Analytics] Tracking user registration: {user.get('name')}\")\n",
        "\n",
        "    def track_order_creation(self, event: Event):\n",
        "        order = event.data.get('order', {})\n",
        "        print(f\"[Analytics] Tracking order creation: #{order.get('id')}\")\n",
        "\n",
        "    def track_payment(self, event: Event):\n",
        "        payment = event.data.get('payment', {})\n",
        "        print(f\"[Analytics] Tracking payment: ${payment.get('amount')} (ID: {payment.get('id')})\")\n",
        "\n",
        "\n",
        "class InventoryService:\n",
        "    def update_inventory(self, event: Event):\n",
        "        order = event.data.get('order', {})\n",
        "        print(f\"[Inventory] Updating inventory for order #{order.get('id')}\")\n",
        "        time.sleep(0.2)\n",
        "        print(f\"[Inventory] Inventory updated for order #{order.get('id')}\")\n",
        "\n",
        "\n",
        "# ================= ECOMMERCE APP =================\n",
        "class ECommerceApplication:\n",
        "    def __init__(self):\n",
        "        self.event_bus = EventBus()\n",
        "        self.setup_services()\n",
        "\n",
        "    def setup_services(self):\n",
        "        email_service = EmailService()\n",
        "        sms_service = SMSService()\n",
        "        analytics_service = AnalyticsService()\n",
        "        inventory_service = InventoryService()\n",
        "\n",
        "        # Subscribe to events\n",
        "        self.event_bus.subscribe(EventType.USER_REGISTERED, email_service.send_welcome_email)\n",
        "        self.event_bus.subscribe(EventType.USER_REGISTERED, sms_service.send_welcome_sms)\n",
        "        self.event_bus.subscribe(EventType.USER_REGISTERED, analytics_service.track_user_registration)\n",
        "\n",
        "        self.event_bus.subscribe(EventType.ORDER_CREATED, email_service.send_order_confirmation)\n",
        "        self.event_bus.subscribe(EventType.ORDER_CREATED, sms_service.send_order_sms)\n",
        "        self.event_bus.subscribe(EventType.ORDER_CREATED, analytics_service.track_order_creation)\n",
        "        self.event_bus.subscribe(EventType.ORDER_CREATED, inventory_service.update_inventory)\n",
        "\n",
        "        self.event_bus.subscribe(EventType.ORDER_SHIPPED, email_service.send_shipping_notification)\n",
        "        self.event_bus.subscribe(EventType.ORDER_SHIPPED, sms_service.send_order_sms)\n",
        "\n",
        "        self.event_bus.subscribe(EventType.PAYMENT_PROCESSED, analytics_service.track_payment)\n",
        "\n",
        "    def register_user(self, user_data: Dict[str, Any]):\n",
        "        print(f\"\\nRegistering User: {user_data['name']} ===\")\n",
        "        event = Event(EventType.USER_REGISTERED, {'user': user_data})\n",
        "        self.event_bus.publish(event)\n",
        "\n",
        "    def create_order(self, order_data: Dict[str, Any], user_data: Dict[str, Any]):\n",
        "        print(f\"\\nCreating Order: #{order_data['id']} ===\")\n",
        "        event = Event(EventType.ORDER_CREATED, {\n",
        "            'order': order_data,\n",
        "            'user': user_data\n",
        "        })\n",
        "        self.event_bus.publish(event)\n",
        "\n",
        "    def process_payment(self, payment_data: Dict[str, Any]):\n",
        "        print(f\"\\nProcessing Payment ===\")\n",
        "        event = Event(EventType.PAYMENT_PROCESSED, {'payment': payment_data})\n",
        "        self.event_bus.publish(event)\n",
        "\n",
        "    def ship_order(self, order_data: Dict[str, Any], user_data: Dict[str, Any]):\n",
        "        print(f\"\\nShipping Order: #{order_data['id']} ===\")\n",
        "        event = Event(EventType.ORDER_SHIPPED, {\n",
        "            'order': order_data,\n",
        "            'user': user_data\n",
        "        })\n",
        "        self.event_bus.publish(event)\n",
        "\n",
        "\n",
        "# ================= DEMO =================\n",
        "if __name__ == \"__main__\":\n",
        "    app = ECommerceApplication()\n",
        "    app.event_bus.start()\n",
        "\n",
        "    # Simulate user journey\n",
        "    user = {\n",
        "        'id': 1,\n",
        "        'name': 'Alice Johnson',\n",
        "        'email': 'alice@example.com',\n",
        "        'phone': '+1234567890'\n",
        "    }\n",
        "\n",
        "    order = {\n",
        "        'id': 101,\n",
        "        'product': 'Laptop',\n",
        "        'amount': 999.99\n",
        "    }\n",
        "\n",
        "    payment = {\n",
        "        'id': 201,\n",
        "        'order_id': 101,\n",
        "        'amount': 999.99,\n",
        "        'status': 'completed'\n",
        "    }\n",
        "\n",
        "    # Execute flow\n",
        "    app.register_user(user)\n",
        "    time.sleep(1.5)\n",
        "\n",
        "    app.create_order(order, user)\n",
        "    time.sleep(1.5)\n",
        "\n",
        "    app.process_payment(payment)\n",
        "    time.sleep(1)\n",
        "\n",
        "    app.ship_order(order, user)\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Shutdown\n",
        "    app.event_bus.stop()\n",
        "    print(\"\\nAll events processed. System shutdown.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf6hToQmzOBz",
        "outputId": "7d2ccd51-f94c-4a2a-df32-c818a953dacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EventBus] Started.\n",
            "\n",
            "Registering User: Alice Johnson ===\n",
            "[Email] Sending welcome email to alice@example.com\n",
            "[Email] Welcome email sent to alice@example.com\n",
            "[SMS] Sending welcome SMS to +1234567890\n",
            "[SMS] Welcome SMS sent to +1234567890\n",
            "[Analytics] Tracking user registration: Alice Johnson\n",
            "\n",
            "Creating Order: #101 ===\n",
            "[Email] Sending order confirmation to alice@example.com for order #101\n",
            "[SMS] Sending order update to +1234567890 for order #101\n",
            "[Analytics] Tracking order creation: #101\n",
            "[Inventory] Updating inventory for order #101\n",
            "[Inventory] Inventory updated for order #101\n",
            "\n",
            "Processing Payment ===\n",
            "[Analytics] Tracking payment: $999.99 (ID: 201)\n",
            "\n",
            "Shipping Order: #101 ===\n",
            "[Email] Sending shipping notification to alice@example.com for order #101\n",
            "[SMS] Sending order update to +1234567890 for order #101\n",
            "[EventBus] Stopped.\n",
            "\n",
            "All events processed. System shutdown.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 8: Quality Attribute Analysis\n",
        "Objective: Analyze and measure software quality attributes.\n",
        "Problem Statement: Create tools to measure performance, maintainability, and reliability."
      ],
      "metadata": {
        "id": "bH6UNwixz16y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory-profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXCVdGnT0iW1",
        "outputId": "ce4af91f-285e-4ab7-ebf1-a31c0445de6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from memory-profiler) (5.9.5)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# PERFORMANCE + MAINTAINABILITY + RELIABILITY ANALYZER\n",
        "# 100% WORKS IN JUPYTER, COLAB, AND .py SCRIPTS\n",
        "# ================================\n",
        "\n",
        "import time\n",
        "import statistics\n",
        "import random\n",
        "import inspect\n",
        "import ast\n",
        "import sys\n",
        "from typing import List, Dict, Callable, Any, Optional\n",
        "\n",
        "# Optional: Memory profiling\n",
        "try:\n",
        "    import memory_profiler\n",
        "    MEMORY_PROFILER_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MEMORY_PROFILER_AVAILABLE = False\n",
        "    print(\"Warning: memory_profiler not installed. Memory tracking skipped.\")\n",
        "    print(\"Install with: pip install memory-profiler\")\n",
        "\n",
        "\n",
        "# ================= PERFORMANCE ANALYZER =================\n",
        "class PerformanceAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.metrics: Dict[str, List[float]] = {}\n",
        "\n",
        "    def measure_execution_time(self, func: Callable) -> Callable:\n",
        "        def wrapper(*args, **kwargs):\n",
        "            start = time.perf_counter()\n",
        "            result = func(*args, **kwargs)\n",
        "            end = time.perf_counter()\n",
        "            duration = end - start\n",
        "            name = func.__name__\n",
        "            self.metrics.setdefault(name, []).append(duration)\n",
        "            print(f\"Time: {name} executed in {duration:.6f}s\")\n",
        "            return result\n",
        "        return wrapper\n",
        "\n",
        "    def measure_memory_usage(self, func: Callable) -> Callable:\n",
        "        if not MEMORY_PROFILER_AVAILABLE:\n",
        "            def wrapper(*args, **kwargs):\n",
        "                print(f\"Memory: Skipping '{func.__name__}' (memory_profiler not available)\")\n",
        "                return func(*args, **kwargs)\n",
        "            return wrapper\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            mem_before = memory_profiler.memory_usage()[0]\n",
        "            result = func(*args, **kwargs)\n",
        "            mem_after = memory_profiler.memory_usage()[0]\n",
        "            used = mem_after - mem_before\n",
        "            print(f\"Memory: {func.__name__} used {used:.2f} MB\")\n",
        "            return result\n",
        "        return wrapper\n",
        "\n",
        "    def get_performance_summary(self):\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\" PERFORMANCE SUMMARY \")\n",
        "        print(\"=\"*60)\n",
        "        if not self.metrics:\n",
        "            print(\"  No functions measured.\")\n",
        "            return\n",
        "        for name, times in self.metrics.items():\n",
        "            avg = statistics.mean(times)\n",
        "            min_t = min(times)\n",
        "            max_t = max(times)\n",
        "            std = statistics.stdev(times) if len(times) > 1 else 0.0\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  Avg: {avg:.6f}s | Min: {min_t:.6f}s | Max: {max_t:.6f}s\")\n",
        "            print(f\"  Std Dev: {std:.6f}s | Samples: {len(times)}\")\n",
        "\n",
        "\n",
        "# ================= MAINTAINABILITY ANALYZER =================\n",
        "class MaintainabilityAnalyzer:\n",
        "    def analyze_complexity(self, source_code: str) -> Dict[str, Any]:\n",
        "        try:\n",
        "            tree = ast.parse(source_code)\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Parse error: {e}\"}\n",
        "\n",
        "        metrics = {\n",
        "            'line_count': len(source_code.splitlines()),\n",
        "            'function_count': 0,\n",
        "            'class_count': 0,\n",
        "            'average_function_length': 0.0,\n",
        "            'max_nesting': 0,\n",
        "            'cyclomatic_complexity': 1\n",
        "        }\n",
        "\n",
        "        function_lines = []\n",
        "\n",
        "        class Visitor(ast.NodeVisitor):\n",
        "            def __init__(self):\n",
        "                self.in_function = False\n",
        "                self.current_lines = 0\n",
        "                self.nesting = 0\n",
        "\n",
        "            def visit_FunctionDef(self, node):\n",
        "                metrics['function_count'] += 1\n",
        "                self.in_function = True\n",
        "                self.current_lines = 0\n",
        "                self.nesting = 0\n",
        "                self.generic_visit(node)\n",
        "                function_lines.append(self.current_lines)\n",
        "                self.in_function = False\n",
        "\n",
        "            def visit_ClassDef(self, node):\n",
        "                metrics['class_count'] += 1\n",
        "                self.generic_visit(node)\n",
        "\n",
        "            def visit(self, node):\n",
        "                control_nodes = (ast.If, ast.For, ast.While, ast.Try, ast.With,\n",
        "                                ast.AsyncFor, ast.AsyncWith, ast.Match)\n",
        "                if isinstance(node, control_nodes):\n",
        "                    metrics['cyclomatic_complexity'] += 1\n",
        "                    self.nesting += 1\n",
        "                    metrics['max_nesting'] = max(metrics['max_nesting'], self.nesting)\n",
        "                super().visit(node)\n",
        "                if isinstance(node, control_nodes):\n",
        "                    self.nesting -= 1\n",
        "\n",
        "            def generic_visit(self, node):\n",
        "                if self.in_function:\n",
        "                    self.current_lines += 1\n",
        "                super().generic_visit(node)\n",
        "\n",
        "        visitor = Visitor()\n",
        "        visitor.visit(tree)\n",
        "\n",
        "        if function_lines:\n",
        "            metrics['average_function_length'] = sum(function_lines) / len(function_lines)\n",
        "        return metrics\n",
        "\n",
        "    def calculate_maintainability_index(self, source_code: str) -> float:\n",
        "        metrics = self.analyze_complexity(source_code)\n",
        "        if \"error\" in metrics:\n",
        "            return 0.0\n",
        "\n",
        "        line_count = metrics['line_count']\n",
        "        func_count = metrics['function_count']\n",
        "        avg_len = metrics['average_function_length']\n",
        "\n",
        "        line_factor = max(0, 1 - line_count / 1000)\n",
        "        func_factor = max(0, 1 - func_count / 50)\n",
        "        len_factor = max(0, 1 - avg_len / 50)\n",
        "\n",
        "        index = (line_factor + func_factor + len_factor) / 3 * 100\n",
        "        return max(0, min(100, index))\n",
        "\n",
        "\n",
        "# ================= RELIABILITY TESTER =================\n",
        "class ReliabilityTester:\n",
        "    def __init__(self):\n",
        "        self.failure_count = 0\n",
        "        self.success_count = 0\n",
        "        self.response_times: List[float] = []\n",
        "\n",
        "    def test_reliability(self, func: Callable, test_cases: List[Dict], iterations: int = 100):\n",
        "        print(f\"\\n=== Reliability Testing: {func.__name__} ===\")\n",
        "        total = len(test_cases) * iterations\n",
        "\n",
        "        for i in range(iterations):\n",
        "            for case in test_cases:\n",
        "                inputs = case.get('input', ())\n",
        "                expected = case.get('expected')\n",
        "\n",
        "                try:\n",
        "                    start = time.perf_counter()\n",
        "                    result = func(*inputs)\n",
        "                    end = time.perf_counter()\n",
        "                    self.response_times.append(end - start)\n",
        "\n",
        "                    if expected is not None and result != expected:\n",
        "                        self.failure_count += 1\n",
        "                        print(f\"  Failed: input={inputs} | expected={expected}, got={result}\")\n",
        "                    else:\n",
        "                        self.success_count += 1\n",
        "                except Exception as e:\n",
        "                    self.failure_count += 1\n",
        "                    print(f\"  Exception: {e} for input={inputs}\")\n",
        "\n",
        "        self._print_reliability_report(total)\n",
        "\n",
        "    def _print_reliability_report(self, total_tests: int):\n",
        "        reliability = (self.success_count / total_tests) * 100 if total_tests > 0 else 0\n",
        "        print(f\"\\n=== Reliability Report ===\")\n",
        "        print(f\"  Total Tests : {total_tests}\")\n",
        "        print(f\"  Successful  : {self.success_count}\")\n",
        "        print(f\"  Failures    : {self.failure_count}\")\n",
        "        print(f\"  Reliability : {reliability:.2f}%\")\n",
        "\n",
        "        if self.response_times:\n",
        "            avg = statistics.mean(self.response_times)\n",
        "            print(f\"  Avg Response: {avg:.6f}s\")\n",
        "\n",
        "\n",
        "# ================= EXAMPLE FUNCTIONS =================\n",
        "class ExampleFunctions:\n",
        "    @staticmethod\n",
        "    def fibonacci(n: int) -> int:\n",
        "        if n <= 1:\n",
        "            return n\n",
        "        a, b = 0, 1\n",
        "        for _ in range(2, n + 1):\n",
        "            a, b = b, a + b\n",
        "        return b\n",
        "\n",
        "    @staticmethod\n",
        "    def process_data(data: List[int]) -> Dict:\n",
        "        if not data:\n",
        "            return {}\n",
        "        return {\n",
        "            'sum': sum(data),\n",
        "            'average': statistics.mean(data),\n",
        "            'max': max(data),\n",
        "            'min': min(data)\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def simulate_network_request() -> bool:\n",
        "        time.sleep(0.01)\n",
        "        return random.random() > 0.1\n",
        "\n",
        "\n",
        "# ================= SAFE SOURCE GETTER (Notebook + Script) =================\n",
        "def safe_getsource(obj) -> Optional[str]:\n",
        "    \"\"\"Safely get source code — works in notebooks and .py files.\"\"\"\n",
        "    try:\n",
        "        return inspect.getsource(obj)\n",
        "    except (OSError, TypeError, IOError):\n",
        "        # In notebook: no file → skip or use cell\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_current_cell_source() -> Optional[str]:\n",
        "    \"\"\"Get last executed cell in Jupyter/Colab.\"\"\"\n",
        "    try:\n",
        "        import IPython\n",
        "        ip = IPython.get_ipython()\n",
        "        if ip is not None:\n",
        "            cell = ip.user_ns.get('In', [''])[-1]\n",
        "            return cell if cell.strip() else None\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "\n",
        "# ================= DEMO =================\n",
        "def run_demo():\n",
        "    perf = PerformanceAnalyzer()\n",
        "    maint = MaintainabilityAnalyzer()\n",
        "\n",
        "    print(\"Starting Full Analysis...\\n\")\n",
        "\n",
        "    # === 1. Performance ===\n",
        "    print(\"1. Performance Testing...\")\n",
        "    fib_perf = perf.measure_execution_time(ExampleFunctions.fibonacci)\n",
        "    proc_perf = perf.measure_execution_time(ExampleFunctions.process_data)\n",
        "\n",
        "    for _ in range(5):\n",
        "        fib_perf(1000)\n",
        "        proc_perf(list(range(1000)))\n",
        "\n",
        "    perf.get_performance_summary()\n",
        "\n",
        "    # === 2. Maintainability (Safe) ===\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"2. Maintainability Analysis...\")\n",
        "\n",
        "    source = safe_getsource(ExampleFunctions)\n",
        "    if source:\n",
        "        metrics = maint.analyze_complexity(source)\n",
        "        index = maint.calculate_maintainability_index(source)\n",
        "        print(\"Complexity Metrics:\")\n",
        "        for k, v in metrics.items():\n",
        "            if k != \"error\":\n",
        "                print(f\"  {k}: {v}\")\n",
        "        print(f\"Maintainability Index: {index:.2f}/100\")\n",
        "    else:\n",
        "        print(\"  Source code not available (running in notebook). Skipping class analysis.\")\n",
        "\n",
        "    # === 3. Reliability ===\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"3. Reliability Testing...\")\n",
        "\n",
        "    fib_cases = [\n",
        "        {'input': (0,), 'expected': 0},\n",
        "        {'input': (1,), 'expected': 1},\n",
        "        {'input': (5,), 'expected': 5},\n",
        "        {'input': (10,), 'expected': 55},\n",
        "        {'input': (20,), 'expected': 6765}\n",
        "    ]\n",
        "    ReliabilityTester().test_reliability(ExampleFunctions.fibonacci, fib_cases, iterations=10)\n",
        "\n",
        "    net_cases = [{'input': ()} for _ in range(50)]\n",
        "    ReliabilityTester().test_reliability(ExampleFunctions.simulate_network_request, net_cases, iterations=1)\n",
        "\n",
        "    # === 4. Full Source / Cell Analysis ===\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"4. Full Script / Cell Analysis...\")\n",
        "\n",
        "    full_source = None\n",
        "\n",
        "    # Try .py file\n",
        "    try:\n",
        "        with open(__file__, 'r', encoding='utf-8') as f:\n",
        "            full_source = f.read()\n",
        "        print(\"  Analyzing .py file...\")\n",
        "    except NameError:\n",
        "        # In notebook\n",
        "        cell_source = get_current_cell_source()\n",
        "        if cell_source:\n",
        "            full_source = cell_source\n",
        "            print(\"  Analyzing current notebook cell...\")\n",
        "        else:\n",
        "            print(\"  No cell source found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Could not read file: {e}\")\n",
        "\n",
        "    if full_source:\n",
        "        index = maint.calculate_maintainability_index(full_source)\n",
        "        print(f\"Full Source Maintainability: {index:.2f}/100\")\n",
        "    else:\n",
        "        print(\"  Tip: Save as .py to analyze full file.\")\n",
        "\n",
        "\n",
        "# Run demo\n",
        "run_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5mxtXmMz4Vv",
        "outputId": "09457c73-6189-45ca-b530-87d5bdb614f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Full Analysis...\n",
            "\n",
            "1. Performance Testing...\n",
            "Time: fibonacci executed in 0.000079s\n",
            "Time: process_data executed in 0.000319s\n",
            "Time: fibonacci executed in 0.000068s\n",
            "Time: process_data executed in 0.000310s\n",
            "Time: fibonacci executed in 0.000068s\n",
            "Time: process_data executed in 0.000272s\n",
            "Time: fibonacci executed in 0.000067s\n",
            "Time: process_data executed in 0.000274s\n",
            "Time: fibonacci executed in 0.000090s\n",
            "Time: process_data executed in 0.000273s\n",
            "\n",
            "============================================================\n",
            " PERFORMANCE SUMMARY \n",
            "============================================================\n",
            "\n",
            "fibonacci:\n",
            "  Avg: 0.000074s | Min: 0.000067s | Max: 0.000090s\n",
            "  Std Dev: 0.000010s | Samples: 5\n",
            "\n",
            "process_data:\n",
            "  Avg: 0.000289s | Min: 0.000272s | Max: 0.000319s\n",
            "  Std Dev: 0.000023s | Samples: 5\n",
            "\n",
            "============================================================\n",
            "2. Maintainability Analysis...\n",
            "  Source code not available (running in notebook). Skipping class analysis.\n",
            "\n",
            "============================================================\n",
            "3. Reliability Testing...\n",
            "\n",
            "=== Reliability Testing: fibonacci ===\n",
            "\n",
            "=== Reliability Report ===\n",
            "  Total Tests : 50\n",
            "  Successful  : 50\n",
            "  Failures    : 0\n",
            "  Reliability : 100.00%\n",
            "  Avg Response: 0.000000s\n",
            "\n",
            "=== Reliability Testing: simulate_network_request ===\n",
            "\n",
            "=== Reliability Report ===\n",
            "  Total Tests : 50\n",
            "  Successful  : 50\n",
            "  Failures    : 0\n",
            "  Reliability : 100.00%\n",
            "  Avg Response: 0.010074s\n",
            "\n",
            "============================================================\n",
            "4. Full Script / Cell Analysis...\n",
            "  Analyzing current notebook cell...\n",
            "Full Source Maintainability: 40.37/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 9: Load Balancer Implementation\n",
        "Objective: Implement different load balancing algorithms.\n",
        "Problem Statement: Create a load balancer that distributes requests using various algorithms.\n"
      ],
      "metadata": {
        "id": "UKK_Qv9F2z6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# LOAD BALANCER WITH MULTIPLE STRATEGIES\n",
        "# Works in .py, Jupyter, Google Colab\n",
        "# ================================\n",
        "\n",
        "import threading\n",
        "import time\n",
        "import random\n",
        "import statistics\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Any\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# ================= SERVER =================\n",
        "class Server:\n",
        "    def __init__(self, server_id: str, capacity: int = 100):\n",
        "        self.server_id = server_id\n",
        "        self.capacity = capacity\n",
        "        self.current_load = 0\n",
        "        self.response_times = []\n",
        "        self.error_count = 0\n",
        "        self.request_count = 0\n",
        "        self.is_healthy = True\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def process_request(self, request_id: str) -> Dict[str, Any]:\n",
        "        with self.lock:\n",
        "            if self.current_load >= self.capacity:\n",
        "                self.error_count += 1\n",
        "                return {'error': 'Server overloaded', 'server': self.server_id}\n",
        "\n",
        "            self.current_load += 1\n",
        "            self.request_count += 1\n",
        "\n",
        "        # Simulate processing time\n",
        "        processing_time = random.uniform(0.1, 2.0)\n",
        "\n",
        "        # Simulate 5% error rate\n",
        "        if random.random() < 0.05:\n",
        "            with self.lock:\n",
        "                self.error_count += 1\n",
        "            time.sleep(processing_time)\n",
        "            return {'error': 'Internal server error', 'server': self.server_id}\n",
        "\n",
        "        time.sleep(processing_time)\n",
        "\n",
        "        with self.lock:\n",
        "            self.current_load -= 1\n",
        "            self.response_times.append(processing_time)\n",
        "\n",
        "        return {\n",
        "            'success': True,\n",
        "            'server': self.server_id,\n",
        "            'request_id': request_id,\n",
        "            'processing_time': processing_time,\n",
        "            'current_load': self.current_load\n",
        "        }\n",
        "\n",
        "    def get_metrics(self) -> Dict[str, Any]:\n",
        "        with self.lock:\n",
        "            avg_response_time = (\n",
        "                statistics.mean(self.response_times) if self.response_times else 0\n",
        "            )\n",
        "            error_rate = (\n",
        "                self.error_count / self.request_count if self.request_count > 0 else 0\n",
        "            )\n",
        "            return {\n",
        "                'server_id': self.server_id,\n",
        "                'current_load': self.current_load,\n",
        "                'capacity': self.capacity,\n",
        "                'utilization': (self.current_load / self.capacity) * 100,\n",
        "                'total_requests': self.request_count,\n",
        "                'error_count': self.error_count,\n",
        "                'error_rate': error_rate,\n",
        "                'avg_response_time': avg_response_time,\n",
        "                'is_healthy': self.is_healthy\n",
        "            }\n",
        "\n",
        "    def health_check(self) -> bool:\n",
        "        # 2% chance of health failure\n",
        "        self.is_healthy = random.random() >= 0.02\n",
        "        return self.is_healthy\n",
        "\n",
        "\n",
        "# ================= LOAD BALANCING STRATEGIES =================\n",
        "class LoadBalancingStrategy(ABC):\n",
        "    @abstractmethod\n",
        "    def select_server(self, servers: List[Server]) -> Server:\n",
        "        pass\n",
        "\n",
        "\n",
        "class RoundRobinStrategy(LoadBalancingStrategy):\n",
        "    def __init__(self):\n",
        "        self.current_index = 0\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def select_server(self, servers: List[Server]) -> Server:\n",
        "        with self.lock:\n",
        "            if not servers:\n",
        "                raise ValueError(\"No servers available\")\n",
        "            server = servers[self.current_index]\n",
        "            self.current_index = (self.current_index + 1) % len(servers)\n",
        "            return server\n",
        "\n",
        "\n",
        "class LeastConnectionsStrategy(LoadBalancingStrategy):\n",
        "    def select_server(self, servers: List[Server]) -> Server:\n",
        "        if not servers:\n",
        "            raise ValueError(\"No servers available\")\n",
        "\n",
        "        healthy_servers = [s for s in servers if s.is_healthy]\n",
        "        if not healthy_servers:\n",
        "            raise ValueError(\"No healthy servers available\")\n",
        "\n",
        "        return min(healthy_servers, key=lambda s: s.current_load)\n",
        "\n",
        "\n",
        "class WeightedRoundRobinStrategy(LoadBalancingStrategy):\n",
        "    def __init__(self, weights: Dict[str, int]):\n",
        "        self.weights = weights\n",
        "        self.current_weights = weights.copy()\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def select_server(self, servers: List[Server]) -> Server:\n",
        "        with self.lock:\n",
        "            if not servers:\n",
        "                raise ValueError(\"No servers available\")\n",
        "\n",
        "            # Filter healthy servers with positive weight\n",
        "            available_servers = [\n",
        "                s for s in servers\n",
        "                if s.is_healthy and self.current_weights.get(s.server_id, 0) > 0\n",
        "            ]\n",
        "\n",
        "            if not available_servers:\n",
        "                # Reset weights\n",
        "                self.current_weights = self.weights.copy()\n",
        "                available_servers = [\n",
        "                    s for s in servers\n",
        "                    if s.is_healthy and self.current_weights.get(s.server_id, 0) > 0\n",
        "                ]\n",
        "\n",
        "            if not available_servers:\n",
        "                raise ValueError(\"No healthy servers available\")\n",
        "\n",
        "            # Select server with highest current weight\n",
        "            selected_server = max(\n",
        "                available_servers,\n",
        "                key=lambda s: self.current_weights[s.server_id]\n",
        "            )\n",
        "            self.current_weights[selected_server.server_id] -= 1\n",
        "            return selected_server\n",
        "\n",
        "\n",
        "class RandomStrategy(LoadBalancingStrategy):\n",
        "    def select_server(self, servers: List[Server]) -> Server:\n",
        "        if not servers:\n",
        "            raise ValueError(\"No servers available\")\n",
        "\n",
        "        healthy_servers = [s for s in servers if s.is_healthy]\n",
        "        if not healthy_servers:\n",
        "            raise ValueError(\"No healthy servers available\")\n",
        "\n",
        "        return random.choice(healthy_servers)\n",
        "\n",
        "\n",
        "# ================= LOAD BALANCER =================\n",
        "class LoadBalancer:\n",
        "    def __init__(self, strategy: LoadBalancingStrategy):\n",
        "        self.servers: List[Server] = []\n",
        "        self.strategy = strategy\n",
        "        self.metrics = defaultdict(list)\n",
        "        self.health_check_interval = 30\n",
        "        self.is_running = False\n",
        "        self.health_check_thread = None\n",
        "\n",
        "    def add_server(self, server: Server):\n",
        "        self.servers.append(server)\n",
        "\n",
        "    def remove_server(self, server_id: str):\n",
        "        self.servers = [s for s in self.servers if s.server_id != server_id]\n",
        "\n",
        "    def process_request(self, request_id: str) -> Dict[str, Any]:\n",
        "        try:\n",
        "            selected_server = self.strategy.select_server(self.servers)\n",
        "            response = selected_server.process_request(request_id)\n",
        "            self.metrics['requests_processed'].append(time.time())\n",
        "            return response\n",
        "        except ValueError as e:\n",
        "            return {'error': str(e), 'request_id': request_id}\n",
        "\n",
        "    def start_health_checks(self):\n",
        "        self.is_running = True\n",
        "        self.health_check_thread = threading.Thread(target=self._health_check_loop)\n",
        "        self.health_check_thread.daemon = True\n",
        "        self.health_check_thread.start()\n",
        "\n",
        "    def stop_health_checks(self):\n",
        "        self.is_running = False\n",
        "        if self.health_check_thread:\n",
        "            self.health_check_thread.join()\n",
        "\n",
        "    def _health_check_loop(self):\n",
        "        while self.is_running:\n",
        "            for server in self.servers:\n",
        "                server.health_check()\n",
        "            time.sleep(self.health_check_interval)\n",
        "\n",
        "    def get_load_balancer_metrics(self) -> Dict[str, Any]:\n",
        "        server_metrics = [server.get_metrics() for server in self.servers]\n",
        "        total_requests = sum(m['total_requests'] for m in server_metrics)\n",
        "        total_errors = sum(m['error_count'] for m in server_metrics)\n",
        "        overall_error_rate = total_errors / total_requests if total_requests > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'total_servers': len(self.servers),\n",
        "            'healthy_servers': len([s for s in self.servers if s.is_healthy]),\n",
        "            'total_requests_processed': total_requests,\n",
        "            'overall_error_rate': overall_error_rate,\n",
        "            'server_metrics': server_metrics,\n",
        "            'strategy': type(self.strategy).__name__\n",
        "        }\n",
        "\n",
        "\n",
        "# ================= SIMULATION =================\n",
        "def simulate_requests(load_balancer: LoadBalancer, num_requests: int):\n",
        "    def make_request(req_id):\n",
        "        response = load_balancer.process_request(f\"req_{req_id}\")\n",
        "        if 'error' in response:\n",
        "            print(f\"Request {req_id} failed: {response['error']}\")\n",
        "        else:\n",
        "            print(f\"Request {req_id} → {response['server']} (load: {response['current_load']})\")\n",
        "\n",
        "    threads = []\n",
        "    for i in range(num_requests):\n",
        "        thread = threading.Thread(target=make_request, args=(i,))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "        time.sleep(random.uniform(0.05, 0.2))  # Stagger\n",
        "\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "\n",
        "# ================= DEMO =================\n",
        "if __name__ == \"__main__\":\n",
        "    # Create servers\n",
        "    servers = [\n",
        "        Server(\"server_1\", capacity=50),\n",
        "        Server(\"server_2\", capacity=75),\n",
        "        Server(\"server_3\", capacity=100),\n",
        "        Server(\"server_4\", capacity=25)\n",
        "    ]\n",
        "\n",
        "    # Define strategies\n",
        "    strategies = {\n",
        "        \"Round Robin\": RoundRobinStrategy(),\n",
        "        \"Least Connections\": LeastConnectionsStrategy(),\n",
        "        \"Weighted Round Robin\": WeightedRoundRobinStrategy({\n",
        "            \"server_1\": 3,\n",
        "            \"server_2\": 2,\n",
        "            \"server_3\": 1,\n",
        "            \"server_4\": 1\n",
        "        }),\n",
        "        \"Random\": RandomStrategy()\n",
        "    }\n",
        "\n",
        "    for strategy_name, strategy in strategies.items():\n",
        "        print(f\"\\n{'='*20} Testing {strategy_name} Strategy {'='*20}\")\n",
        "\n",
        "        # Reset servers\n",
        "        for s in servers:\n",
        "            s.current_load = 0\n",
        "            s.request_count = 0\n",
        "            s.error_count = 0\n",
        "            s.response_times = []\n",
        "            s.is_healthy = True\n",
        "\n",
        "        # Setup load balancer\n",
        "        lb = LoadBalancer(strategy)\n",
        "        for server in servers:\n",
        "            lb.add_server(server)\n",
        "\n",
        "        # Start health checks\n",
        "        lb.start_health_checks()\n",
        "\n",
        "        # Simulate traffic\n",
        "        simulate_requests(lb, 25)\n",
        "\n",
        "        # Wait for processing\n",
        "        time.sleep(3)\n",
        "\n",
        "        # Print metrics\n",
        "        metrics = lb.get_load_balancer_metrics()\n",
        "        print(f\"\\n{strategy_name} Results:\")\n",
        "        print(f\"  Healthy: {metrics['healthy_servers']}/{metrics['total_servers']}\")\n",
        "        print(f\"  Total Requests: {metrics['total_requests_processed']}\")\n",
        "        print(f\"  Error Rate: {metrics['overall_error_rate']:.2%}\")\n",
        "\n",
        "        for sm in metrics['server_metrics']:\n",
        "            print(f\"  {sm['server_id']}: \"\n",
        "                  f\"{sm['current_load']}/{sm['capacity']} \"\n",
        "                  f\"({sm['utilization']:.1f}%) \"\n",
        "                  f\"Errors: {sm['error_count']}\")\n",
        "\n",
        "        lb.stop_health_checks()\n",
        "\n",
        "    print(\"\\nAll strategies tested!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQgR0Zwy2JDc",
        "outputId": "316fe099-31cc-43df-83aa-535dc8234a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Testing Round Robin Strategy ====================\n",
            "Request 0 → server_1 (load: 1)\n",
            "Request 1 → server_2 (load: 0)\n",
            "Request 4 → server_1 (load: 1)\n",
            "Request 7 failed: Internal server error\n",
            "Request 3 → server_4 (load: 2)\n",
            "Request 5 → server_2 (load: 2)\n",
            "Request 9 → server_2 (load: 1)\n",
            "Request 2 failed: Internal server error\n",
            "Request 6 → server_3 (load: 3)\n",
            "Request 8 → server_1 (load: 1)\n",
            "Request 13 → server_2 (load: 0)\n",
            "Request 10 → server_3 (load: 2)\n",
            "Request 16 → server_1 (load: 1)\n",
            "Request 11 → server_4 (load: 2)\n",
            "Request 12 → server_1 (load: 0)\n",
            "Request 20 → server_1 (load: 0)\n",
            "Request 18 → server_3 (load: 3)\n",
            "Request 19 → server_4 (load: 3)\n",
            "Request 14 → server_3 (load: 2)\n",
            "Request 24 → server_1 (load: 0)\n",
            "Request 17 → server_2 (load: 1)\n",
            "Request 15 failed: Internal server error\n",
            "Request 21 → server_2 (load: 0)\n",
            "Request 22 → server_3 (load: 1)\n",
            "Request 23 → server_4 (load: 2)\n",
            "\n",
            "Round Robin Results:\n",
            "  Healthy: 4/4\n",
            "  Total Requests: 25\n",
            "  Error Rate: 12.00%\n",
            "  server_1: 0/50 (0.0%) Errors: 0\n",
            "  server_2: 0/75 (0.0%) Errors: 0\n",
            "  server_3: 1/100 (1.0%) Errors: 1\n",
            "  server_4: 2/25 (8.0%) Errors: 2\n",
            "\n",
            "==================== Testing Least Connections Strategy ====================\n",
            "Request 4 → server_1 (load: 1)\n",
            "Request 7 failed: Internal server error\n",
            "Request 0 → server_1 (load: 2)\n",
            "Request 3 → server_4 (load: 2)\n",
            "Request 1 → server_2 (load: 2)\n",
            "Request 15 → server_1 (load: 3)\n",
            "Request 17 → server_2 (load: 3)\n",
            "Request 14 → server_4 (load: 2)\n",
            "Request 13 → server_4 (load: 2)\n",
            "Request 11 → server_3 (load: 2)\n",
            "Request 2 → server_3 (load: 2)\n",
            "Request 8 → server_4 (load: 1)\n",
            "Request 5 → server_2 (load: 3)\n",
            "Request 9 → server_1 (load: 3)\n",
            "Request 12 → server_1 (load: 2)\n",
            "Request 10 → server_2 (load: 2)\n",
            "Request 18 → server_1 (load: 1)\n",
            "Request 6 → server_1 (load: 0)\n",
            "Request 24 → server_1 (load: 0)\n",
            "Request 16 → server_2 (load: 1)\n",
            "Request 20 → server_4 (load: 1)\n",
            "Request 19 → server_2 (load: 0)\n",
            "Request 21 → server_3 (load: 2)\n",
            "Request 23 → server_3 (load: 1)\n",
            "Request 22 → server_4 (load: 0)\n",
            "\n",
            "Least Connections Results:\n",
            "  Healthy: 4/4\n",
            "  Total Requests: 25\n",
            "  Error Rate: 4.00%\n",
            "  server_1: 0/50 (0.0%) Errors: 0\n",
            "  server_2: 0/75 (0.0%) Errors: 0\n",
            "  server_3: 1/100 (1.0%) Errors: 1\n",
            "  server_4: 0/25 (0.0%) Errors: 0\n",
            "\n",
            "==================== Testing Weighted Round Robin Strategy ====================\n",
            "Request 1 → server_1 (load: 1)\n",
            "Request 3 → server_1 (load: 1)\n",
            "Request 0 → server_1 (load: 0)\n",
            "Request 6 → server_4 (load: 0)\n",
            "Request 8 → server_1 (load: 1)\n",
            "Request 11 → server_2 (load: 3)\n",
            "Request 4 → server_2 (load: 2)\n",
            "Request 9 → server_2 (load: 1)\n",
            "Request 2 → server_2 (load: 0)\n",
            "Request 5 → server_3 (load: 1)\n",
            "Request 7 → server_1 (load: 4)\n",
            "Request 12 failed: Internal server error\n",
            "Request 15 → server_1 (load: 3)\n",
            "Request 10 → server_1 (load: 4)\n",
            "Request 21 → server_1 (load: 3)\n",
            "Request 14 → server_1 (load: 3)\n",
            "Request 13 failed: Internal server error\n",
            "Request 16 failed: Internal server error\n",
            "Request 22 → server_1 (load: 2)\n",
            "Request 18 → server_2 (load: 2)\n",
            "Request 17 → server_1 (load: 1)\n",
            "Request 24 → server_1 (load: 0)\n",
            "Request 20 → server_4 (load: 1)\n",
            "Request 19 → server_3 (load: 1)\n",
            "Request 23 → server_2 (load: 1)\n",
            "\n",
            "Weighted Round Robin Results:\n",
            "  Healthy: 4/4\n",
            "  Total Requests: 25\n",
            "  Error Rate: 12.00%\n",
            "  server_1: 0/50 (0.0%) Errors: 0\n",
            "  server_2: 1/75 (1.3%) Errors: 1\n",
            "  server_3: 1/100 (1.0%) Errors: 1\n",
            "  server_4: 1/25 (4.0%) Errors: 1\n",
            "\n",
            "==================== Testing Random Strategy ====================\n",
            "Request 4 → server_4 (load: 0)\n",
            "Request 2 → server_2 (load: 2)\n",
            "Request 3 → server_2 (load: 1)\n",
            "Request 8 → server_3 (load: 4)\n",
            "Request 0 → server_3 (load: 3)\n",
            "Request 1 → server_1 (load: 2)\n",
            "Request 5 → server_2 (load: 1)\n",
            "Request 13 → server_4 (load: 0)\n",
            "Request 6 → server_3 (load: 2)\n",
            "Request 12 → server_1 (load: 2)\n",
            "Request 17 → server_2 (load: 3)\n",
            "Request 7 → server_3 (load: 1)\n",
            "Request 16 → server_2 (load: 3)\n",
            "Request 9 → server_1 (load: 2)\n",
            "Request 14 → server_1 (load: 1)\n",
            "Request 11 → server_2 (load: 3)\n",
            "Request 19 → server_2 (load: 2)\n",
            "Request 22 → server_1 (load: 2)\n",
            "Request 10 → server_3 (load: 1)\n",
            "Request 15 → server_2 (load: 1)\n",
            "Request 18 → server_2 (load: 0)\n",
            "Request 23 → server_1 (load: 1)\n",
            "Request 21 → server_3 (load: 0)\n",
            "Request 20 → server_1 (load: 0)\n",
            "Request 24 → server_4 (load: 0)\n",
            "\n",
            "Random Results:\n",
            "  Healthy: 4/4\n",
            "  Total Requests: 25\n",
            "  Error Rate: 0.00%\n",
            "  server_1: 0/50 (0.0%) Errors: 0\n",
            "  server_2: 0/75 (0.0%) Errors: 0\n",
            "  server_3: 0/100 (0.0%) Errors: 0\n",
            "  server_4: 0/25 (0.0%) Errors: 0\n",
            "\n",
            "All strategies tested!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 10: Caching Strategies\n",
        "Objective: Implement and compare different caching strategies.\n",
        "Problem Statement: Create a caching system with LRU, LFU, and TTL eviction policies.\n"
      ],
      "metadata": {
        "id": "fCG51eMI394s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Any, Dict, Optional\n",
        "from collections import OrderedDict, defaultdict\n",
        "import threading\n",
        "\n",
        "\n",
        "class Cache(ABC):\n",
        "    @abstractmethod\n",
        "    def get(self, key: str) -> Optional[Any]:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def put(self, key: str, value: Any, ttl: Optional[int] = None):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def delete(self, key: str) -> bool:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def clear(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def size(self) -> int:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_stats(self) -> Dict:\n",
        "        pass\n",
        "\n",
        "\n",
        "class LRUCache(Cache):\n",
        "    \"\"\"Least Recently Used cache implementation\"\"\"\n",
        "\n",
        "    def __init__(self, capacity: int):\n",
        "        self.capacity = capacity\n",
        "        self.cache = OrderedDict()\n",
        "        self.hits = 0\n",
        "        self.misses = 0\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def get(self, key: str) -> Optional[Any]:\n",
        "        with self.lock:\n",
        "            if key not in self.cache:\n",
        "                self.misses += 1\n",
        "                return None\n",
        "\n",
        "            # Move to end (most recently used)\n",
        "            value = self.cache.pop(key)\n",
        "            self.cache[key] = value\n",
        "            self.hits += 1\n",
        "            return value\n",
        "\n",
        "    def put(self, key: str, value: Any, ttl: Optional[int] = None):\n",
        "        with self.lock:\n",
        "            if key in self.cache:\n",
        "                # Remove existing key to update order\n",
        "                self.cache.pop(key)\n",
        "            elif len(self.cache) >= self.capacity:\n",
        "                # Remove least recently used item\n",
        "                self.cache.popitem(last=False)\n",
        "\n",
        "            self.cache[key] = value\n",
        "\n",
        "    def delete(self, key: str) -> bool:\n",
        "        with self.lock:\n",
        "            if key in self.cache:\n",
        "                self.cache.pop(key)\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "    def clear(self):\n",
        "        with self.lock:\n",
        "            self.cache.clear()\n",
        "            self.hits = 0\n",
        "            self.misses = 0\n",
        "\n",
        "    def size(self) -> int:\n",
        "        return len(self.cache)\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        total = self.hits + self.misses\n",
        "        hit_ratio = self.hits / total if total > 0 else 0.0\n",
        "\n",
        "        return {\n",
        "            \"type\": \"LRU\",\n",
        "            \"capacity\": self.capacity,\n",
        "            \"size\": self.size(),\n",
        "            \"hits\": self.hits,\n",
        "            \"misses\": self.misses,\n",
        "            \"hit_ratio\": hit_ratio,\n",
        "            \"items\": list(self.cache.keys()),\n",
        "        }\n",
        "\n",
        "\n",
        "class LFUCache(Cache):\n",
        "    \"\"\"Least Frequently Used cache implementation\"\"\"\n",
        "\n",
        "    def __init__(self, capacity: int):\n",
        "        self.capacity = capacity\n",
        "        # key -> (value, frequency)\n",
        "        self.cache: Dict[str, tuple] = {}\n",
        "        # frequency -> OrderedDict of keys (to preserve recency among same-frequency)\n",
        "        self.frequency_dict: Dict[int, OrderedDict] = defaultdict(OrderedDict)\n",
        "        self.min_frequency = 0\n",
        "        self.hits = 0\n",
        "        self.misses = 0\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def _remove_from_freq_bucket(self, key: str, frequency: int):\n",
        "        bucket = self.frequency_dict.get(frequency)\n",
        "        if bucket and key in bucket:\n",
        "            del bucket[key]\n",
        "            if not bucket:\n",
        "                # keep the mapping but it will be empty dict; we may clean min_frequency elsewhere\n",
        "                self.frequency_dict.pop(frequency, None)\n",
        "\n",
        "    def get(self, key: str) -> Optional[Any]:\n",
        "        with self.lock:\n",
        "            if key not in self.cache:\n",
        "                self.misses += 1\n",
        "                return None\n",
        "\n",
        "            value, frequency = self.cache[key]\n",
        "\n",
        "            # Remove from current frequency bucket\n",
        "            self._remove_from_freq_bucket(key, frequency)\n",
        "\n",
        "            # Increase frequency\n",
        "            new_frequency = frequency + 1\n",
        "            self.cache[key] = (value, new_frequency)\n",
        "            self.frequency_dict[new_frequency][key] = None\n",
        "\n",
        "            # If the old frequency was the min and its bucket is now empty, update min_frequency\n",
        "            if frequency == self.min_frequency and frequency not in self.frequency_dict:\n",
        "                # find next min frequency\n",
        "                if self.frequency_dict:\n",
        "                    self.min_frequency = min(self.frequency_dict.keys())\n",
        "                else:\n",
        "                    self.min_frequency = new_frequency\n",
        "\n",
        "            self.hits += 1\n",
        "            return value\n",
        "\n",
        "    def put(self, key: str, value: Any, ttl: Optional[int] = None):\n",
        "        with self.lock:\n",
        "            if self.capacity == 0:\n",
        "                return\n",
        "\n",
        "            if key in self.cache:\n",
        "                # Update existing key: increase frequency and update value\n",
        "                _, frequency = self.cache[key]\n",
        "                self._remove_from_freq_bucket(key, frequency)\n",
        "                new_frequency = frequency + 1\n",
        "                self.cache[key] = (value, new_frequency)\n",
        "                self.frequency_dict[new_frequency][key] = None\n",
        "\n",
        "                if frequency == self.min_frequency and frequency not in self.frequency_dict:\n",
        "                    if self.frequency_dict:\n",
        "                        self.min_frequency = min(self.frequency_dict.keys())\n",
        "                    else:\n",
        "                        self.min_frequency = new_frequency\n",
        "                return\n",
        "\n",
        "            # If capacity reached, evict least frequently used (and least recently used among them)\n",
        "            if len(self.cache) >= self.capacity:\n",
        "                # Ensure min_frequency points to a non-empty bucket\n",
        "                if self.min_frequency not in self.frequency_dict or not self.frequency_dict[self.min_frequency]:\n",
        "                    # recalc min_frequency\n",
        "                    if self.frequency_dict:\n",
        "                        self.min_frequency = min(self.frequency_dict.keys())\n",
        "                    else:\n",
        "                        self.min_frequency = 0\n",
        "\n",
        "                # pop the oldest key in min_frequency bucket\n",
        "                lfu_bucket = self.frequency_dict.get(self.min_frequency)\n",
        "                if lfu_bucket:\n",
        "                    lfu_key, _ = lfu_bucket.popitem(last=False)\n",
        "                    self.cache.pop(lfu_key, None)\n",
        "                    if not lfu_bucket:\n",
        "                        self.frequency_dict.pop(self.min_frequency, None)\n",
        "\n",
        "            # Add new item with frequency 1\n",
        "            self.cache[key] = (value, 1)\n",
        "            self.frequency_dict[1][key] = None\n",
        "            self.min_frequency = 1\n",
        "\n",
        "    def delete(self, key: str) -> bool:\n",
        "        with self.lock:\n",
        "            if key not in self.cache:\n",
        "                return False\n",
        "\n",
        "            _, frequency = self.cache[key]\n",
        "            del self.cache[key]\n",
        "            self._remove_from_freq_bucket(key, frequency)\n",
        "\n",
        "            # Update min_frequency if needed\n",
        "            if frequency == self.min_frequency and self.min_frequency not in self.frequency_dict:\n",
        "                if self.frequency_dict:\n",
        "                    self.min_frequency = min(self.frequency_dict.keys())\n",
        "                else:\n",
        "                    self.min_frequency = 0\n",
        "\n",
        "            return True\n",
        "\n",
        "    def clear(self):\n",
        "        with self.lock:\n",
        "            self.cache.clear()\n",
        "            self.frequency_dict.clear()\n",
        "            self.min_frequency = 0\n",
        "            self.hits = 0\n",
        "            self.misses = 0\n",
        "\n",
        "    def size(self) -> int:\n",
        "        return len(self.cache)\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        total = self.hits + self.misses\n",
        "        hit_ratio = self.hits / total if total > 0 else 0.0\n",
        "\n",
        "        frequency_distribution = {}\n",
        "        for freq, keys in self.frequency_dict.items():\n",
        "            frequency_distribution[freq] = len(keys)\n",
        "\n",
        "        return {\n",
        "            \"type\": \"LFU\",\n",
        "            \"capacity\": self.capacity,\n",
        "            \"size\": self.size(),\n",
        "            \"hits\": self.hits,\n",
        "            \"misses\": self.misses,\n",
        "            \"hit_ratio\": hit_ratio,\n",
        "            \"min_frequency\": self.min_frequency,\n",
        "            \"frequency_distribution\": frequency_distribution,\n",
        "            \"items\": list(self.cache.keys()),\n",
        "        }\n",
        "\n",
        "\n",
        "class TTLCache(Cache):\n",
        "    \"\"\"Time-to-Live cache implementation\"\"\"\n",
        "\n",
        "    def __init__(self, capacity: int, default_ttl: int = 300):  # default 5 minutes\n",
        "        self.capacity = capacity\n",
        "        self.default_ttl = default_ttl\n",
        "        # key -> (value, expiry_time)\n",
        "        self.cache = OrderedDict()\n",
        "        self.hits = 0\n",
        "        self.misses = 0\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def _is_expired(self, key: str) -> bool:\n",
        "        \"\"\"Check if key has expired\"\"\"\n",
        "        if key not in self.cache:\n",
        "            return True\n",
        "\n",
        "        _, expiry_time = self.cache[key]\n",
        "        return time.time() > expiry_time\n",
        "\n",
        "    def _cleanup_expired(self):\n",
        "        \"\"\"Remove expired entries\"\"\"\n",
        "        current_time = time.time()\n",
        "        expired_keys = [key for key, (_, expiry) in list(self.cache.items()) if expiry <= current_time]\n",
        "        for key in expired_keys:\n",
        "            del self.cache[key]\n",
        "\n",
        "    def get(self, key: str) -> Optional[Any]:\n",
        "        with self.lock:\n",
        "            self._cleanup_expired()\n",
        "\n",
        "            if key not in self.cache or self._is_expired(key):\n",
        "                self.misses += 1\n",
        "                if key in self.cache:\n",
        "                    del self.cache[key]  # remove expired entry\n",
        "                return None\n",
        "\n",
        "            value, expiry = self.cache.pop(key)\n",
        "            # Re-insert to update order (LRU behavior for non-expired items)\n",
        "            self.cache[key] = (value, expiry)\n",
        "            self.hits += 1\n",
        "            return value\n",
        "\n",
        "    def put(self, key: str, value: Any, ttl: Optional[int] = None):\n",
        "        with self.lock:\n",
        "            self._cleanup_expired()\n",
        "\n",
        "            if ttl is None:\n",
        "                ttl = self.default_ttl\n",
        "\n",
        "            expiry_time = time.time() + ttl\n",
        "\n",
        "            if key in self.cache:\n",
        "                # Remove existing key to update order\n",
        "                del self.cache[key]\n",
        "            elif len(self.cache) >= self.capacity:\n",
        "                # Remove least recently used non-expired item\n",
        "                # ensure we pop a non-expired item; cleanup already done so pop is fine\n",
        "                try:\n",
        "                    self.cache.popitem(last=False)\n",
        "                except KeyError:\n",
        "                    # nothing to pop\n",
        "                    pass\n",
        "\n",
        "            self.cache[key] = (value, expiry_time)\n",
        "\n",
        "    def delete(self, key: str) -> bool:\n",
        "        with self.lock:\n",
        "            if key in self.cache:\n",
        "                del self.cache[key]\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "    def clear(self):\n",
        "        with self.lock:\n",
        "            self.cache.clear()\n",
        "            self.hits = 0\n",
        "            self.misses = 0\n",
        "\n",
        "    def size(self) -> int:\n",
        "        with self.lock:\n",
        "            self._cleanup_expired()\n",
        "            return len(self.cache)\n",
        "\n",
        "    def get_expired_count(self) -> int:\n",
        "        \"\"\"Get count of expired but not yet cleaned up entries\"\"\"\n",
        "        with self.lock:\n",
        "            current_time = time.time()\n",
        "            return sum(1 for _, expiry in self.cache.values() if expiry <= current_time)\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        with self.lock:\n",
        "            self._cleanup_expired()\n",
        "\n",
        "            total = self.hits + self.misses\n",
        "            hit_ratio = self.hits / total if total > 0 else 0.0\n",
        "\n",
        "            # Calculate TTL distribution\n",
        "            current_time = time.time()\n",
        "            ttl_distribution = {\"<1min\": 0, \"1-5min\": 0, \"5-15min\": 0, \">15min\": 0}\n",
        "\n",
        "            for _, expiry in self.cache.values():\n",
        "                ttl_remaining = expiry - current_time\n",
        "                if ttl_remaining < 60:\n",
        "                    ttl_distribution[\"<1min\"] += 1\n",
        "                elif ttl_remaining < 300:\n",
        "                    ttl_distribution[\"1-5min\"] += 1\n",
        "                elif ttl_remaining < 900:\n",
        "                    ttl_distribution[\"5-15min\"] += 1\n",
        "                else:\n",
        "                    ttl_distribution[\">15min\"] += 1\n",
        "\n",
        "            return {\n",
        "                \"type\": \"TTL\",\n",
        "                \"capacity\": self.capacity,\n",
        "                \"size\": self.size(),\n",
        "                \"hits\": self.hits,\n",
        "                \"misses\": self.misses,\n",
        "                \"hit_ratio\": hit_ratio,\n",
        "                \"default_ttl\": self.default_ttl,\n",
        "                \"ttl_distribution\": ttl_distribution,\n",
        "                \"expired_count\": self.get_expired_count(),\n",
        "                \"items\": list(self.cache.keys()),\n",
        "            }\n",
        "\n",
        "\n",
        "class CacheManager:\n",
        "    \"\"\"Manager to test and compare different caching strategies\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.caches: Dict[str, Cache] = {}\n",
        "\n",
        "    def add_cache(self, name: str, cache: Cache):\n",
        "        self.caches[name] = cache\n",
        "\n",
        "    def benchmark_cache(self, cache: Cache, operations: int) -> Dict:\n",
        "        \"\"\"Benchmark cache performance with simulated workload\"\"\"\n",
        "        # Warm up cache (if cache has capacity attribute)\n",
        "        try:\n",
        "            warm = min(operations // 2, cache.capacity)\n",
        "        except Exception:\n",
        "            warm = min(operations // 2, 100)\n",
        "\n",
        "        for i in range(warm):\n",
        "            # put supports ttl optional parameter, safe for all implementations\n",
        "            cache.put(f\"key_{i}\", f\"value_{i}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Mixed workload: 70% reads, 20% writes, 10% deletes\n",
        "        for i in range(operations):\n",
        "            op_type = random.random()\n",
        "\n",
        "            if op_type < 0.7:  # Read operation\n",
        "                key = f\"key_{random.randint(0, operations // 2)}\"\n",
        "                cache.get(key)\n",
        "            elif op_type < 0.9:  # Write operation\n",
        "                key = f\"key_{random.randint(0, operations // 2)}\"\n",
        "                cache.put(key, f\"value_{i}\")\n",
        "            else:  # Delete operation\n",
        "                key = f\"key_{random.randint(0, operations // 2)}\"\n",
        "                cache.delete(key)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        stats = cache.get_stats()\n",
        "        total_time = end_time - start_time if end_time > start_time else 0.0\n",
        "        stats[\"total_time\"] = total_time\n",
        "        stats[\"operations_per_second\"] = operations / total_time if total_time > 0 else float(\"inf\")\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def compare_caches(self, operations: int = 1000):\n",
        "        \"\"\"Compare performance of all registered caches\"\"\"\n",
        "        print(\"=== Cache Strategy Comparison ===\")\n",
        "        print(f\"Operations: {operations}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        results = []\n",
        "        for name, cache in self.caches.items():\n",
        "            print(f\"Testing {name}...\")\n",
        "\n",
        "            # Clear cache before test\n",
        "            cache.clear()\n",
        "\n",
        "            # Run benchmark\n",
        "            stats = self.benchmark_cache(cache, operations)\n",
        "            results.append((name, stats))\n",
        "\n",
        "            print(f\"Hit Ratio: {stats['hit_ratio']:.3f}\")\n",
        "            print(f\"Operations / sec: {stats['operations_per_second']:.2f}\")\n",
        "            print(f\"Final Size: {stats['size']}/{stats['capacity']}\")\n",
        "            print()\n",
        "\n",
        "        # Print comparison\n",
        "        print(\"=== Results Summary ===\")\n",
        "        print(f\"{'Cache Type':<15} {'Hit Ratio':<12} {'Ops / Sec':<12} {'Size':<10}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        for name, stats in results:\n",
        "            print(\n",
        "                f\"{name:<15} {stats['hit_ratio']:<12.3f} \"\n",
        "                f\"{stats['operations_per_second']:<12.2f} \"\n",
        "                f\"{stats['size']:<10}\"\n",
        "            )\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "if __name__ == \"__main__\":\n",
        "    # Create cache manager\n",
        "    manager = CacheManager()\n",
        "\n",
        "    # Add different cache strategies\n",
        "    manager.add_cache(\"LRU\", LRUCache(capacity=50))\n",
        "    manager.add_cache(\"LFU\", LFUCache(capacity=50))\n",
        "    manager.add_cache(\"TTL\", TTLCache(capacity=50, default_ttl=60))\n",
        "\n",
        "    # Compare performance\n",
        "    manager.compare_caches(operations=1000)\n",
        "\n",
        "    # Demonstrate individual cache usage\n",
        "    print(\"\\n=== Individual Cache Demonstration ===\")\n",
        "\n",
        "    lru_cache = LRUCache(capacity=5)\n",
        "\n",
        "    # Add some items\n",
        "    for i in range(5):\n",
        "        lru_cache.put(f\"item_{i}\", f\"value_{i}\")\n",
        "\n",
        "    print(\"Initial cache state:\")\n",
        "    print(lru_cache.get_stats())\n",
        "\n",
        "    # Access some items to change LRU order\n",
        "    lru_cache.get(\"item_0\")\n",
        "    lru_cache.get(\"item_2\")\n",
        "\n",
        "    # Add new item (should evict least recently used)\n",
        "    lru_cache.put(\"item_5\", \"value_5\")\n",
        "\n",
        "    print(\"\\nAfter accessing items and adding new one:\")\n",
        "    print(lru_cache.get_stats())\n",
        "\n",
        "    # TTL Cache demonstration\n",
        "    print(\"\\n=== TTL Cache Demonstration ===\")\n",
        "    ttl_cache = TTLCache(capacity=5, default_ttl=2)  # 2 second TTL\n",
        "\n",
        "    ttl_cache.put(\"temp_1\", \"value_1\")\n",
        "    ttl_cache.put(\"temp_2\", \"value_2\", ttl=5)  # Custom TTL\n",
        "\n",
        "    print(\"Immediately after adding:\")\n",
        "    print(f\"temp_1: {ttl_cache.get('temp_1')}\")  # Should be there\n",
        "    print(f\"temp_2: {ttl_cache.get('temp_2')}\")  # Should be there\n",
        "\n",
        "    print(\"\\nAfter 3 seconds:\")\n",
        "    time.sleep(3)\n",
        "    print(f\"temp_1: {ttl_cache.get('temp_1')}\")  # Should be expired\n",
        "    print(f\"temp_2: {ttl_cache.get('temp_2')}\")  # Should still be there\n",
        "\n",
        "    print(\"\\nTTL Cache stats:\")\n",
        "    print(ttl_cache.get_stats())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "dQx_Ozn54nAC",
        "outputId": "6d713215-e098-4e0e-8d46-a68ff87c0a83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Cache Strategy Comparison ===\n",
            "Operations: 1000\n",
            "------------------------------------------------------------\n",
            "Testing LRU...\n",
            "Hit Ratio: 0.127\n",
            "Operations / sec: 712347.83\n",
            "Final Size: 50/50\n",
            "\n",
            "Testing LFU...\n",
            "Hit Ratio: 0.117\n",
            "Operations / sec: 639180.74\n",
            "Final Size: 50/50\n",
            "\n",
            "Testing TTL...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-207208324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;31m# Compare performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_caches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Demonstrate individual cache usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-207208324.py\u001b[0m in \u001b[0;36mcompare_caches\u001b[0;34m(self, operations)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# Run benchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-207208324.py\u001b[0m in \u001b[0;36mbenchmark_cache\u001b[0;34m(self, cache, operations)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total_time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-207208324.py\u001b[0m in \u001b[0;36mget_stats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"TTL\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;34m\"capacity\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0;34m\"size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m                 \u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;34m\"misses\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-207208324.py\u001b[0m in \u001b[0;36msize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cleanup_expired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11: Database Sharding\n",
        "Objective: Implement database sharding for horizontal scaling.\n",
        "Problem Statement: Create a sharded database system that distributes data across multiple nodes"
      ],
      "metadata": {
        "id": "isklHqcT5cll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import threading\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, List, Optional, Any\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "class Shard(ABC):\n",
        "    @abstractmethod\n",
        "    def connect(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def insert(self, key: str, data: Dict) -> bool:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get(self, key: str) -> Optional[Dict]:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def update(self, key: str, data: Dict) -> bool:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def delete(self, key: str) -> bool:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_stats(self) -> Dict:\n",
        "        pass\n",
        "\n",
        "class InMemoryShard(Shard):\n",
        "    \"\"\"In-memory implementation of a database shard\"\"\"\n",
        "\n",
        "    def __init__(self, shard_id: str):\n",
        "        self.shard_id = shard_id\n",
        "        self.data = {}\n",
        "        self.operation_count = 0\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def connect(self):\n",
        "        print(f\"Connected to shard {self.shard_id}\")\n",
        "\n",
        "    def insert(self, key: str, data: Dict) -> bool:\n",
        "        with self.lock:\n",
        "            if key in self.data:\n",
        "                return False\n",
        "\n",
        "            data['_shard_id'] = self.shard_id\n",
        "            data['_created_at'] = datetime.now().isoformat()\n",
        "            data['_updated_at'] = datetime.now().isoformat()\n",
        "\n",
        "            self.data[key] = data\n",
        "            self.operation_count += 1\n",
        "            return True\n",
        "\n",
        "    def get(self, key: str) -> Optional[Dict]:\n",
        "        with self.lock:\n",
        "            if key in self.data:\n",
        "                self.operation_count += 1\n",
        "                return self.data[key].copy()\n",
        "            return None\n",
        "\n",
        "    def update(self, key: str, data: Dict) -> bool:\n",
        "        with self.lock:\n",
        "            if key not in self.data:\n",
        "                return False\n",
        "\n",
        "            # Preserve metadata and update only provided fields\n",
        "            existing_data = self.data[key].copy()\n",
        "            existing_data.update(data)\n",
        "            # Re-set metadata to avoid overwriting\n",
        "            existing_data['_shard_id'] = self.data[key]['_shard_id']\n",
        "            existing_data['_created_at'] = self.data[key]['_created_at']\n",
        "            existing_data['_updated_at'] = datetime.now().isoformat()\n",
        "\n",
        "            self.data[key] = existing_data\n",
        "            self.operation_count += 1\n",
        "            return True\n",
        "\n",
        "    def delete(self, key: str) -> bool:\n",
        "        with self.lock:\n",
        "            if key in self.data:\n",
        "                del self.data[key]\n",
        "                self.operation_count += 1\n",
        "                return True\n",
        "            return False\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        with self.lock:\n",
        "            return {\n",
        "                'shard_id': self.shard_id,\n",
        "                'record_count': len(self.data),\n",
        "                'operation_count': self.operation_count,\n",
        "                'memory_usage_estimate': len(str(self.data))  # Rough estimate\n",
        "            }\n",
        "\n",
        "class ShardingStrategy(ABC):\n",
        "    @abstractmethod\n",
        "    def get_shard_id(self, key: str, total_shards: int) -> str:\n",
        "        pass\n",
        "\n",
        "class HashShardingStrategy(ShardingStrategy):\n",
        "    \"\"\"Hash-based sharding strategy\"\"\"\n",
        "\n",
        "    def get_shard_id(self, key: str, total_shards: int) -> str:\n",
        "        hash_value = int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
        "        shard_index = hash_value % total_shards\n",
        "        return f\"shard_{shard_index}\"\n",
        "\n",
        "class RangeShardingStrategy(ShardingStrategy):\n",
        "    \"\"\"Range-based sharding strategy\"\"\"\n",
        "\n",
        "    def __init__(self, ranges: List[tuple]):\n",
        "        \"\"\"\n",
        "        ranges: List of tuples (start_key, end_key, shard_id)\n",
        "        \"\"\"\n",
        "        self.ranges = sorted(ranges, key=lambda x: x[0])\n",
        "\n",
        "    def get_shard_id(self, key: str, total_shards: int) -> str:\n",
        "        # For simplicity, assume numeric keys for range sharding\n",
        "        try:\n",
        "            key_num = int(key)\n",
        "            for start, end, shard_id in self.ranges:\n",
        "                if start <= key_num <= end:\n",
        "                    return shard_id\n",
        "        except ValueError:\n",
        "            # Fallback to hash if key is not numeric\n",
        "            hash_strategy = HashShardingStrategy()\n",
        "            return hash_strategy.get_shard_id(key, total_shards)\n",
        "\n",
        "        # Default to first shard if no range matches (safe for empty ranges)\n",
        "        return self.ranges[0][2] if self.ranges else \"shard_0\"\n",
        "\n",
        "class DirectoryShardingStrategy(ShardingStrategy):\n",
        "    \"\"\"Directory-based sharding strategy\"\"\"\n",
        "\n",
        "    def __init__(self, mapping: Dict[str, str]):\n",
        "        self.mapping = mapping\n",
        "\n",
        "    def get_shard_id(self, key: str, total_shards: int) -> str:\n",
        "        return self.mapping.get(key, \"shard_0\")\n",
        "\n",
        "class ShardedDatabase:\n",
        "    \"\"\"Main sharded database system\"\"\"\n",
        "\n",
        "    def __init__(self, sharding_strategy: ShardingStrategy, num_shards: int = 4):\n",
        "        self.sharding_strategy = sharding_strategy\n",
        "        self.num_shards = num_shards\n",
        "        self.shards: Dict[str, Shard] = {}\n",
        "        self.setup_shards()\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "        # Statistics\n",
        "        self.operations = {\n",
        "            'insert': 0,\n",
        "            'get': 0,\n",
        "            'update': 0,\n",
        "            'delete': 0,\n",
        "            'errors': 0\n",
        "        }\n",
        "\n",
        "    def setup_shards(self):\n",
        "        \"\"\"Initialize all shards\"\"\"\n",
        "        for i in range(self.num_shards):\n",
        "            shard_id = f\"shard_{i}\"\n",
        "            self.shards[shard_id] = InMemoryShard(shard_id)\n",
        "            self.shards[shard_id].connect()\n",
        "\n",
        "    def get_shard_for_key(self, key: str) -> Shard:\n",
        "        \"\"\"Determine which shard should handle the given key\"\"\"\n",
        "        shard_id = self.sharding_strategy.get_shard_id(key, self.num_shards)\n",
        "        return self.shards[shard_id]\n",
        "\n",
        "    def insert(self, key: str, data: Dict) -> bool:\n",
        "        \"\"\"Insert data into appropriate shard\"\"\"\n",
        "        try:\n",
        "            shard = self.get_shard_for_key(key)\n",
        "            success = shard.insert(key, data)\n",
        "\n",
        "            with self.lock:\n",
        "                self.operations['insert'] += 1\n",
        "                if not success:\n",
        "                    self.operations['errors'] += 1\n",
        "\n",
        "            return success\n",
        "\n",
        "        except Exception as e:\n",
        "            with self.lock:\n",
        "                self.operations['errors'] += 1\n",
        "            print(f\"Insert error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get(self, key: str) -> Optional[Dict]:\n",
        "        \"\"\"Retrieve data from appropriate shard\"\"\"\n",
        "        try:\n",
        "            shard = self.get_shard_for_key(key)\n",
        "            result = shard.get(key)\n",
        "\n",
        "            with self.lock:\n",
        "                self.operations['get'] += 1\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            with self.lock:\n",
        "                self.operations['errors'] += 1\n",
        "            print(f\"Get error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def update(self, key: str, data: Dict) -> bool:\n",
        "        \"\"\"Update data in appropriate shard\"\"\"\n",
        "        try:\n",
        "            shard = self.get_shard_for_key(key)\n",
        "            success = shard.update(key, data)\n",
        "\n",
        "            with self.lock:\n",
        "                self.operations['update'] += 1\n",
        "                if not success:\n",
        "                    self.operations['errors'] += 1\n",
        "\n",
        "            return success\n",
        "\n",
        "        except Exception as e:\n",
        "            with self.lock:\n",
        "                self.operations['errors'] += 1\n",
        "            print(f\"Update error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def delete(self, key: str) -> bool:\n",
        "        \"\"\"Delete data from appropriate shard\"\"\"\n",
        "        try:\n",
        "            shard = self.get_shard_for_key(key)\n",
        "            success = shard.delete(key)\n",
        "\n",
        "            with self.lock:\n",
        "                self.operations['delete'] += 1\n",
        "                if not success:\n",
        "                    self.operations['errors'] += 1\n",
        "\n",
        "            return success\n",
        "\n",
        "        except Exception as e:\n",
        "            with self.lock:\n",
        "                self.operations['errors'] += 1\n",
        "            print(f\"Delete error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_database_stats(self) -> Dict:\n",
        "        \"\"\"Get comprehensive database statistics\"\"\"\n",
        "        shard_stats = {}\n",
        "        total_records = 0\n",
        "        total_operations = 0\n",
        "\n",
        "        for shard_id, shard in self.shards.items():\n",
        "            stats = shard.get_stats()\n",
        "            shard_stats[shard_id] = stats\n",
        "            total_records += stats['record_count']\n",
        "            total_operations += stats['operation_count']\n",
        "\n",
        "        # Calculate load distribution\n",
        "        load_distribution = {}\n",
        "        for shard_id, stats in shard_stats.items():\n",
        "            load_distribution[shard_id] = {\n",
        "                'record_count': stats['record_count'],\n",
        "                'percentage': (stats['record_count'] / total_records * 100)\n",
        "                if total_records > 0 else 0\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'sharding_strategy': type(self.sharding_strategy).__name__,\n",
        "            'total_shards': self.num_shards,\n",
        "            'total_records': total_records,\n",
        "            'total_operations': total_operations,\n",
        "            'operations': self.operations.copy(),\n",
        "            'load_distribution': load_distribution,\n",
        "            'shard_stats': shard_stats\n",
        "        }\n",
        "\n",
        "    def redistribute_data(self, new_num_shards: int, new_strategy: ShardingStrategy):\n",
        "        \"\"\"Redistribute data when changing sharding configuration\"\"\"\n",
        "        print(f\"Redistributing data from {self.num_shards} to {new_num_shards} shards...\")\n",
        "\n",
        "        # Collect all data\n",
        "        all_data = {}\n",
        "        for shard in self.shards.values():\n",
        "            # This would need proper serialization in real implementation\n",
        "            all_data.update(shard.data)\n",
        "\n",
        "        # Update configuration\n",
        "        self.num_shards = new_num_shards\n",
        "        self.sharding_strategy = new_strategy\n",
        "\n",
        "        # Clear existing shards\n",
        "        self.shards.clear()\n",
        "        self.setup_shards()\n",
        "\n",
        "        # Reinsert all data\n",
        "        for key, data in all_data.items():\n",
        "            self.insert(key, data)\n",
        "\n",
        "        print(\"Data redistribution completed!\")\n",
        "\n",
        "# Demonstration\n",
        "def demonstrate_sharding():\n",
        "    \"\"\"Demonstrate different sharding strategies\"\"\"\n",
        "\n",
        "    print(\"=== Hash-based Sharding ===\")\n",
        "    hash_strategy = HashShardingStrategy()\n",
        "    hash_db = ShardedDatabase(hash_strategy, num_shards=4)\n",
        "\n",
        "    # Insert sample data\n",
        "    for i in range(100):\n",
        "        hash_db.insert(f\"user_{i}\", {\n",
        "            \"name\": f\"User {i}\",\n",
        "            \"email\": f\"user{i}@example.com\",\n",
        "            \"age\": 20 + (i % 40)\n",
        "        })\n",
        "\n",
        "    stats = hash_db.get_database_stats()\n",
        "    print(f\"Total records: {stats['total_records']}\")\n",
        "    print(\"Load distribution:\")\n",
        "    for shard_id, distribution in stats['load_distribution'].items():\n",
        "        print(f\"{shard_id}: {distribution['record_count']} records \"\n",
        "              f\"({distribution['percentage']:.1f}%)\")\n",
        "\n",
        "    print(\"\\n=== Range-based Sharding ===\")\n",
        "    range_strategy = RangeShardingStrategy([\n",
        "        (0, 24, \"shard_0\"),\n",
        "        (25, 49, \"shard_1\"),\n",
        "        (50, 74, \"shard_2\"),\n",
        "        (75, 99, \"shard_3\")\n",
        "    ])\n",
        "    range_db = ShardedDatabase(range_strategy, num_shards=4)\n",
        "\n",
        "    # Insert sample data with numeric keys\n",
        "    for i in range(100):\n",
        "        range_db.insert(str(i), {\n",
        "            \"name\": f\"User {i}\",\n",
        "            \"category\": f\"category_{i // 10}\"\n",
        "        })\n",
        "\n",
        "    range_stats = range_db.get_database_stats()\n",
        "    print(\"Load distribution:\")\n",
        "    for shard_id, distribution in range_stats['load_distribution'].items():\n",
        "        print(f\"{shard_id}: {distribution['record_count']} records \"\n",
        "              f\"({distribution['percentage']:.1f}%)\")\n",
        "\n",
        "    print(\"\\n=== Directory-based Sharding ===\")\n",
        "    # Create mapping for specific users to specific shards\n",
        "    directory_mapping = {}\n",
        "    for i in range(100):\n",
        "        if i % 3 == 0:\n",
        "            directory_mapping[f\"user_{i}\"] = \"shard_0\"\n",
        "        elif i % 3 == 1:\n",
        "            directory_mapping[f\"user_{i}\"] = \"shard_1\"\n",
        "        else:\n",
        "            directory_mapping[f\"user_{i}\"] = \"shard_2\"\n",
        "\n",
        "    directory_strategy = DirectoryShardingStrategy(directory_mapping)\n",
        "    directory_db = ShardedDatabase(directory_strategy, num_shards=3)\n",
        "\n",
        "    for i in range(100):\n",
        "        directory_db.insert(f\"user_{i}\", {\n",
        "            \"name\": f\"User {i}\",\n",
        "            \"preferred_shard\": directory_mapping.get(f\"user_{i}\", \"unknown\")\n",
        "        })\n",
        "\n",
        "    directory_stats = directory_db.get_database_stats()\n",
        "    print(\"Load distribution:\")\n",
        "    for shard_id, distribution in directory_stats['load_distribution'].items():\n",
        "        print(f\"{shard_id}: {distribution['record_count']} records \"\n",
        "              f\"({distribution['percentage']:.1f}%)\")\n",
        "\n",
        "    return hash_db, range_db, directory_db\n",
        "\n",
        "def test_shard_operations(db: ShardedDatabase, db_name: str):\n",
        "    \"\"\"Test basic operations on a sharded database\"\"\"\n",
        "    print(f\"\\n=== Testing {db_name} ===\")\n",
        "\n",
        "    # Test insert and get\n",
        "    test_key = \"test_user_123\"\n",
        "    test_data = {\"name\": \"Test User\", \"email\": \"test@example.com\"}\n",
        "\n",
        "    print(f\"Inserting {test_key}: {db.insert(test_key, test_data)}\")\n",
        "    print(f\"Retrieving {test_key}: {db.get(test_key)}\")\n",
        "\n",
        "    # Test update\n",
        "    updated_data = {\"name\": \"Updated User\", \"email\": \"updated@example.com\"}\n",
        "    print(f\"Updating {test_key}: {db.update(test_key, updated_data)}\")\n",
        "    print(f\"Retrieving updated {test_key}: {db.get(test_key)}\")\n",
        "\n",
        "    # Test delete\n",
        "    print(f\"Deleting {test_key}: {db.delete(test_key)}\")\n",
        "    print(f\"Retrieving deleted {test_key}: {db.get(test_key)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Demonstrate different sharding strategies\n",
        "    hash_db, range_db, directory_db = demonstrate_sharding()\n",
        "\n",
        "    # Test operations on each database\n",
        "    test_shard_operations(hash_db, \"Hash-sharded Database\")\n",
        "    test_shard_operations(range_db, \"Range-sharded Database\")\n",
        "    test_shard_operations(directory_db, \"Directory-sharded Database\")\n",
        "\n",
        "    # Show final statistics\n",
        "    print(\"\\n=== Final Statistics ===\")\n",
        "    for db, name in [(hash_db, \"Hash\"), (range_db, \"Range\"), (directory_db, \"Directory\")]:\n",
        "        stats = db.get_database_stats()\n",
        "        print(f\"\\n{name} Sharding:\")\n",
        "        print(f\"Total Operations: {stats['total_operations']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxZJTkT1yuk-",
        "outputId": "4abb8857-80e5-41a7-fc78-61ee2506df4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Hash-based Sharding ===\n",
            "Connected to shard shard_0\n",
            "Connected to shard shard_1\n",
            "Connected to shard shard_2\n",
            "Connected to shard shard_3\n",
            "Total records: 100\n",
            "Load distribution:\n",
            "shard_0: 28 records (28.0%)\n",
            "shard_1: 24 records (24.0%)\n",
            "shard_2: 29 records (29.0%)\n",
            "shard_3: 19 records (19.0%)\n",
            "\n",
            "=== Range-based Sharding ===\n",
            "Connected to shard shard_0\n",
            "Connected to shard shard_1\n",
            "Connected to shard shard_2\n",
            "Connected to shard shard_3\n",
            "Load distribution:\n",
            "shard_0: 25 records (25.0%)\n",
            "shard_1: 25 records (25.0%)\n",
            "shard_2: 25 records (25.0%)\n",
            "shard_3: 25 records (25.0%)\n",
            "\n",
            "=== Directory-based Sharding ===\n",
            "Connected to shard shard_0\n",
            "Connected to shard shard_1\n",
            "Connected to shard shard_2\n",
            "Load distribution:\n",
            "shard_0: 34 records (34.0%)\n",
            "shard_1: 33 records (33.0%)\n",
            "shard_2: 33 records (33.0%)\n",
            "\n",
            "=== Testing Hash-sharded Database ===\n",
            "Inserting test_user_123: True\n",
            "Retrieving test_user_123: {'name': 'Test User', 'email': 'test@example.com', '_shard_id': 'shard_0', '_created_at': '2025-11-19T06:49:22.448282', '_updated_at': '2025-11-19T06:49:22.448291'}\n",
            "Updating test_user_123: True\n",
            "Retrieving updated test_user_123: {'name': 'Updated User', 'email': 'updated@example.com', '_shard_id': 'shard_0', '_created_at': '2025-11-19T06:49:22.448282', '_updated_at': '2025-11-19T06:49:22.448358'}\n",
            "Deleting test_user_123: True\n",
            "Retrieving deleted test_user_123: None\n",
            "\n",
            "=== Testing Range-sharded Database ===\n",
            "Inserting test_user_123: True\n",
            "Retrieving test_user_123: {'name': 'Test User', 'email': 'test@example.com', '_shard_id': 'shard_0', '_created_at': '2025-11-19T06:49:22.448450', '_updated_at': '2025-11-19T06:49:22.448455'}\n",
            "Updating test_user_123: True\n",
            "Retrieving updated test_user_123: {'name': 'Updated User', 'email': 'updated@example.com', '_shard_id': 'shard_0', '_created_at': '2025-11-19T06:49:22.448450', '_updated_at': '2025-11-19T06:49:22.448498'}\n",
            "Deleting test_user_123: True\n",
            "Retrieving deleted test_user_123: None\n",
            "\n",
            "=== Testing Directory-sharded Database ===\n",
            "Inserting test_user_123: True\n",
            "Retrieving test_user_123: {'name': 'Test User', 'email': 'test@example.com', '_shard_id': 'shard_0', '_created_at': '2025-11-19T06:49:22.448571', '_updated_at': '2025-11-19T06:49:22.448575'}\n",
            "Updating test_user_123: True\n",
            "Retrieving updated test_user_123: {'name': 'Updated User', 'email': 'updated@example.com', '_shard_id': 'shard_0', '_created_at': '2025-11-19T06:49:22.448571', '_updated_at': '2025-11-19T06:49:22.448598'}\n",
            "Deleting test_user_123: True\n",
            "Retrieving deleted test_user_123: None\n",
            "\n",
            "=== Final Statistics ===\n",
            "\n",
            "Hash Sharding:\n",
            "Total Operations: 105\n",
            "\n",
            "Range Sharding:\n",
            "Total Operations: 105\n",
            "\n",
            "Directory Sharding:\n",
            "Total Operations: 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lab 12: Message Queue System\n",
        "Objective: Implement a basic message queue system with publishers and subscribers.\n",
        "Problem Statement: Create a message queue that supports topics, persistence, and multiple consumers."
      ],
      "metadata": {
        "id": "5vjupzcp7Zrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import json\n",
        "import uuid\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, List, Callable, Optional\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, deque\n",
        "import heapq\n",
        "\n",
        "class Message:\n",
        "    def __init__(self, topic: str, payload: Dict, priority: int = 0):\n",
        "        self.id = str(uuid.uuid4())\n",
        "        self.topic = topic\n",
        "        self.payload = payload\n",
        "        self.priority = priority\n",
        "        self.timestamp = datetime.now()\n",
        "        self.delivery_attempts = 0\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        return {\n",
        "            'id': self.id,\n",
        "            'topic': self.topic,\n",
        "            'payload': self.payload,\n",
        "            'priority': self.priority,\n",
        "            'timestamp': self.timestamp.isoformat(),\n",
        "            'delivery_attempts': self.delivery_attempts\n",
        "        }\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        # Higher priority messages come first\n",
        "        return self.priority > other.priority\n",
        "\n",
        "class MessageQueue(ABC):\n",
        "    @abstractmethod\n",
        "    def publish(self, topic: str, message: Dict, priority: int = 0) -> str:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def subscribe(self, topic: str, callback: Callable) -> str:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def unsubscribe(self, subscription_id: str):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_stats(self) -> Dict:\n",
        "        pass\n",
        "\n",
        "class InMemoryMessageQueue(MessageQueue):\n",
        "    def __init__(self, max_queue_size: int = 10000):\n",
        "        self.queues: Dict[str, List] = {}  # topic -> priority queue\n",
        "        self.subscribers: Dict[str, List[tuple]] = defaultdict(list)  # topic -> [(sub_id, callback)]\n",
        "        self.dead_letter_queues: Dict[str, List] = defaultdict(list)\n",
        "        self.max_queue_size = max_queue_size\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "        # Statistics\n",
        "        self.stats = {\n",
        "            'messages_published': 0,\n",
        "            'messages_delivered': 0,\n",
        "            'messages_failed': 0,\n",
        "            'subscriptions_created': 0,\n",
        "            'subscriptions_removed': 0\n",
        "        }\n",
        "\n",
        "        # Start message processor\n",
        "        self.is_running = True\n",
        "        self.processor_thread = threading.Thread(target=self._process_messages)\n",
        "        self.processor_thread.daemon = True\n",
        "        self.processor_thread.start()\n",
        "\n",
        "    def publish(self, topic: str, message: Dict, priority: int = 0) -> str:\n",
        "        msg = Message(topic, message, priority)\n",
        "\n",
        "        with self.lock:\n",
        "            if topic not in self.queues:\n",
        "                self.queues[topic] = []\n",
        "\n",
        "            # Check queue size limit\n",
        "            if len(self.queues[topic]) >= self.max_queue_size:\n",
        "                # Remove lowest priority message\n",
        "                if self.queues[topic]:\n",
        "                    heapq.heappop(self.queues[topic])\n",
        "\n",
        "            heapq.heappush(self.queues[topic], msg)\n",
        "            self.stats['messages_published'] += 1\n",
        "\n",
        "        return msg.id\n",
        "\n",
        "    def subscribe(self, topic: str, callback: Callable) -> str:\n",
        "        subscription_id = str(uuid.uuid4())\n",
        "\n",
        "        with self.lock:\n",
        "            self.subscribers[topic].append((subscription_id, callback))\n",
        "            self.stats['subscriptions_created'] += 1\n",
        "\n",
        "        return subscription_id\n",
        "\n",
        "    def unsubscribe(self, subscription_id: str):\n",
        "        with self.lock:\n",
        "            for topic in self.subscribers:\n",
        "                # Create a new list with only the subscriptions that don't match the ID\n",
        "                self.subscribers[topic] = [\n",
        "                    (sub_id, callback) for sub_id, callback in self.subscribers[topic]\n",
        "                    if sub_id != subscription_id\n",
        "                ]\n",
        "            self.stats['subscriptions_removed'] += 1\n",
        "\n",
        "    def _process_messages(self):\n",
        "        \"\"\"Background thread to process messages\"\"\"\n",
        "        while self.is_running:\n",
        "            with self.lock:\n",
        "                # Process each topic\n",
        "                for topic, queue in self.queues.items():\n",
        "                    if queue and topic in self.subscribers:\n",
        "                        # Get highest priority message\n",
        "                        msg = heapq.heappop(queue)\n",
        "                        subscribers = self.subscribers[topic]\n",
        "\n",
        "                        # Deliver to all subscribers\n",
        "                        for subscription_id, callback in subscribers:\n",
        "                            try:\n",
        "                                callback(msg.to_dict())\n",
        "                                self.stats['messages_delivered'] += 1\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error delivering message {msg.id}: {e}\")\n",
        "                                msg.delivery_attempts += 1\n",
        "\n",
        "                        # Move to dead letter queue after 3 attempts\n",
        "                        if msg.delivery_attempts >= 3:\n",
        "                            self.dead_letter_queues[topic].append(msg)\n",
        "                            self.stats['messages_failed'] += 1\n",
        "                        else:\n",
        "                            # Requeue the message\n",
        "                            heapq.heappush(queue, msg)\n",
        "\n",
        "            time.sleep(0.1)  # Small delay to prevent busy waiting\n",
        "\n",
        "    def get_queue_size(self, topic: str) -> int:\n",
        "        with self.lock:\n",
        "            return len(self.queues.get(topic, []))\n",
        "\n",
        "    def get_subscriber_count(self, topic: str) -> int:\n",
        "        with self.lock:\n",
        "            return len(self.subscribers.get(topic, []))\n",
        "\n",
        "    def get_dead_letter_count(self, topic: str) -> int:\n",
        "        with self.lock:\n",
        "            return len(self.dead_letter_queues.get(topic, []))\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        with self.lock:\n",
        "            queue_sizes = {topic: len(queue) for topic, queue in self.queues.items()}\n",
        "            subscriber_counts = {topic: len(subs) for topic, subs in self.subscribers.items()}\n",
        "            dead_letter_counts = {topic: len(dlq) for topic, dlq in self.dead_letter_queues.items()}\n",
        "\n",
        "            return {\n",
        "                'queues': queue_sizes,\n",
        "                'subscribers': subscriber_counts,\n",
        "                'dead_letter_queues': dead_letter_counts,\n",
        "                'statistics': self.stats.copy()\n",
        "            }\n",
        "\n",
        "    def stop(self):\n",
        "        self.is_running = False\n",
        "        if self.processor_thread:\n",
        "            self.processor_thread.join()\n",
        "\n",
        "class PersistentMessageQueue(InMemoryMessageQueue):\n",
        "    \"\"\"Message queue with basic persistence to disk\"\"\"\n",
        "    def __init__(self, max_queue_size: int = 10000, persistence_file: str = \"mq_persistence.json\"):\n",
        "        self.persistence_file = persistence_file\n",
        "        super().__init__(max_queue_size)\n",
        "        self._load_persistence()\n",
        "\n",
        "        # Start persistence thread\n",
        "        self.persistence_thread = threading.Thread(target=self._persistence_loop)\n",
        "        self.persistence_thread.daemon = True\n",
        "        self.persistence_thread.start()\n",
        "\n",
        "    def _load_persistence(self):\n",
        "        \"\"\"Load queue state from disk\"\"\"\n",
        "        try:\n",
        "            with open(self.persistence_file, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Reconstruct queues (simplified - in reality would need proper serialization)\n",
        "            print(\"Loaded persistent state from disk\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"No persistence file found, starting fresh\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading persistence: {e}\")\n",
        "\n",
        "    def _save_persistence(self):\n",
        "        \"\"\"Save queue state to disk\"\"\"\n",
        "        try:\n",
        "            # Simplified persistence - in reality would need proper serialization\n",
        "            persistence_data = {\n",
        "                'stats': self.stats,\n",
        "                'queues_count': {topic: len(queue) for topic, queue in self.queues.items()}\n",
        "            }\n",
        "\n",
        "            with open(self.persistence_file, 'w') as f:\n",
        "                json.dump(persistence_data, f, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving persistence: {e}\")\n",
        "\n",
        "    def _persistence_loop(self):\n",
        "        \"\"\"Background thread to periodically save state\"\"\"\n",
        "        while self.is_running:\n",
        "            time.sleep(30)  # Save every 30 seconds\n",
        "            self._save_persistence()\n",
        "\n",
        "    def stop(self):\n",
        "        super().stop()\n",
        "        self._save_persistence()  # Final save\n",
        "\n",
        "class TopicRouter:\n",
        "    \"\"\"Advanced topic routing with pattern matching\"\"\"\n",
        "    def __init__(self):\n",
        "        self.patterns = {}  # pattern -> handler\n",
        "\n",
        "    def add_route(self, pattern: str, handler: Callable):\n",
        "        \"\"\"Add route with pattern (supports * wildcard)\"\"\"\n",
        "        self.patterns[pattern] = handler\n",
        "\n",
        "    def route_message(self, topic: str, message: Dict):\n",
        "        \"\"\"Route message to matching patterns\"\"\"\n",
        "        matched = False\n",
        "        for pattern, handler in self.patterns.items():\n",
        "            if self._matches_pattern(topic, pattern):\n",
        "                try:\n",
        "                    handler(message)\n",
        "                    matched = True\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in route handler for pattern {pattern}: {e}\")\n",
        "\n",
        "        if not matched:\n",
        "            print(f\"No route found for topic: {topic}\")\n",
        "\n",
        "    def _matches_pattern(self, topic: str, pattern: str) -> bool:\n",
        "        \"\"\"Check if topic matches pattern with wildcards\"\"\"\n",
        "        topic_parts = topic.split('.')\n",
        "        pattern_parts = pattern.split('.')\n",
        "\n",
        "        if len(topic_parts) != len(pattern_parts):\n",
        "            return False\n",
        "\n",
        "        for t, p in zip(topic_parts, pattern_parts):\n",
        "            if p != '*' and t != p:\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "# Example consumers and producers\n",
        "class EmailService:\n",
        "    def send_email(self, message: Dict):\n",
        "        print(f\"[Email] Sending email: {message['payload']['subject']}\")\n",
        "        # Simulate email sending\n",
        "        time.sleep(0.1)\n",
        "        print(f\"[Email] Email sent to {message['payload']['to']}\")\n",
        "\n",
        "class NotificationService:\n",
        "    def send_notification(self, message: Dict):\n",
        "        print(f\"[Notification] Sending push notification: {message['payload']['message']}\")\n",
        "        time.sleep(0.05)\n",
        "\n",
        "class AnalyticsService:\n",
        "    def track_event(self, message: Dict):\n",
        "        print(f\"[Analytics] Tracking event: {message['payload']['event_name']}\")\n",
        "        # Simulate analytics processing\n",
        "        time.sleep(0.02)\n",
        "\n",
        "class OrderService:\n",
        "    def __init__(self, message_queue: MessageQueue):\n",
        "        self.mq = message_queue\n",
        "        self.setup_consumers()\n",
        "\n",
        "    def setup_consumers(self):\n",
        "        # Subscribe to order-related topics\n",
        "        self.mq.subscribe(\"order.created\", self.handle_order_created)\n",
        "        self.mq.subscribe(\"order.updated\", self.handle_order_updated)\n",
        "        self.mq.subscribe(\"order.cancelled\", self.handle_order_cancelled)\n",
        "\n",
        "    def handle_order_created(self, message: Dict):\n",
        "        order_data = message['payload']\n",
        "        print(f\"[OrderService] Processing new order: {order_data['order_id']}\")\n",
        "\n",
        "        # Publish related events\n",
        "        self.mq.publish(\"email.order_confirmation\", {\n",
        "            'to': order_data['customer_email'],\n",
        "            'subject': 'Order Confirmation',\n",
        "            'order_id': order_data['order_id']\n",
        "        })\n",
        "\n",
        "        self.mq.publish(\"analytics.event\", {\n",
        "            'event_name': 'order_created',\n",
        "            'order_id': order_data['order_id'],\n",
        "            'amount': order_data['amount']\n",
        "        })\n",
        "\n",
        "    def handle_order_updated(self, message: Dict):\n",
        "        order_data = message['payload']\n",
        "        print(f\"[OrderService] Order updated: {order_data['order_id']}\")\n",
        "\n",
        "    def handle_order_cancelled(self, message: Dict):\n",
        "        order_data = message['payload']\n",
        "        print(f\"[OrderService] Order cancelled: {order_data['order_id']}\")\n",
        "\n",
        "# Demonstration\n",
        "def demonstrate_message_queue():\n",
        "    print(\"=== Message Queue System Demonstration === \")\n",
        "\n",
        "    # Create message queue\n",
        "    mq = InMemoryMessageQueue(max_queue_size=1000)\n",
        "\n",
        "    # Create services\n",
        "    email_service = EmailService()\n",
        "    notification_service = NotificationService()\n",
        "    analytics_service = AnalyticsService()\n",
        "    order_service = OrderService(mq)\n",
        "\n",
        "    # Set up additional consumers\n",
        "    mq.subscribe(\"email.*\", email_service.send_email)\n",
        "    mq.subscribe(\"notification.*\", notification_service.send_notification)\n",
        "    mq.subscribe(\"analytics.*\", analytics_service.track_event)\n",
        "\n",
        "    # Create topic router for advanced routing\n",
        "    router = TopicRouter()\n",
        "    router.add_route(\"user.*\", lambda msg: print(f\"[Router] User event: {msg['topic']}\"))\n",
        "    router.add_route(\"*.created\", lambda msg: print(f\"[Router] Creation event: {msg['topic']}\"))\n",
        "\n",
        "    mq.subscribe(\"*\", router.route_message)\n",
        "\n",
        "    # Produce some messages\n",
        "    print(\"=== Producing Messages === \")\n",
        "\n",
        "    # High priority order\n",
        "    mq.publish(\"order.created\", {\n",
        "        'order_id': 'ORD-001',\n",
        "        'customer_email': 'customer@example.com',\n",
        "        'amount': 99.99,\n",
        "        'items': ['item1', 'item2']\n",
        "    }, priority=10)\n",
        "\n",
        "    # Regular priority notifications\n",
        "    mq.publish(\"notification.welcome\", {\n",
        "        'user_id': 'user123',\n",
        "        'message': 'Welcome to our service!'\n",
        "    })\n",
        "\n",
        "    mq.publish(\"user.created\", {\n",
        "        'user_id': 'user456',\n",
        "        'name': 'John Doe'\n",
        "    })\n",
        "\n",
        "    mq.publish(\"analytics.page_view\", {\n",
        "        'page': '/home',\n",
        "        'user_agent': 'Mozilla/5.0'\n",
        "    })\n",
        "\n",
        "    # Let messages process - increased sleep time to ensure processing\n",
        "    print(\"Waiting for messages to be processed (3 seconds)...\")\n",
        "    time.sleep(3)  # Increased from 2 to 3 seconds to ensure processing\n",
        "\n",
        "    # Show statistics\n",
        "    print(\"=== Message Queue Statistics === \")\n",
        "    stats = mq.get_stats()\n",
        "    for category, data in stats.items():\n",
        "        print(f\"{category}:\")\n",
        "        if isinstance(data, dict):\n",
        "            for key, value in data.items():\n",
        "                print(f\"  {key}: {value}\")\n",
        "        else:\n",
        "            print(f\"  {data}\")\n",
        "\n",
        "    # Cleanup\n",
        "    mq.stop()\n",
        "\n",
        "def performance_test():\n",
        "    \"\"\"Test message queue performance\"\"\"\n",
        "    print(\"=== Performance Test === \")\n",
        "\n",
        "    mq = InMemoryMessageQueue()\n",
        "    message_count = 100\n",
        "\n",
        "    # Simple consumer\n",
        "    received_count = [0]  # Use list for mutable reference\n",
        "\n",
        "    def simple_consumer(message):\n",
        "        received_count[0] += 1\n",
        "\n",
        "    mq.subscribe(\"test.topic\", simple_consumer)\n",
        "\n",
        "    # Produce messages\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(message_count):\n",
        "        mq.publish(\"test.topic\", {'message_id': i, 'data': 'x' * 100})\n",
        "\n",
        "    # Wait for processing\n",
        "    time.sleep(1)\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    print(f\"Produced and consumed {message_count} messages in {duration:.2f} seconds\")\n",
        "    print(f\"Throughput: {message_count / duration:.2f} messages/second\")\n",
        "    print(f\"Messages received: {received_count[0]}/{message_count}\")\n",
        "\n",
        "    mq.stop()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demonstrate_message_queue()\n",
        "    performance_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "N5I8ODLS8VuR",
        "outputId": "b7ba8c4c-fec8-44ce-b6da-9d5718b96cc4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Message Queue System Demonstration === \n",
            "=== Producing Messages === \n",
            "Waiting for messages to be processed (3 seconds)...\n",
            "[OrderService] Processing new order: ORD-001\n",
            "=== Message Queue Statistics === \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2279223088.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0mdemonstrate_message_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0mperformance_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2279223088.py\u001b[0m in \u001b[0;36mdemonstrate_message_queue\u001b[0;34m()\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m# Show statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Message Queue Statistics === \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{category}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2279223088.py\u001b[0m in \u001b[0;36mget_stats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mqueue_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0msubscriber_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubscribers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 13: ATAM Evaluation Framework\n",
        "Objective: Implement Architecture Tradeoff Analysis Method (ATAM) evaluation.\n",
        "Problem Statement: Create a framework to evaluate architectural decisions against quality attributes."
      ],
      "metadata": {
        "id": "gK10-Bl596UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, List, Set, Tuple\n",
        "from enum import Enum\n",
        "import math\n",
        "\n",
        "class QualityAttribute(Enum):\n",
        "    PERFORMANCE = \"Performance\"\n",
        "    SCALABILITY = \"Scalability\"\n",
        "    RELIABILITY = \"Reliability\"\n",
        "    SECURITY = \"Security\"\n",
        "    MAINTAINABILITY = \"Maintainability\"\n",
        "    AVAILABILITY = \"Availability\"\n",
        "    USABILITY = \"Usability\"\n",
        "    TESTABILITY = \"Testability\"\n",
        "    DEPLOYABILITY = \"Deployability\"  # Added to resolve reference in examples\n",
        "\n",
        "class ArchitecturalApproach:\n",
        "    def __init__(self, name: str, description: str):\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.quality_impacts: Dict[QualityAttribute, int] = {}  # -5 to +5 scale\n",
        "        self.risks: List[str] = []\n",
        "        self.sensitivity_points: List[str] = []\n",
        "        self.tradeoff_points: List[str] = []\n",
        "\n",
        "    def set_impact(self, attribute: QualityAttribute, impact: int):\n",
        "        \"\"\"Set impact on quality attribute (-5 to +5 scale)\"\"\"\n",
        "        self.quality_impacts[attribute] = max(-5, min(5, impact))\n",
        "\n",
        "    def add_risk(self, risk: str):\n",
        "        self.risks.append(risk)\n",
        "\n",
        "    def add_sensitivity_point(self, point: str):\n",
        "        self.sensitivity_points.append(point)\n",
        "\n",
        "    def add_tradeoff_point(self, point: str):\n",
        "        self.tradeoff_points.append(point)\n",
        "\n",
        "    def get_score(self) -> float:\n",
        "        \"\"\"Calculate overall score based on quality impacts\"\"\"\n",
        "        if not self.quality_impacts:\n",
        "            return 0.0\n",
        "\n",
        "        # Weighted average of impacts\n",
        "        total_weight = 0\n",
        "        weighted_sum = 0\n",
        "\n",
        "        for attribute, impact in self.quality_impacts.items():\n",
        "            weight = self._get_attribute_weight(attribute)\n",
        "            weighted_sum += impact * weight\n",
        "            total_weight += weight\n",
        "\n",
        "        return weighted_sum / total_weight if total_weight > 0 else 0.0\n",
        "\n",
        "    def _get_attribute_weight(self, attribute: QualityAttribute) -> float:\n",
        "        \"\"\"Get weight for quality attribute (1.0 to 3.0 scale)\"\"\"\n",
        "        weights = {\n",
        "            QualityAttribute.PERFORMANCE: 2.0,\n",
        "            QualityAttribute.SCALABILITY: 1.5,\n",
        "            QualityAttribute.RELIABILITY: 2.5,\n",
        "            QualityAttribute.SECURITY: 3.0,\n",
        "            QualityAttribute.MAINTAINABILITY: 1.5,\n",
        "            QualityAttribute.AVAILABILITY: 2.0,\n",
        "            QualityAttribute.USABILITY: 1.0,\n",
        "            QualityAttribute.TESTABILITY: 1.0,\n",
        "            QualityAttribute.DEPLOYABILITY: 1.5  # Added to resolve reference in examples\n",
        "        }\n",
        "        return weights.get(attribute, 1.0)\n",
        "\n",
        "class Scenario:\n",
        "    def __init__(self, description: str, quality_attributes: List[QualityAttribute]):\n",
        "        self.description = description\n",
        "        self.quality_attributes = quality_attributes\n",
        "        self.importance: int = 1  # 1-5 scale\n",
        "\n",
        "    def set_importance(self, importance: int):\n",
        "        self.importance = max(1, min(5, importance))\n",
        "\n",
        "class ATAMEvaluator:\n",
        "    def __init__(self):\n",
        "        self.approaches: List[ArchitecturalApproach] = []\n",
        "        self.scenarios: List[Scenario] = []\n",
        "        self.stakeholders: List[str] = []\n",
        "        self.quality_requirements: Dict[QualityAttribute, int] = {}  # 1-5 scale\n",
        "\n",
        "    def add_approach(self, approach: ArchitecturalApproach):\n",
        "        self.approaches.append(approach)\n",
        "\n",
        "    def add_scenario(self, scenario: Scenario):\n",
        "        self.scenarios.append(scenario)\n",
        "\n",
        "    def add_stakeholder(self, stakeholder: str):\n",
        "        self.stakeholders.append(stakeholder)\n",
        "\n",
        "    def set_quality_requirement(self, attribute: QualityAttribute, importance: int):\n",
        "        self.quality_requirements[attribute] = max(1, min(5, importance))\n",
        "\n",
        "    def evaluate_approaches(self) -> List[Tuple[ArchitecturalApproach, float]]:\n",
        "        \"\"\"Evaluate all approaches and return sorted by score\"\"\"\n",
        "        results = []\n",
        "\n",
        "        for approach in self.approaches:\n",
        "            score = self._calculate_approach_score(approach)\n",
        "            results.append((approach, score))\n",
        "\n",
        "        # Sort by score descending\n",
        "        return sorted(results, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    def _calculate_approach_score(self, approach: ArchitecturalApproach) -> float:\n",
        "        \"\"\"Calculate comprehensive score for an approach\"\"\"\n",
        "        # Base score from quality impacts\n",
        "        base_score = approach.get_score()\n",
        "\n",
        "        # Adjust based on quality requirements alignment\n",
        "        requirement_score = 0\n",
        "        total_weight = 0\n",
        "\n",
        "        for attribute, requirement_importance in self.quality_requirements.items():\n",
        "            approach_impact = approach.quality_impacts.get(attribute, 0)\n",
        "\n",
        "            # Normalize impact to 0-1 scale\n",
        "            normalized_impact = (approach_impact + 5) / 10\n",
        "\n",
        "            requirement_score += normalized_impact * requirement_importance\n",
        "            total_weight += requirement_importance\n",
        "\n",
        "        requirement_alignment = requirement_score / total_weight if total_weight > 0 else 0\n",
        "\n",
        "        # Combine scores (60% base, 40% requirement alignment)\n",
        "        final_score = (base_score * 0.6) + (requirement_alignment * 40)\n",
        "\n",
        "        return final_score\n",
        "\n",
        "    def identify_sensitivity_points(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Identify sensitivity points across all approaches\"\"\"\n",
        "        sensitivity_points = {}\n",
        "\n",
        "        for approach in self.approaches:\n",
        "            for point in approach.sensitivity_points:\n",
        "                if point not in sensitivity_points:\n",
        "                    sensitivity_points[point] = []\n",
        "                sensitivity_points[point].append(approach.name)\n",
        "\n",
        "        return sensitivity_points\n",
        "\n",
        "    def identify_tradeoff_points(self) -> Dict[str, List[Tuple[str, str]]]:\n",
        "        \"\"\"Identify tradeoff points between quality attributes\"\"\"\n",
        "        tradeoffs = {}\n",
        "\n",
        "        for approach in self.approaches:\n",
        "            for point in approach.tradeoff_points:\n",
        "                if point not in tradeoffs:\n",
        "                    tradeoffs[point] = []\n",
        "\n",
        "                # Find attributes with positive and negative impacts\n",
        "                positive_attrs = []\n",
        "                negative_attrs = []\n",
        "\n",
        "                for attr, impact in approach.quality_impacts.items():\n",
        "                    if impact > 0:\n",
        "                        positive_attrs.append(attr.value)\n",
        "                    elif impact < 0:\n",
        "                        negative_attrs.append(attr.value)\n",
        "\n",
        "                if positive_attrs and negative_attrs:\n",
        "                    tradeoff_desc = f\"Improves {', '.join(positive_attrs)} but degrades {', '.join(negative_attrs)}\"\n",
        "                    tradeoffs[point].append((approach.name, tradeoff_desc))\n",
        "\n",
        "        return tradeoffs\n",
        "\n",
        "    def generate_report(self) -> Dict:\n",
        "        \"\"\"Generate comprehensive ATAM report\"\"\"\n",
        "        evaluated_approaches = self.evaluate_approaches()\n",
        "        sensitivity_points = self.identify_sensitivity_points()\n",
        "        tradeoff_points = self.identify_tradeoff_points()\n",
        "\n",
        "        report = {\n",
        "            'stakeholders': self.stakeholders,\n",
        "            'quality_requirements': {attr.value: importance\n",
        "                                    for attr, importance in self.quality_requirements.items()},\n",
        "            'scenarios': [{'description': s.description, 'importance': s.importance}\n",
        "                         for s in self.scenarios],\n",
        "            'approach_rankings': [\n",
        "                {\n",
        "                    'approach': approach.name,\n",
        "                    'score': round(score, 2),\n",
        "                    'description': approach.description,\n",
        "                    'risks': approach.risks\n",
        "                }\n",
        "                for approach, score in evaluated_approaches\n",
        "            ],\n",
        "            'sensitivity_points': sensitivity_points,\n",
        "            'tradeoff_points': tradeoff_points,\n",
        "            'recommendations': self._generate_recommendations(evaluated_approaches)\n",
        "        }\n",
        "\n",
        "        return report\n",
        "\n",
        "    def _generate_recommendations(self, evaluated_approaches: List[Tuple[ArchitecturalApproach, float]]) -> List[str]:\n",
        "        \"\"\"Generate recommendations based on evaluation\"\"\"\n",
        "        recommendations = []\n",
        "\n",
        "        if not evaluated_approaches:\n",
        "            return recommendations\n",
        "\n",
        "        best_approach, best_score = evaluated_approaches[0]\n",
        "\n",
        "        recommendations.append(f\"Recommended approach: {best_approach.name} (Score: {best_score:.2f})\")\n",
        "\n",
        "        # Identify key strengths\n",
        "        positive_impacts = []\n",
        "        for attr, impact in best_approach.quality_impacts.items():\n",
        "            if impact >= 3:  # Significant positive impact\n",
        "                positive_impacts.append(f\"{attr.value}(+{impact})\")\n",
        "\n",
        "        if positive_impacts:\n",
        "            recommendations.append(f\"Key strengths: {', '.join(positive_impacts)}\")\n",
        "\n",
        "        # Identify risks to mitigate\n",
        "        if best_approach.risks:\n",
        "            recommendations.append(\"Key risks to mitigate:\")\n",
        "            for risk in best_approach.risks[:3]:  # Top 3 risks\n",
        "                recommendations.append(f\" - {risk}\")\n",
        "\n",
        "        # Consider alternatives if scores are close\n",
        "        if len(evaluated_approaches) > 1:\n",
        "            second_approach, second_score = evaluated_approaches[1]\n",
        "            score_difference = best_score - second_score\n",
        "\n",
        "            if score_difference < 5:  # Close scores\n",
        "                recommendations.append(f\"Consider {second_approach.name} as alternative (Score: {second_score:.2f})\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "# Example usage and demonstration\n",
        "def demonstrate_atam():\n",
        "    print(\"=== ATAM Architecture Evaluation ===\")\n",
        "\n",
        "    # Create evaluator\n",
        "    evaluator = ATAMEvaluator()\n",
        "\n",
        "    # Add stakeholders\n",
        "    evaluator.add_stakeholder(\"Product Owner\")\n",
        "    evaluator.add_stakeholder(\"Development Team\")\n",
        "    evaluator.add_stakeholder(\"Operations Team\")\n",
        "    evaluator.add_stakeholder(\"End Users\")\n",
        "\n",
        "    # Set quality requirements\n",
        "    evaluator.set_quality_requirement(QualityAttribute.PERFORMANCE, 4)\n",
        "    evaluator.set_quality_requirement(QualityAttribute.SCALABILITY, 3)\n",
        "    evaluator.set_quality_requirement(QualityAttribute.RELIABILITY, 5)\n",
        "    evaluator.set_quality_requirement(QualityAttribute.SECURITY, 4)\n",
        "    evaluator.set_quality_requirement(QualityAttribute.MAINTAINABILITY, 3)\n",
        "\n",
        "    # Add scenarios\n",
        "    scenario1 = Scenario(\n",
        "        \"System should handle 10,000 concurrent users with response time < 2 seconds\",\n",
        "        [QualityAttribute.PERFORMANCE, QualityAttribute.SCALABILITY]\n",
        "    )\n",
        "    scenario1.set_importance(5)\n",
        "    evaluator.add_scenario(scenario1)\n",
        "\n",
        "    scenario2 = Scenario(\n",
        "        \"System should have 99.9% availability with automatic failover\",\n",
        "        [QualityAttribute.AVAILABILITY, QualityAttribute.RELIABILITY]\n",
        "    )\n",
        "    scenario2.set_importance(4)\n",
        "    evaluator.add_scenario(scenario2)\n",
        "\n",
        "    # Define architectural approaches\n",
        "\n",
        "    # Approach 1: Microservices\n",
        "    microservices = ArchitecturalApproach(\n",
        "        \"Microservices Architecture\",\n",
        "        \"Decompose system into small, independently deployable services\"\n",
        "    )\n",
        "    microservices.set_impact(QualityAttribute.SCALABILITY, 4)\n",
        "    microservices.set_impact(QualityAttribute.MAINTAINABILITY, 3)\n",
        "    microservices.set_impact(QualityAttribute.DEPLOYABILITY, 4)\n",
        "    microservices.set_impact(QualityAttribute.PERFORMANCE, -1)  # Network overhead\n",
        "    microservices.set_impact(QualityAttribute.RELIABILITY, 2)\n",
        "    microservices.set_impact(QualityAttribute.SECURITY, -2)  # Increased attack surface\n",
        "    microservices.add_risk(\"Distributed system complexity\")\n",
        "    microservices.add_risk(\"Data consistency challenges\")\n",
        "    microservices.add_sensitivity_point(\"Service communication latency\")\n",
        "    microservices.add_tradeoff_point(\"Independent deployment vs. operational complexity\")\n",
        "\n",
        "    # Approach 2: Monolithic\n",
        "    monolithic = ArchitecturalApproach(\n",
        "        \"Monolithic Architecture\",\n",
        "        \"Single unified codebase deployed as one unit\"\n",
        "    )\n",
        "    monolithic.set_impact(QualityAttribute.PERFORMANCE, 3)  # No network calls\n",
        "    monolithic.set_impact(QualityAttribute.SECURITY, 2)  # Smaller attack surface\n",
        "    monolithic.set_impact(QualityAttribute.SCALABILITY, -2)  # Hard to scale components independently\n",
        "    monolithic.set_impact(QualityAttribute.MAINTAINABILITY, -3)  # Codebase complexity\n",
        "    monolithic.set_impact(QualityAttribute.RELIABILITY, 1)\n",
        "    monolithic.set_impact(QualityAttribute.DEPLOYABILITY, -2)\n",
        "    monolithic.add_risk(\"Single point of failure\")\n",
        "    monolithic.add_risk(\"Difficult to adopt new technologies\")\n",
        "    monolithic.add_sensitivity_point(\"Database performance\")\n",
        "    monolithic.add_tradeoff_point(\"Development speed vs. long-term maintainability\")\n",
        "\n",
        "    # Approach 3: Event-Driven\n",
        "    event_driven = ArchitecturalApproach(\n",
        "        \"Event-Driven Architecture\",\n",
        "        \"Components communicate through asynchronous events\"\n",
        "    )\n",
        "    event_driven.set_impact(QualityAttribute.SCALABILITY, 5)\n",
        "    event_driven.set_impact(QualityAttribute.RELIABILITY, 3)\n",
        "    event_driven.set_impact(QualityAttribute.PERFORMANCE, 2)\n",
        "    event_driven.set_impact(QualityAttribute.MAINTAINABILITY, 1)\n",
        "    event_driven.set_impact(QualityAttribute.SECURITY, -1)\n",
        "    event_driven.set_impact(QualityAttribute.TESTABILITY, -2)\n",
        "    event_driven.add_risk(\"Event ordering and consistency\")\n",
        "    event_driven.add_risk(\"Debugging complexity\")\n",
        "    event_driven.add_sensitivity_point(\"Message broker performance\")\n",
        "    event_driven.add_tradeoff_point(\"Loose coupling vs. system understanding\")\n",
        "\n",
        "    # Add approaches to evaluator\n",
        "    evaluator.add_approach(microservices)\n",
        "    evaluator.add_approach(monolithic)\n",
        "    evaluator.add_approach(event_driven)\n",
        "\n",
        "    # Generate evaluation report\n",
        "    report = evaluator.generate_report()\n",
        "\n",
        "    # Print report\n",
        "    print(\"\\n=== ATAM Evaluation Report ===\")\n",
        "\n",
        "    print(f\"\\nStakeholders: {', '.join(report['stakeholders'])}\")\n",
        "\n",
        "    print(\"\\nQuality Requirements:\")\n",
        "    for attr, importance in report['quality_requirements'].items():\n",
        "        print(f\"  {attr}: {importance}/5\")\n",
        "\n",
        "    print(\"\\nApproach Rankings:\")\n",
        "    for i, ranking in enumerate(report['approach_rankings'], 1):\n",
        "        print(f\"{i}. {ranking['approach']} - Score: {ranking['score']}\")\n",
        "        print(f\"   Description: {ranking['description']}\")\n",
        "        if ranking['risks']:\n",
        "            print(f\"   Key Risks: {', '.join(ranking['risks'][:2])}\")\n",
        "\n",
        "    print(\"\\nSensitivity Points:\")\n",
        "    for point, approaches in report['sensitivity_points'].items():\n",
        "        print(f\"  {point}: {', '.join(approaches)}\")\n",
        "\n",
        "    print(\"\\nTrade-off Points:\")\n",
        "    for point, tradeoffs in report['tradeoff_points'].items():\n",
        "        print(f\"  {point}:\")\n",
        "        for approach, description in tradeoffs:\n",
        "            print(f\"  - {approach}: {description}\")\n",
        "\n",
        "    print(\"\\nRecommendations:\")\n",
        "    for recommendation in report['recommendations']:\n",
        "        print(f\"  {recommendation}\")\n",
        "\n",
        "    return evaluator\n",
        "\n",
        "def detailed_approach_comparison(evaluator: ATAMEvaluator):\n",
        "    \"\"\"Show detailed comparison of approaches\"\"\"\n",
        "    print(\"\\n=== Detailed Approach Comparison ===\")\n",
        "\n",
        "    approaches = evaluator.evaluate_approaches()\n",
        "\n",
        "    # Quality attributes for comparison\n",
        "    attributes = list(QualityAttribute)\n",
        "\n",
        "    # Print header\n",
        "    header = f\"{'Approach':<25} \" + \"\".join(f\"{attr.value[:10]:<12} \" for attr in attributes) + \" Overall\"\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "\n",
        "    # Print each approach\n",
        "    for approach, overall_score in approaches:\n",
        "        row = f\"{approach.name:<25} \"\n",
        "        for attr in attributes:\n",
        "            impact = approach.quality_impacts.get(attr, 0)\n",
        "            impact_str = f\"+{impact}\" if impact > 0 else str(impact)\n",
        "            row += f\"{impact_str:<12}\"\n",
        "        row += f\"{overall_score:.2f}\"\n",
        "        print(row)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evaluator = demonstrate_atam()\n",
        "    detailed_approach_comparison(evaluator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxFGX3LA-Ssy",
        "outputId": "aa9bab65-bfb8-44ba-f82f-13379599bc37"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ATAM Architecture Evaluation ===\n",
            "\n",
            "=== ATAM Evaluation Report ===\n",
            "\n",
            "Stakeholders: Product Owner, Development Team, Operations Team, End Users\n",
            "\n",
            "Quality Requirements:\n",
            "  Performance: 4/5\n",
            "  Scalability: 3/5\n",
            "  Reliability: 5/5\n",
            "  Security: 4/5\n",
            "  Maintainability: 3/5\n",
            "\n",
            "Approach Rankings:\n",
            "1. Event-Driven Architecture - Score: 28.6\n",
            "   Description: Components communicate through asynchronous events\n",
            "   Key Risks: Event ordering and consistency, Debugging complexity\n",
            "2. Microservices Architecture - Score: 24.68\n",
            "   Description: Decompose system into small, independently deployable services\n",
            "   Key Risks: Distributed system complexity, Data consistency challenges\n",
            "3. Monolithic Architecture - Score: 22.31\n",
            "   Description: Single unified codebase deployed as one unit\n",
            "   Key Risks: Single point of failure, Difficult to adopt new technologies\n",
            "\n",
            "Sensitivity Points:\n",
            "  Service communication latency: Microservices Architecture\n",
            "  Database performance: Monolithic Architecture\n",
            "  Message broker performance: Event-Driven Architecture\n",
            "\n",
            "Trade-off Points:\n",
            "  Independent deployment vs. operational complexity:\n",
            "  - Microservices Architecture: Improves Scalability, Maintainability, Deployability, Reliability but degrades Performance, Security\n",
            "  Development speed vs. long-term maintainability:\n",
            "  - Monolithic Architecture: Improves Performance, Security, Reliability but degrades Scalability, Maintainability, Deployability\n",
            "  Loose coupling vs. system understanding:\n",
            "  - Event-Driven Architecture: Improves Scalability, Reliability, Performance, Maintainability but degrades Security, Testability\n",
            "\n",
            "Recommendations:\n",
            "  Recommended approach: Event-Driven Architecture (Score: 28.60)\n",
            "  Key strengths: Scalability(+5), Reliability(+3)\n",
            "  Key risks to mitigate:\n",
            "   - Event ordering and consistency\n",
            "   - Debugging complexity\n",
            "  Consider Microservices Architecture as alternative (Score: 24.68)\n",
            "\n",
            "=== Detailed Approach Comparison ===\n",
            "Approach                  Performanc   Scalabilit   Reliabilit   Security     Maintainab   Availabili   Usability    Testabilit   Deployabil    Overall\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Event-Driven Architecture +2          +5          +3          -1          +1          0           0           -2          0           28.60\n",
            "Microservices Architecture -1          +4          +2          -2          +3          0           0           0           +4          24.68\n",
            "Monolithic Architecture   +3          -2          +1          +2          -3          0           0           0           -2          22.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 14: Architecture Documentation Generator\n",
        "Objective: Create automated architecture documentation from code.\n",
        "Problem Statement: Build a tool that analyzes Python code and generates architecture documentation"
      ],
      "metadata": {
        "id": "Iqz2CkOhAYVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import ast\n",
        "import os\n",
        "from typing import Dict, List, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ClassInfo:\n",
        "    name: str\n",
        "    methods: List[str]\n",
        "    attributes: List[str]\n",
        "    base_classes: List[str]\n",
        "    docstring: str\n",
        "    file_path: str\n",
        "    line_number: int\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FunctionInfo:\n",
        "    name: str\n",
        "    parameters: List[str]\n",
        "    return_type: str\n",
        "    docstring: str\n",
        "    file_path: str\n",
        "    line_number: int\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModuleInfo:\n",
        "    name: str\n",
        "    classes: List[ClassInfo]\n",
        "    functions: List[FunctionInfo]\n",
        "    imports: List[str]\n",
        "    file_path: str\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Dependency:\n",
        "    source: str\n",
        "    target: str\n",
        "    type: str  # 'inheritance', 'composition', 'association', 'dependency'\n",
        "\n",
        "\n",
        "class ArchitectureAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.modules: Dict[str, ModuleInfo] = {}\n",
        "        self.dependencies: List[Dependency] = []\n",
        "\n",
        "    def analyze_directory(self, directory_path: str):\n",
        "        \"\"\"Analyze all Python files in directory (recursively).\"\"\"\n",
        "        path = Path(directory_path)\n",
        "\n",
        "        for py_file in path.rglob(\"*.py\"):\n",
        "            if self._should_analyze_file(py_file):\n",
        "                self.analyze_file(str(py_file))\n",
        "\n",
        "        self._build_dependencies()\n",
        "\n",
        "    def _should_analyze_file(self, file_path: Path) -> bool:\n",
        "        \"\"\"Check if file should be analyzed (skip tests, venvs, caches).\"\"\"\n",
        "        excluded_patterns = [\"test_\", \"_test\", \"__pycache__\", \".venv\", \"venv\", \"env\", \"/.venv/\", \"/venv/\"]\n",
        "        s = str(file_path)\n",
        "        return not any(pattern in s for pattern in excluded_patterns)\n",
        "\n",
        "    def analyze_file(self, file_path: str):\n",
        "        \"\"\"Analyze a single Python file and extract module info.\"\"\"\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                content = file.read()\n",
        "\n",
        "            tree = ast.parse(content)\n",
        "            module_name = Path(file_path).stem\n",
        "\n",
        "            module_info = ModuleInfo(\n",
        "                name=module_name,\n",
        "                classes=[],\n",
        "                functions=[],\n",
        "                imports=[],\n",
        "                file_path=file_path,\n",
        "            )\n",
        "\n",
        "            # Extract imports\n",
        "            for node in ast.walk(tree):\n",
        "                if isinstance(node, ast.Import):\n",
        "                    for alias in node.names:\n",
        "                        module_info.imports.append(alias.name)\n",
        "                elif isinstance(node, ast.ImportFrom):\n",
        "                    if node.module:\n",
        "                        module_info.imports.append(node.module)\n",
        "\n",
        "            # Extract top-level classes and functions\n",
        "            for node in ast.iter_child_nodes(tree):\n",
        "                if isinstance(node, ast.ClassDef):\n",
        "                    class_info = self._extract_class_info(node, file_path)\n",
        "                    module_info.classes.append(class_info)\n",
        "                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
        "                    function_info = self._extract_function_info(node, file_path)\n",
        "                    module_info.functions.append(function_info)\n",
        "\n",
        "            self.modules[module_name] = module_info\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing {file_path}: {e}\")\n",
        "\n",
        "    def _get_annotation_name(self, node: ast.AST) -> str:\n",
        "        \"\"\"Return a readable name for annotation nodes (simple best-effort).\"\"\"\n",
        "        if node is None:\n",
        "            return \"Any\"\n",
        "        if isinstance(node, ast.Name):\n",
        "            return node.id\n",
        "        if isinstance(node, ast.Attribute):\n",
        "            # e.g., typing.List -> Attribute(value=Name('typing'), attr='List')\n",
        "            parts = []\n",
        "            cur: Optional[ast.AST] = node\n",
        "            while isinstance(cur, ast.Attribute):\n",
        "                parts.append(cur.attr)\n",
        "                cur = cur.value\n",
        "            if isinstance(cur, ast.Name):\n",
        "                parts.append(cur.id)\n",
        "            return \".\".join(reversed(parts))\n",
        "        if isinstance(node, ast.Subscript):\n",
        "            # e.g., List[int]\n",
        "            value = self._get_annotation_name(node.value)\n",
        "            # Try to get slice name\n",
        "            try:\n",
        "                slice_name = self._get_annotation_name(node.slice) if not isinstance(node.slice, ast.Tuple) else \",\".join(\n",
        "                    self._get_annotation_name(elt) for elt in node.slice.elts\n",
        "                )\n",
        "            except Exception:\n",
        "                slice_name = \"...\"\n",
        "            return f\"{value}[{slice_name}]\"\n",
        "        if isinstance(node, ast.Constant):\n",
        "            return repr(node.value)\n",
        "        return \"Any\"\n",
        "\n",
        "    def _extract_class_info(self, class_node: ast.ClassDef, file_path: str) -> ClassInfo:\n",
        "        \"\"\"Extract methods, attributes, base classes, docstring, etc.\"\"\"\n",
        "        methods: List[str] = []\n",
        "        attributes: List[str] = []\n",
        "        base_classes: List[str] = []\n",
        "\n",
        "        # Base classes (handle Name and Attribute)\n",
        "        for base in class_node.bases:\n",
        "            if isinstance(base, ast.Name):\n",
        "                base_classes.append(base.id)\n",
        "            elif isinstance(base, ast.Attribute):\n",
        "                base_classes.append(self._get_annotation_name(base))\n",
        "            else:\n",
        "                # Fallback for complex expressions\n",
        "                base_classes.append(ast.unparse(base) if hasattr(ast, \"unparse\") else \"UnknownBase\")\n",
        "\n",
        "        # Extract methods and class-level attributes (AnnAssign/Assign)\n",
        "        for node in class_node.body:\n",
        "            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
        "                methods.append(node.name)\n",
        "            elif isinstance(node, ast.Assign):\n",
        "                for target in node.targets:\n",
        "                    if isinstance(target, ast.Name):\n",
        "                        attributes.append(target.id)\n",
        "                    elif isinstance(target, ast.Attribute):\n",
        "                        # e.g., some_module.CONST = ...\n",
        "                        attributes.append(ast.unparse(target) if hasattr(ast, \"unparse\") else \"attr\")\n",
        "            elif isinstance(node, ast.AnnAssign):\n",
        "                target = node.target\n",
        "                if isinstance(target, ast.Name):\n",
        "                    attributes.append(target.id)\n",
        "\n",
        "        docstring = ast.get_docstring(class_node) or \"\"\n",
        "\n",
        "        return ClassInfo(\n",
        "            name=class_node.name,\n",
        "            methods=methods,\n",
        "            attributes=attributes,\n",
        "            base_classes=base_classes,\n",
        "            docstring=docstring,\n",
        "            file_path=file_path,\n",
        "            line_number=class_node.lineno,\n",
        "        )\n",
        "\n",
        "    def _extract_function_info(self, function_node: ast.AST, file_path: str) -> FunctionInfo:\n",
        "        \"\"\"Extract function name, parameters, return type and docstring.\"\"\"\n",
        "        # function_node may be FunctionDef or AsyncFunctionDef\n",
        "        name = getattr(function_node, \"name\", \"<lambda>\")\n",
        "        parameters: List[str] = []\n",
        "\n",
        "        # args: positional and kwonly; skip vararg/kwarg names for brevity\n",
        "        args_obj = function_node.args\n",
        "        for arg in getattr(args_obj, \"args\", []) + getattr(args_obj, \"kwonlyargs\", []):\n",
        "            parameters.append(arg.arg)\n",
        "        if getattr(args_obj, \"vararg\", None):\n",
        "            parameters.append(\"*\" + args_obj.vararg.arg)\n",
        "        if getattr(args_obj, \"kwarg\", None):\n",
        "            parameters.append(\"**\" + args_obj.kwarg.arg)\n",
        "\n",
        "        # Return type best-effort\n",
        "        return_type = \"Any\"\n",
        "        if getattr(function_node, \"returns\", None):\n",
        "            try:\n",
        "                return_type = self._get_annotation_name(function_node.returns)\n",
        "            except Exception:\n",
        "                return_type = \"Any\"\n",
        "\n",
        "        docstring = ast.get_docstring(function_node) or \"\"\n",
        "        lineno = getattr(function_node, \"lineno\", 0)\n",
        "\n",
        "        return FunctionInfo(\n",
        "            name=name,\n",
        "            parameters=parameters,\n",
        "            return_type=return_type,\n",
        "            docstring=docstring,\n",
        "            file_path=file_path,\n",
        "            line_number=lineno,\n",
        "        )\n",
        "\n",
        "    def _build_dependencies(self):\n",
        "        \"\"\"Build dependency graph between modules and classes.\"\"\"\n",
        "        self.dependencies.clear()\n",
        "        # Module import-based dependencies\n",
        "        for module_name, module_info in self.modules.items():\n",
        "            seen = set()\n",
        "            for import_name in module_info.imports:\n",
        "                imported_module = import_name.split(\".\")[0]\n",
        "                if imported_module in self.modules and imported_module != module_name:\n",
        "                    key = (module_name, imported_module, \"dependency\")\n",
        "                    if key not in seen:\n",
        "                        self.dependencies.append(\n",
        "                            Dependency(source=module_name, target=imported_module, type=\"dependency\")\n",
        "                        )\n",
        "                        seen.add(key)\n",
        "\n",
        "        # Class inheritance relationships across modules\n",
        "        for module_name, module_info in self.modules.items():\n",
        "            for class_info in module_info.classes:\n",
        "                for base_class in class_info.base_classes:\n",
        "                    # Try to find which module defines this base class\n",
        "                    for other_module_name, other_module in self.modules.items():\n",
        "                        for other_class in other_module.classes:\n",
        "                            if other_class.name == base_class:\n",
        "                                self.dependencies.append(\n",
        "                                    Dependency(\n",
        "                                        source=f\"{module_name}.{class_info.name}\",\n",
        "                                        target=f\"{other_module_name}.{base_class}\",\n",
        "                                        type=\"inheritance\",\n",
        "                                    )\n",
        "                                )\n",
        "\n",
        "    def generate_class_diagram(self) -> str:\n",
        "        \"\"\"Generate PlantUML class diagram (text).\"\"\"\n",
        "        plantuml = [\"@startuml\", \"skinparam classAttributeIconSize 0\"]\n",
        "\n",
        "        # Add classes\n",
        "        for module_name, module_info in self.modules.items():\n",
        "            for class_info in module_info.classes:\n",
        "                full_name = f\"{module_name}.{class_info.name}\"\n",
        "                plantuml.append(f\"class \\\"{full_name}\\\" as {module_name}_{class_info.name}\")\n",
        "                # attributes and methods (limited for readability)\n",
        "                for attr in class_info.attributes[:10]:\n",
        "                    plantuml.append(f\"{module_name}_{class_info.name} : +{attr}\")\n",
        "                for method in class_info.methods[:10]:\n",
        "                    plantuml.append(f\"{module_name}_{class_info.name} : +{method}()\")\n",
        "\n",
        "        # Add relationships\n",
        "        for dep in self.dependencies:\n",
        "            if dep.type == \"inheritance\":\n",
        "                # dep.target is like module.Class - convert to alias used above\n",
        "                target_alias = dep.target.replace(\".\", \"_\")\n",
        "                source_alias = dep.source.replace(\".\", \"_\")\n",
        "                plantuml.append(f\"{target_alias} <|-- {source_alias}\")\n",
        "            elif dep.type == \"dependency\":\n",
        "                plantuml.append(f\"{dep.source} ..> {dep.target}\")\n",
        "\n",
        "        plantuml.append(\"@enduml\")\n",
        "        return \"\\n\".join(plantuml)\n",
        "\n",
        "    def generate_component_diagram(self) -> str:\n",
        "        \"\"\"Generate PlantUML component diagram (modules as components).\"\"\"\n",
        "        plantuml = [\"@startuml\", \"skinparam componentStyle uml2\"]\n",
        "\n",
        "        # Components (modules)\n",
        "        for module_name in self.modules.keys():\n",
        "            plantuml.append(f\"component \\\"{module_name}\\\" as {module_name}\")\n",
        "\n",
        "        # Module-level dependencies\n",
        "        module_deps: Dict[(str, str), int] = {}\n",
        "        for dep in self.dependencies:\n",
        "            if dep.type == \"dependency\":\n",
        "                key = (dep.source, dep.target)\n",
        "                module_deps[key] = module_deps.get(key, 0) + 1\n",
        "\n",
        "        for (source, target), count in module_deps.items():\n",
        "            plantuml.append(f\"{source} --> {target}\")\n",
        "\n",
        "        plantuml.append(\"@enduml\")\n",
        "        return \"\\n\".join(plantuml)\n",
        "\n",
        "    def generate_architecture_report(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate a dictionary report of the architecture.\"\"\"\n",
        "        report: Dict[str, Any] = {\n",
        "            \"summary\": {\n",
        "                \"total_modules\": len(self.modules),\n",
        "                \"total_classes\": sum(len(m.classes) for m in self.modules.values()),\n",
        "                \"total_functions\": sum(len(m.functions) for m in self.modules.values()),\n",
        "                \"total_dependencies\": len(self.dependencies),\n",
        "            },\n",
        "            \"modules\": {},\n",
        "            \"dependencies\": [],\n",
        "            \"metrics\": self._calculate_metrics(),\n",
        "        }\n",
        "\n",
        "        for module_name, module_info in self.modules.items():\n",
        "            report[\"modules\"][module_name] = {\n",
        "                \"file_path\": module_info.file_path,\n",
        "                \"class_count\": len(module_info.classes),\n",
        "                \"function_count\": len(module_info.functions),\n",
        "                \"import_count\": len(module_info.imports),\n",
        "                \"classes\": [\n",
        "                    {\n",
        "                        \"name\": cls.name,\n",
        "                        \"method_count\": len(cls.methods),\n",
        "                        \"attribute_count\": len(cls.attributes),\n",
        "                        \"base_classes\": cls.base_classes,\n",
        "                        \"has_docstring\": bool(cls.docstring and cls.docstring.strip()),\n",
        "                    }\n",
        "                    for cls in module_info.classes\n",
        "                ],\n",
        "            }\n",
        "\n",
        "        for dep in self.dependencies:\n",
        "            report[\"dependencies\"].append({\"source\": dep.source, \"target\": dep.target, \"type\": dep.type})\n",
        "\n",
        "        return report\n",
        "\n",
        "    def _calculate_metrics(self) -> Dict[str, float]:\n",
        "        \"\"\"Calculate some simple architecture metrics.\"\"\"\n",
        "        metrics: Dict[str, float] = {}\n",
        "        if not self.modules:\n",
        "            return metrics\n",
        "\n",
        "        # Methods count across all classes\n",
        "        total_methods = sum(len(cls.methods) for m in self.modules.values() for cls in m.classes)\n",
        "        total_functions = sum(len(m.functions) for m in self.modules.values())\n",
        "\n",
        "        metrics[\"methods_per_module\"] = total_methods / len(self.modules) if self.modules else 0.0\n",
        "        metrics[\"functions_per_module\"] = total_functions / len(self.modules) if self.modules else 0.0\n",
        "\n",
        "        # Coupling (average outgoing deps per module)\n",
        "        outgoing_deps: Dict[str, int] = {}\n",
        "        incoming_deps: Dict[str, int] = {}\n",
        "        for dep in self.dependencies:\n",
        "            outgoing_deps[dep.source] = outgoing_deps.get(dep.source, 0) + 1\n",
        "            incoming_deps[dep.target] = incoming_deps.get(dep.target, 0) + 1\n",
        "\n",
        "        if outgoing_deps:\n",
        "            metrics[\"average_coupling\"] = sum(outgoing_deps.values()) / len(outgoing_deps)\n",
        "        else:\n",
        "            metrics[\"average_coupling\"] = 0.0\n",
        "\n",
        "        metrics[\"module_cohesion\"] = self._calculate_cohesion()\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _calculate_cohesion(self) -> float:\n",
        "        \"\"\"Simplified cohesion: for modules with >1 class, fraction of shared method names.\"\"\"\n",
        "        total_cohesion = 0.0\n",
        "        modules_count = 0\n",
        "\n",
        "        for module_info in self.modules.values():\n",
        "            if len(module_info.classes) > 1:\n",
        "                shared_methods = set()\n",
        "                all_methods = set()\n",
        "                for cls in module_info.classes:\n",
        "                    class_methods = set(cls.methods)\n",
        "                    shared_methods.update(all_methods.intersection(class_methods))\n",
        "                    all_methods.update(class_methods)\n",
        "                if all_methods:\n",
        "                    module_cohesion = len(shared_methods) / len(all_methods)\n",
        "                    total_cohesion += module_cohesion\n",
        "                    modules_count += 1\n",
        "\n",
        "        return total_cohesion / modules_count if modules_count > 0 else 1.0\n",
        "\n",
        "\n",
        "class DocumentationGenerator:\n",
        "    def __init__(self, analyzer: ArchitectureAnalyzer):\n",
        "        self.analyzer = analyzer\n",
        "\n",
        "    def generate_markdown_documentation(self, output_path: str):\n",
        "        \"\"\"Generate Markdown architecture documentation from the analyzer report.\"\"\"\n",
        "        report = self.analyzer.generate_architecture_report()\n",
        "\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"# Architecture Documentation\\n\\n\")\n",
        "\n",
        "            # Summary\n",
        "            f.write(\"## Summary\\n\\n\")\n",
        "            f.write(f\"- **Total Modules**: {report['summary']['total_modules']}\\n\")\n",
        "            f.write(f\"- **Total Classes**: {report['summary']['total_classes']}\\n\")\n",
        "            f.write(f\"- **Total Functions**: {report['summary']['total_functions']}\\n\")\n",
        "            f.write(f\"- **Total Dependencies**: {report['summary']['total_dependencies']}\\n\\n\")\n",
        "\n",
        "            # Metrics\n",
        "            f.write(\"## Architecture Metrics\\n\\n\")\n",
        "            for metric, value in report.get(\"metrics\", {}).items():\n",
        "                if isinstance(value, float):\n",
        "                    f.write(f\"- **{metric.replace('_', ' ').title()}**: {value:.2f}\\n\")\n",
        "                else:\n",
        "                    f.write(f\"- **{metric.replace('_', ' ').title()}**: {value}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "            # Modules\n",
        "            f.write(\"## Modules\\n\\n\")\n",
        "            for module_name, module_data in report[\"modules\"].items():\n",
        "                f.write(f\"### {module_name}\\n\\n\")\n",
        "                f.write(f\"- **File**: {module_data['file_path']}\\n\")\n",
        "                f.write(f\"- **Classes**: {module_data['class_count']}\\n\")\n",
        "                f.write(f\"- **Functions**: {module_data['function_count']}\\n\")\n",
        "                f.write(f\"- **Imports**: {module_data['import_count']}\\n\\n\")\n",
        "\n",
        "                if module_data[\"classes\"]:\n",
        "                    f.write(\"#### Classes\\n\\n\")\n",
        "                    for cls in module_data[\"classes\"]:\n",
        "                        f.write(f\"- **{cls['name']}**\\n\")\n",
        "                        f.write(f\"  - Methods: {cls['method_count']}\\n\")\n",
        "                        f.write(f\"  - Attributes: {cls['attribute_count']}\\n\")\n",
        "                        base_str = \", \".join(cls[\"base_classes\"]) if cls[\"base_classes\"] else \"None\"\n",
        "                        f.write(f\"  - Base Classes: {base_str}\\n\")\n",
        "                        f.write(f\"  - Documented: {'Yes' if cls['has_docstring'] else 'No'}\\n\\n\")\n",
        "\n",
        "            # Dependencies\n",
        "            f.write(\"## Dependencies\\n\\n\")\n",
        "            f.write(\"| Source | Target | Type |\\n\")\n",
        "            f.write(\"|---|---|---|\\n\")\n",
        "            for dep in report[\"dependencies\"][:1000]:\n",
        "                f.write(f\"| {dep['source']} | {dep['target']} | {dep['type']} |\\n\")\n",
        "\n",
        "        print(f\"Markdown documentation generated: {output_path}\")\n",
        "\n",
        "    def generate_plantuml_diagrams(self, output_dir: str):\n",
        "        \"\"\"Write PlantUML diagram files for class/component diagrams.\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        class_diagram = self.analyzer.generate_class_diagram()\n",
        "        with open(os.path.join(output_dir, \"class_diagram.puml\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(class_diagram)\n",
        "\n",
        "        component_diagram = self.analyzer.generate_component_diagram()\n",
        "        with open(os.path.join(output_dir, \"component_diagram.puml\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(component_diagram)\n",
        "\n",
        "        print(f\"PlantUML diagrams generated in: {output_dir}\")\n",
        "\n",
        "\n",
        "def demonstrate_analyzer():\n",
        "    \"\"\"Demonstration entrypoint for the analyzer.\"\"\"\n",
        "    print(\"=== Architecture Documentation Generator ===\")\n",
        "\n",
        "    analyzer = ArchitectureAnalyzer()\n",
        "\n",
        "    # Try to use the script directory; fall back to cwd\n",
        "    try:\n",
        "        current_dir = str(Path(__file__).parent)\n",
        "    except NameError:\n",
        "        current_dir = os.getcwd()\n",
        "\n",
        "    print(f\"Analyzing directory: {current_dir}\")\n",
        "    analyzer.analyze_directory(current_dir)\n",
        "\n",
        "    doc_generator = DocumentationGenerator(analyzer)\n",
        "\n",
        "    # Generate Markdown documentation and diagrams\n",
        "    output_md = os.path.join(current_dir, \"architecture_documentation.md\")\n",
        "    diagrams_dir = os.path.join(current_dir, \"diagrams\")\n",
        "\n",
        "    doc_generator.generate_markdown_documentation(output_md)\n",
        "    doc_generator.generate_plantuml_diagrams(diagrams_dir)\n",
        "\n",
        "    # Print summary\n",
        "    report = analyzer.generate_architecture_report()\n",
        "    print(\"\\n=== Analysis Summary ===\")\n",
        "    for key, value in report[\"summary\"].items():\n",
        "        print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "    print(\"\\n=== Architecture Metrics ===\")\n",
        "    for metric, value in report[\"metrics\"].items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"{metric.replace('_', ' ').title()}: {value:.2f}\")\n",
        "        else:\n",
        "            print(f\"{metric.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "    print(\"\\n=== Top Module Dependencies ===\")\n",
        "    dependency_count: Dict[(str, str), int] = {}\n",
        "    for dep in report[\"dependencies\"]:\n",
        "        if dep[\"type\"] == \"dependency\":\n",
        "            key = (dep[\"source\"], dep[\"target\"])\n",
        "            dependency_count[key] = dependency_count.get(key, 0) + 1\n",
        "\n",
        "    sorted_deps = sorted(dependency_count.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "    for (source, target), count in sorted_deps:\n",
        "        print(f\"{source} -> {target} ({count} dependencies)\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demonstrate_analyzer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl1002eMAbZg",
        "outputId": "8e1bd464-118f-4ef9-a7a1-98a3c80036cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Architecture Documentation Generator ===\n",
            "Analyzing directory: /content\n",
            "Markdown documentation generated: /content/architecture_documentation.md\n",
            "PlantUML diagrams generated in: /content/diagrams\n",
            "\n",
            "=== Analysis Summary ===\n",
            "Total Modules: 0\n",
            "Total Classes: 0\n",
            "Total Functions: 0\n",
            "Total Dependencies: 0\n",
            "\n",
            "=== Architecture Metrics ===\n",
            "\n",
            "=== Top Module Dependencies ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 15: Cloud-Native Patterns\n",
        "Objective: Implement cloud-native patterns including circuit breaker and retry mechanisms.\n",
        "Problem Statement: Create resilient microservices with circuit breakers, retries, and fallbacks.\n"
      ],
      "metadata": {
        "id": "RqcjAO6wCFx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Any, Callable, Optional, Dict\n",
        "from enum import Enum\n",
        "import threading\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "class CircuitState(Enum):\n",
        "    CLOSED = \"CLOSED\"       # Normal operation\n",
        "    OPEN = \"OPEN\"           # Fail fast, no requests\n",
        "    HALF_OPEN = \"HALF_OPEN\" # Testing if service recovered\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CircuitBreakerConfig:\n",
        "    failure_threshold: int = 5          # Failures before opening circuit\n",
        "    success_threshold: int = 3          # Successes before closing circuit\n",
        "    timeout_seconds: int = 60           # Time circuit stays open\n",
        "    half_open_max_requests: int = 3     # Max concurrent requests in half-open state\n",
        "\n",
        "\n",
        "class CircuitBreakerError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class CircuitBreaker:\n",
        "    def __init__(self, name: str, config: CircuitBreakerConfig = None):\n",
        "        self.name = name\n",
        "        self.config = config or CircuitBreakerConfig()\n",
        "        self.state = CircuitState.CLOSED\n",
        "        self.failure_count = 0\n",
        "        self.success_count = 0\n",
        "        self.last_failure_time: Optional[datetime] = None\n",
        "        self.last_state_change = datetime.now()\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "        # Track concurrent requests when in HALF_OPEN\n",
        "        self.half_open_current_requests = 0\n",
        "\n",
        "    def execute(self, func: Callable, *args, **kwargs) -> Any:\n",
        "        # First check and update state under lock\n",
        "        with self.lock:\n",
        "            # If OPEN, check timeout\n",
        "            if self.state == CircuitState.OPEN:\n",
        "                elapsed = (datetime.now() - self.last_state_change).total_seconds()\n",
        "                if elapsed >= self.config.timeout_seconds:\n",
        "                    self._transition_to_half_open()\n",
        "                else:\n",
        "                    raise CircuitBreakerError(f\"Circuit breaker '{self.name}' is OPEN\")\n",
        "\n",
        "            # If HALF_OPEN, enforce concurrent request limit\n",
        "            if self.state == CircuitState.HALF_OPEN:\n",
        "                if self.half_open_current_requests >= self.config.half_open_max_requests:\n",
        "                    raise CircuitBreakerError(\n",
        "                        f\"Circuit breaker '{self.name}' is in HALF_OPEN and at request limit\"\n",
        "                    )\n",
        "                # reserve a slot for this request\n",
        "                self.half_open_current_requests += 1\n",
        "\n",
        "        # Execute the function *without* holding the main lock (to avoid blocking)\n",
        "        try:\n",
        "            result = func(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            # On failure: update state\n",
        "            self._on_failure()\n",
        "            raise CircuitBreakerError(f\"Circuit breaker '{self.name}' caught exception: {e}\") from e\n",
        "        else:\n",
        "            # On success: update state\n",
        "            self._on_success()\n",
        "            return result\n",
        "        finally:\n",
        "            # If we had reserved a half-open slot, release it\n",
        "            with self.lock:\n",
        "                if self.state == CircuitState.HALF_OPEN and self.half_open_current_requests > 0:\n",
        "                    # If we transitioned away from HALF_OPEN in _on_success/_on_failure,\n",
        "                    # the counter was reset in the transition methods. Only decrement if still in HALF_OPEN.\n",
        "                    # But to be safe:\n",
        "                    if self.half_open_current_requests > 0:\n",
        "                        self.half_open_current_requests = max(0, self.half_open_current_requests - 1)\n",
        "\n",
        "    def _on_success(self):\n",
        "        with self.lock:\n",
        "            if self.state == CircuitState.HALF_OPEN:\n",
        "                self.success_count += 1\n",
        "                # If enough successes in half-open, close the circuit\n",
        "                if self.success_count >= self.config.success_threshold:\n",
        "                    self._transition_to_closed()\n",
        "            elif self.state == CircuitState.CLOSED:\n",
        "                # Reset failure_count on success during normal operation\n",
        "                self.failure_count = 0\n",
        "                self.success_count = 0\n",
        "\n",
        "    def _on_failure(self):\n",
        "        with self.lock:\n",
        "            self.failure_count += 1\n",
        "            self.last_failure_time = datetime.now()\n",
        "\n",
        "            if self.state == CircuitState.CLOSED and self.failure_count >= self.config.failure_threshold:\n",
        "                self._transition_to_open()\n",
        "            elif self.state == CircuitState.HALF_OPEN:\n",
        "                # Any failure in half-open should re-open\n",
        "                self._transition_to_open()\n",
        "\n",
        "    def _transition_to_open(self):\n",
        "        self.state = CircuitState.OPEN\n",
        "        self.last_state_change = datetime.now()\n",
        "        self.success_count = 0\n",
        "        self.half_open_current_requests = 0\n",
        "        print(f\"Circuit breaker '{self.name}' transitioned to OPEN\")\n",
        "\n",
        "    def _transition_to_half_open(self):\n",
        "        self.state = CircuitState.HALF_OPEN\n",
        "        self.last_state_change = datetime.now()\n",
        "        self.failure_count = 0\n",
        "        self.success_count = 0\n",
        "        self.half_open_current_requests = 0\n",
        "        print(f\"Circuit breaker '{self.name}' transitioned to HALF_OPEN\")\n",
        "\n",
        "    def _transition_to_closed(self):\n",
        "        self.state = CircuitState.CLOSED\n",
        "        self.last_state_change = datetime.now()\n",
        "        self.failure_count = 0\n",
        "        self.success_count = 0\n",
        "        self.half_open_current_requests = 0\n",
        "        print(f\"Circuit breaker '{self.name}' transitioned to CLOSED\")\n",
        "\n",
        "    def get_status(self) -> Dict:\n",
        "        with self.lock:\n",
        "            return {\n",
        "                \"name\": self.name,\n",
        "                \"state\": self.state.value,\n",
        "                \"failure_count\": self.failure_count,\n",
        "                \"success_count\": self.success_count,\n",
        "                \"last_state_change\": self.last_state_change.isoformat(),\n",
        "                \"is_closed\": self.state == CircuitState.CLOSED,\n",
        "                \"is_open\": self.state == CircuitState.OPEN,\n",
        "                \"is_half_open\": self.state == CircuitState.HALF_OPEN,\n",
        "                \"half_open_current_requests\": self.half_open_current_requests,\n",
        "                \"half_open_max_requests\": self.config.half_open_max_requests,\n",
        "            }\n",
        "\n",
        "\n",
        "class RetryError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class RetryStrategy:\n",
        "    def __init__(self, max_attempts: int = 3, base_delay: float = 1.0, max_delay: float = 30.0, exponential_base: float = 2.0):\n",
        "        self.max_attempts = max_attempts\n",
        "        self.base_delay = base_delay\n",
        "        self.max_delay = max_delay\n",
        "        self.exponential_base = exponential_base\n",
        "\n",
        "    def get_delay(self, attempt: int) -> float:\n",
        "        \"\"\"Calculate delay for retry attempt (attempt is 1-based).\"\"\"\n",
        "        delay = self.base_delay * (self.exponential_base ** (attempt - 1))\n",
        "        return min(delay, self.max_delay)\n",
        "\n",
        "\n",
        "class RetryManager:\n",
        "    def __init__(self, strategy: RetryStrategy = None):\n",
        "        self.strategy = strategy or RetryStrategy()\n",
        "\n",
        "    def execute_with_retry(self, func: Callable, *args, **kwargs) -> Any:\n",
        "        last_exception = None\n",
        "\n",
        "        for attempt in range(1, self.strategy.max_attempts + 1):\n",
        "            try:\n",
        "                return func(*args, **kwargs)\n",
        "            except Exception as e:\n",
        "                last_exception = e\n",
        "                print(f\"Attempt {attempt} failed: {e}\")\n",
        "\n",
        "                if attempt == self.strategy.max_attempts:\n",
        "                    break\n",
        "\n",
        "                delay = self.strategy.get_delay(attempt)\n",
        "                print(f\"Retrying in {delay:.2f} seconds...\")\n",
        "                time.sleep(delay)\n",
        "\n",
        "        raise RetryError(f\"All {self.strategy.max_attempts} attempts failed\") from last_exception\n",
        "\n",
        "\n",
        "class FallbackStrategy:\n",
        "    def __init__(self, fallback_func: Callable, fallback_on_exceptions: tuple = (Exception,)):\n",
        "        self.fallback_func = fallback_func\n",
        "        self.fallback_on_exceptions = fallback_on_exceptions\n",
        "\n",
        "    def execute_with_fallback(self, func: Callable, *args, **kwargs) -> Any:\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except self.fallback_on_exceptions as e:\n",
        "            print(f\"Primary operation failed, using fallback: {e}\")\n",
        "            return self.fallback_func(*args, **kwargs)\n",
        "\n",
        "\n",
        "class BulkheadError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class BulkheadPattern:\n",
        "    def __init__(self, max_concurrent: int = 10, name: str = \"default\"):\n",
        "        self.name = name\n",
        "        self.max_concurrent = max_concurrent\n",
        "        self.current_concurrent = 0\n",
        "        self.lock = threading.Lock()\n",
        "        self.semaphore = threading.Semaphore(max_concurrent)\n",
        "\n",
        "    def execute(self, func: Callable, *args, **kwargs) -> Any:\n",
        "        if not self.semaphore.acquire(blocking=False):\n",
        "            raise BulkheadError(f\"Bulkhead '{self.name}' is at capacity\")\n",
        "\n",
        "        try:\n",
        "            with self.lock:\n",
        "                self.current_concurrent += 1\n",
        "            return func(*args, **kwargs)\n",
        "        finally:\n",
        "            with self.lock:\n",
        "                self.current_concurrent = max(0, self.current_concurrent - 1)\n",
        "            self.semaphore.release()\n",
        "\n",
        "    def get_status(self) -> Dict:\n",
        "        with self.lock:\n",
        "            return {\n",
        "                \"name\": self.name,\n",
        "                \"max_concurrent\": self.max_concurrent,\n",
        "                \"current_concurrent\": self.current_concurrent,\n",
        "                \"available_capacity\": self.max_concurrent - self.current_concurrent,\n",
        "            }\n",
        "\n",
        "\n",
        "class ServiceError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class ResilientService:\n",
        "    \"\"\"Service with built-in resilience patterns\"\"\"\n",
        "\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "\n",
        "        # Initialize resilience patterns\n",
        "        self.circuit_breaker = CircuitBreaker(f\"{name}_cb\")\n",
        "        self.retry_manager = RetryManager()\n",
        "        self.bulkhead = BulkheadPattern(max_concurrent=5, name=f\"{name}_bh\")\n",
        "\n",
        "        # Statistics (not thread-safe counters for simplicity)\n",
        "        self.request_count = 0\n",
        "        self.success_count = 0\n",
        "        self.failure_count = 0\n",
        "        self._stats_lock = threading.Lock()\n",
        "\n",
        "    def call_external_service(self, should_fail: bool = False) -> str:\n",
        "        \"\"\"Simulate calling an external service\"\"\"\n",
        "        with self._stats_lock:\n",
        "            self.request_count += 1\n",
        "\n",
        "        # Simulate random failures (10% chance) or forced failure\n",
        "        if should_fail or random.random() < 0.1:\n",
        "            with self._stats_lock:\n",
        "                self.failure_count += 1\n",
        "            raise ServiceError(f\"External service {self.name} failed\")\n",
        "\n",
        "        # Simulate processing time\n",
        "        time.sleep(random.uniform(0.1, 0.5))\n",
        "\n",
        "        with self._stats_lock:\n",
        "            self.success_count += 1\n",
        "        return f\"Success from {self.name}\"\n",
        "\n",
        "    def fallback_method(self, *args, **kwargs) -> str:\n",
        "        \"\"\"Fallback method when primary service fails\"\"\"\n",
        "        return f\"Fallback response from {self.name}\"\n",
        "\n",
        "    def resilient_call(self, use_circuit_breaker: bool = True, use_retry: bool = True, use_bulkhead: bool = True, use_fallback: bool = True, should_fail: bool = False) -> str:\n",
        "        \"\"\"Make resilient call with configured patterns\"\"\"\n",
        "\n",
        "        def primary_operation():\n",
        "            return self.call_external_service(should_fail)\n",
        "\n",
        "        operation = primary_operation\n",
        "\n",
        "        # Apply fallback (wraps primary)\n",
        "        if use_fallback:\n",
        "            fallback_strategy = FallbackStrategy(self.fallback_method)\n",
        "            prev_op = operation\n",
        "            operation = lambda: fallback_strategy.execute_with_fallback(prev_op)\n",
        "\n",
        "        # Apply bulkhead\n",
        "        if use_bulkhead:\n",
        "            prev_op = operation\n",
        "            operation = lambda: self.bulkhead.execute(prev_op)\n",
        "\n",
        "        # Apply retry\n",
        "        if use_retry:\n",
        "            prev_op = operation\n",
        "            operation = lambda: self.retry_manager.execute_with_retry(prev_op)\n",
        "\n",
        "        # Apply circuit breaker\n",
        "        if use_circuit_breaker:\n",
        "            prev_op = operation\n",
        "            operation = lambda: self.circuit_breaker.execute(prev_op)\n",
        "\n",
        "        return operation()\n",
        "\n",
        "    def get_service_stats(self) -> Dict:\n",
        "        \"\"\"Get service statistics\"\"\"\n",
        "        cb_status = self.circuit_breaker.get_status()\n",
        "        bh_status = self.bulkhead.get_status()\n",
        "        with self._stats_lock:\n",
        "            total = self.request_count\n",
        "            success = self.success_count\n",
        "            failed = self.failure_count\n",
        "            success_rate = (success / total * 100) if total > 0 else 0.0\n",
        "\n",
        "        return {\n",
        "            \"service_name\": self.name,\n",
        "            \"requests\": {\n",
        "                \"total\": total,\n",
        "                \"successful\": success,\n",
        "                \"failed\": failed,\n",
        "                \"success_rate\": success_rate,\n",
        "            },\n",
        "            \"circuit_breaker\": cb_status,\n",
        "            \"bulkhead\": bh_status,\n",
        "        }\n",
        "\n",
        "\n",
        "class CloudNativeOrchestrator:\n",
        "    \"\"\"Orchestrator for demonstrating cloud-native patterns\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.services: Dict[str, ResilientService] = {}\n",
        "        self.setup_services()\n",
        "\n",
        "    def setup_services(self):\n",
        "        \"\"\"Setup resilient services\"\"\"\n",
        "        service_names = [\"user-service\", \"order-service\", \"payment-service\", \"inventory-service\"]\n",
        "        for name in service_names:\n",
        "            self.services[name] = ResilientService(name)\n",
        "\n",
        "    def simulate_traffic(self, duration_seconds: int = 60, requests_per_second: int = 10):\n",
        "        \"\"\"Simulate traffic to all services\"\"\"\n",
        "        print(f\"=== Simulating Traffic for {duration_seconds} seconds ===\")\n",
        "\n",
        "        end_time = time.time() + duration_seconds\n",
        "        request_count = 0\n",
        "\n",
        "        while time.time() < end_time:\n",
        "            threads = []\n",
        "\n",
        "            # Create multiple concurrent requests\n",
        "            for _ in range(requests_per_second):\n",
        "                for service_name, service in self.services.items():\n",
        "                    # Randomly decide if this request should fail\n",
        "                    should_fail = random.random() < 0.15  # 15% forced failure rate\n",
        "\n",
        "                    thread = threading.Thread(\n",
        "                        target=self._make_resilient_call,\n",
        "                        args=(service, should_fail),\n",
        "                    )\n",
        "                    threads.append(thread)\n",
        "                    thread.start()\n",
        "                    request_count += 1\n",
        "\n",
        "            # Wait for all threads to complete\n",
        "            for thread in threads:\n",
        "                thread.join()\n",
        "\n",
        "            time.sleep(1)  # Wait 1 second between batches\n",
        "\n",
        "        print(f\"Completed {request_count} requests\")\n",
        "\n",
        "    def _make_resilient_call(self, service: ResilientService, should_fail: bool):\n",
        "        \"\"\"Make a resilient call to a service\"\"\"\n",
        "        try:\n",
        "            result = service.resilient_call(\n",
        "                use_circuit_breaker=True,\n",
        "                use_retry=True,\n",
        "                use_bulkhead=True,\n",
        "                use_fallback=True,\n",
        "                should_fail=should_fail,\n",
        "            )\n",
        "            print(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Service call failed: {e}\")\n",
        "\n",
        "    def display_dashboard(self):\n",
        "        \"\"\"Display current status dashboard\"\"\"\n",
        "        print(\"\\n=== Resilience Patterns Dashboard ===\")\n",
        "        for service_name, service in self.services.items():\n",
        "            stats = service.get_service_stats()\n",
        "            print(f\"\\n{service_name}:\")\n",
        "            print(f\"  Requests: {stats['requests']['total']} ({stats['requests']['success_rate']:.1f}% success)\")\n",
        "            cb_state = stats[\"circuit_breaker\"][\"state\"]\n",
        "            print(f\"  Circuit Breaker: {cb_state} (failures: {stats['circuit_breaker']['failure_count']})\")\n",
        "            bh_usage = stats[\"bulkhead\"][\"current_concurrent\"]\n",
        "            bh_max = stats[\"bulkhead\"][\"max_concurrent\"]\n",
        "            print(f\"  Bulkhead: {bh_usage}/{bh_max} concurrent\")\n",
        "\n",
        "\n",
        "def demonstrate_resilience_patterns():\n",
        "    \"\"\"Demonstrate individual resilience patterns\"\"\"\n",
        "    print(\"=== Individual Resilience Patterns Demo ===\")\n",
        "\n",
        "    service = ResilientService(\"demo-service\")\n",
        "\n",
        "    # Test circuit breaker by forcing failures\n",
        "    print(\"\\n1. Testing Circuit Breaker:\")\n",
        "    for i in range(10):\n",
        "        try:\n",
        "            result = service.resilient_call(\n",
        "                use_circuit_breaker=True,\n",
        "                use_retry=False,\n",
        "                use_bulkhead=False,\n",
        "                use_fallback=False,\n",
        "                should_fail=True,  # Force failures\n",
        "            )\n",
        "            print(f\"Request {i + 1}: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Request {i + 1}: {e}\")\n",
        "\n",
        "    # Wait for circuit to potentially half-open\n",
        "    print(\"\\nWaiting for circuit breaker timeout + 5s...\")\n",
        "    time.sleep(service.circuit_breaker.config.timeout_seconds + 5)\n",
        "\n",
        "    # Test with recovery (no forced failures)\n",
        "    print(\"\\n2. Testing Recovery:\")\n",
        "    for i in range(5):\n",
        "        try:\n",
        "            result = service.resilient_call(\n",
        "                use_circuit_breaker=True,\n",
        "                use_retry=False,\n",
        "                use_bulkhead=False,\n",
        "                use_fallback=False,\n",
        "                should_fail=False,  # No forced failures\n",
        "            )\n",
        "            print(f\"Request {i + 1}: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Request {i + 1}: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Demonstrate individual patterns\n",
        "    demonstrate_resilience_patterns()\n",
        "\n",
        "    # Run orchestrated simulation\n",
        "    orchestrator = CloudNativeOrchestrator()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    orchestrator.display_dashboard()\n",
        "\n",
        "    print(\"\\nStarting traffic simulation ...\")\n",
        "    orchestrator.simulate_traffic(duration_seconds=10, requests_per_second=3)\n",
        "\n",
        "    print(\"\\nFinal Status:\")\n",
        "    orchestrator.display_dashboard()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzIS88JoClEb",
        "outputId": "049aaa86-e490-4b26-df0b-d14deab50c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Individual Resilience Patterns Demo ===\n",
            "\n",
            "1. Testing Circuit Breaker:\n",
            "Request 1: Circuit breaker 'demo-service_cb' caught exception: External service demo-service failed\n",
            "Request 2: Circuit breaker 'demo-service_cb' caught exception: External service demo-service failed\n",
            "Request 3: Circuit breaker 'demo-service_cb' caught exception: External service demo-service failed\n",
            "Request 4: Circuit breaker 'demo-service_cb' caught exception: External service demo-service failed\n",
            "Circuit breaker 'demo-service_cb' transitioned to OPEN\n",
            "Request 5: Circuit breaker 'demo-service_cb' caught exception: External service demo-service failed\n",
            "Request 6: Circuit breaker 'demo-service_cb' is OPEN\n",
            "Request 7: Circuit breaker 'demo-service_cb' is OPEN\n",
            "Request 8: Circuit breaker 'demo-service_cb' is OPEN\n",
            "Request 9: Circuit breaker 'demo-service_cb' is OPEN\n",
            "Request 10: Circuit breaker 'demo-service_cb' is OPEN\n",
            "\n",
            "Waiting for circuit breaker timeout + 5s...\n",
            "\n",
            "2. Testing Recovery:\n",
            "Circuit breaker 'demo-service_cb' transitioned to HALF_OPEN\n",
            "Circuit breaker 'demo-service_cb' transitioned to OPEN\n",
            "Request 1: Circuit breaker 'demo-service_cb' caught exception: External service demo-service failed\n",
            "Request 2: Circuit breaker 'demo-service_cb' is OPEN\n",
            "Request 3: Circuit breaker 'demo-service_cb' is OPEN\n",
            "Request 4: Circuit breaker 'demo-service_cb' is OPEN\n",
            "Request 5: Circuit breaker 'demo-service_cb' is OPEN\n",
            "\n",
            "==================================================\n",
            "\n",
            "=== Resilience Patterns Dashboard ===\n",
            "\n",
            "user-service:\n",
            "  Requests: 0 (0.0% success)\n",
            "  Circuit Breaker: CLOSED (failures: 0)\n",
            "  Bulkhead: 0/5 concurrent\n",
            "\n",
            "order-service:\n",
            "  Requests: 0 (0.0% success)\n",
            "  Circuit Breaker: CLOSED (failures: 0)\n",
            "  Bulkhead: 0/5 concurrent\n",
            "\n",
            "payment-service:\n",
            "  Requests: 0 (0.0% success)\n",
            "  Circuit Breaker: CLOSED (failures: 0)\n",
            "  Bulkhead: 0/5 concurrent\n",
            "\n",
            "inventory-service:\n",
            "  Requests: 0 (0.0% success)\n",
            "  Circuit Breaker: CLOSED (failures: 0)\n",
            "  Bulkhead: 0/5 concurrent\n",
            "\n",
            "Starting traffic simulation ...\n",
            "=== Simulating Traffic for 10 seconds ===\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n",
            "Attempt 1 failed: maximum recursion depth exceeded\n",
            "Retrying in 1.00 seconds...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Lab 16: DevOps and CI/CD Pipeline Simulation\n",
        "Objective: Simulate a complete CI/CD pipeline with automated testing and deployment.\n",
        "Problem Statement: Create a pipeline simulator that handles code integration, testing, and deployment."
      ],
      "metadata": {
        "id": "iQ58DYgTDK1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Dict, Any, Optional, Callable\n",
        "from enum import Enum\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "import json\n",
        "import statistics\n",
        "\n",
        "\n",
        "class PipelineStage(Enum):\n",
        "    SOURCE = \"source\"\n",
        "    BUILD = \"build\"\n",
        "    TEST = \"test\"\n",
        "    SECURITY_SCAN = \"security_scan\"\n",
        "    DEPLOY_STAGING = \"deploy_staging\"\n",
        "    INTEGRATION_TEST = \"integration_test\"\n",
        "    DEPLOY_PRODUCTION = \"deploy_production\"\n",
        "\n",
        "\n",
        "class BuildStatus(Enum):\n",
        "    PENDING = \"pending\"\n",
        "    RUNNING = \"running\"\n",
        "    SUCCESS = \"success\"\n",
        "    FAILED = \"failed\"\n",
        "    CANCELLED = \"cancelled\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CodeChange:\n",
        "    commit_hash: str\n",
        "    author: str\n",
        "    message: str\n",
        "    timestamp: datetime\n",
        "    files_changed: List[str]\n",
        "    lines_added: int\n",
        "    lines_removed: int\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BuildResult:\n",
        "    build_id: str\n",
        "    status: BuildStatus\n",
        "    stages: Dict[PipelineStage, BuildStatus]\n",
        "    duration: float\n",
        "    logs: List[str]\n",
        "    artifacts: List[str]\n",
        "    test_results: Optional[Dict[str, Any]] = None\n",
        "    security_issues: Optional[List[Dict[str, Any]]] = None\n",
        "\n",
        "\n",
        "class VersionControlSystem(ABC):\n",
        "    @abstractmethod\n",
        "    def get_latest_changes(self) -> List[CodeChange]:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_branch(self, name: str) -> bool:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def merge_branch(self, source: str, target: str) -> bool:\n",
        "        pass\n",
        "\n",
        "\n",
        "class GitSimulator(VersionControlSystem):\n",
        "    def __init__(self):\n",
        "        self.branches = [\"main\", \"develop\"]\n",
        "        self.commits: List[CodeChange] = []\n",
        "        self.current_branch = \"main\"\n",
        "\n",
        "    def get_latest_changes(self) -> List[CodeChange]:\n",
        "        # Simulate getting recent commits\n",
        "        changes: List[CodeChange] = []\n",
        "        for _ in range(random.randint(1, 3)):\n",
        "            ch = CodeChange(\n",
        "                commit_hash=hashlib.md5(str(time.time()).encode()).hexdigest()[:8],\n",
        "                author=f\"developer{random.randint(1, 5)}\",\n",
        "                message=self._generate_commit_message(),\n",
        "                timestamp=datetime.now(),\n",
        "                files_changed=[f\"file{random.randint(1, 10)}.py\"],\n",
        "                lines_added=random.randint(1, 50),\n",
        "                lines_removed=random.randint(0, 20),\n",
        "            )\n",
        "            changes.append(ch)\n",
        "            self.commits.append(ch)\n",
        "        return changes\n",
        "\n",
        "    def create_branch(self, name: str) -> bool:\n",
        "        if name not in self.branches:\n",
        "            self.branches.append(name)\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def merge_branch(self, source: str, target: str) -> bool:\n",
        "        if source in self.branches and target in self.branches:\n",
        "            print(f\"Merged branch '{source}' into '{target}'\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _generate_commit_message(self) -> str:\n",
        "        messages = [\n",
        "            \"Fix bug in user authentication\",\n",
        "            \"Add new API endpoint for orders\",\n",
        "            \"Refactor database layer\",\n",
        "            \"Update documentation\",\n",
        "            \"Optimize performance\",\n",
        "            \"Add unit tests\",\n",
        "            \"Fix security vulnerability\",\n",
        "            \"Update dependencies\",\n",
        "            \"Improve error handling\",\n",
        "            \"Add feature flag for new functionality\",\n",
        "        ]\n",
        "        return random.choice(messages)\n",
        "\n",
        "\n",
        "class TestRunner(ABC):\n",
        "    @abstractmethod\n",
        "    def run_unit_tests(self) -> Dict[str, Any]:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def run_integration_tests(self) -> Dict[str, Any]:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def run_performance_tests(self) -> Dict[str, Any]:\n",
        "        pass\n",
        "\n",
        "\n",
        "class PythonTestRunner(TestRunner):\n",
        "    def run_unit_tests(self) -> Dict[str, Any]:\n",
        "        # Simulate running unit tests\n",
        "        time.sleep(random.uniform(0.1, 0.3))\n",
        "\n",
        "        total_tests = random.randint(50, 200)\n",
        "        failed_tests = random.randint(0, 5)\n",
        "        passed_tests = total_tests - failed_tests\n",
        "\n",
        "        return {\n",
        "            \"type\": \"unit\",\n",
        "            \"total_tests\": total_tests,\n",
        "            \"passed\": passed_tests,\n",
        "            \"failed\": failed_tests,\n",
        "            \"success_rate\": (passed_tests / total_tests) * 100,\n",
        "            \"duration\": random.uniform(1, 3),\n",
        "            \"failed_test_cases\": [] if failed_tests == 0 else [f\"test_user_authentication_{i}\" for i in range(failed_tests)],\n",
        "        }\n",
        "\n",
        "    def run_integration_tests(self) -> Dict[str, Any]:\n",
        "        time.sleep(random.uniform(0.1, 0.2))\n",
        "\n",
        "        total_tests = random.randint(20, 50)\n",
        "        failed_tests = random.randint(0, 3)\n",
        "        passed_tests = total_tests - failed_tests\n",
        "\n",
        "        return {\n",
        "            \"type\": \"integration\",\n",
        "            \"total_tests\": total_tests,\n",
        "            \"passed\": passed_tests,\n",
        "            \"failed\": failed_tests,\n",
        "            \"success_rate\": (passed_tests / total_tests) * 100,\n",
        "            \"duration\": random.uniform(2, 4),\n",
        "            \"failed_test_cases\": [] if failed_tests == 0 else [f\"test_order_workflow_{i}\" for i in range(failed_tests)],\n",
        "        }\n",
        "\n",
        "    def run_performance_tests(self) -> Dict[str, Any]:\n",
        "        time.sleep(random.uniform(0.1, 0.2))\n",
        "        return {\n",
        "            \"type\": \"performance\",\n",
        "            \"response_time_avg\": random.uniform(100, 500),\n",
        "            \"throughput\": random.randint(100, 1000),\n",
        "            \"error_rate\": random.uniform(0, 2),\n",
        "            \"memory_usage\": random.uniform(50, 200),\n",
        "            \"cpu_usage\": random.uniform(10, 80),\n",
        "        }\n",
        "\n",
        "\n",
        "class SecurityScanner:\n",
        "    def scan_code(self) -> List[Dict[str, Any]]:\n",
        "        # Simulate security scanning\n",
        "        time.sleep(random.uniform(0.1, 0.3))\n",
        "        issues: List[Dict[str, Any]] = []\n",
        "        vulnerability_types = [\n",
        "            \"SQL Injection\",\n",
        "            \"XSS\",\n",
        "            \"CSRF\",\n",
        "            \"Insecure Deserialization\",\n",
        "            \"Broken Authentication\",\n",
        "            \"Sensitive Data Exposure\",\n",
        "        ]\n",
        "        for _ in range(random.randint(0, 3)):\n",
        "            issues.append({\n",
        "                \"type\": random.choice(vulnerability_types),\n",
        "                \"severity\": random.choice([\"low\", \"medium\", \"high\"]),\n",
        "                \"file\": f\"file{random.randint(1, 10)}.py\",\n",
        "                \"line\": random.randint(1, 100),\n",
        "                \"description\": f\"Potential {random.choice(vulnerability_types)} vulnerability\",\n",
        "            })\n",
        "        return issues\n",
        "\n",
        "    def scan_dependencies(self) -> List[Dict[str, Any]]:\n",
        "        time.sleep(random.uniform(0.1, 0.2))\n",
        "        issues: List[Dict[str, Any]] = []\n",
        "        packages = [\"requests\", \"flask\", \"django\", \"numpy\", \"pandas\"]\n",
        "        for _ in range(random.randint(0, 2)):\n",
        "            issues.append({\n",
        "                \"package\": random.choice(packages),\n",
        "                \"version\": f\"{random.randint(1,3)}.{random.randint(0,9)}.{random.randint(0,9)}\",\n",
        "                \"vulnerability\": \"CVE-2023-\" + str(random.randint(1000, 9999)),\n",
        "                \"severity\": random.choice([\"low\", \"medium\", \"high\"]),\n",
        "                \"fixed_in\": f\"{random.randint(1,3)}.{random.randint(0,9)}.{random.randint(1,9)}\",\n",
        "            })\n",
        "        return issues\n",
        "\n",
        "\n",
        "class DeploymentManager:\n",
        "    def __init__(self):\n",
        "        self.environments = [\"staging\", \"production\"]\n",
        "        self.deployment_history: List[Dict[str, Any]] = []\n",
        "\n",
        "    def deploy_to_staging(self, build_artifact: str) -> bool:\n",
        "        print(\"Deploying to staging environment ...\")\n",
        "        time.sleep(random.uniform(0.1, 0.3))\n",
        "        success = random.random() > 0.1  # 90% success\n",
        "        print(\"Staging deployment successful\" if success else \"Staging deployment failed\")\n",
        "        self.deployment_history.append({\n",
        "            \"environment\": \"staging\",\n",
        "            \"artifact\": build_artifact,\n",
        "            \"timestamp\": datetime.now(),\n",
        "            \"success\": success,\n",
        "        })\n",
        "        return success\n",
        "\n",
        "    def deploy_to_production(self, build_artifact: str) -> bool:\n",
        "        print(\"Deploying to production environment ...\")\n",
        "        time.sleep(random.uniform(0.1, 0.3))\n",
        "        success = random.random() > 0.05  # 95% success\n",
        "        print(\"Production deployment successful\" if success else \"Production deployment failed\")\n",
        "        self.deployment_history.append({\n",
        "            \"environment\": \"production\",\n",
        "            \"artifact\": build_artifact,\n",
        "            \"timestamp\": datetime.now(),\n",
        "            \"success\": success,\n",
        "        })\n",
        "        return success\n",
        "\n",
        "    def rollback_production(self) -> bool:\n",
        "        print(\"Rolling back production deployment ...\")\n",
        "        time.sleep(random.uniform(0.1, 0.2))\n",
        "        success = random.random() > 0.02\n",
        "        print(\"Production rollback successful\" if success else \"Production rollback failed\")\n",
        "        return success\n",
        "\n",
        "\n",
        "class CICDPipeline:\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "        self.vcs = GitSimulator()\n",
        "        self.test_runner = PythonTestRunner()\n",
        "        self.security_scanner = SecurityScanner()\n",
        "        self.deployment_manager = DeploymentManager()\n",
        "\n",
        "        self.build_history: List[BuildResult] = []\n",
        "        self.current_build: Optional[BuildResult] = None\n",
        "\n",
        "        # Pipeline configuration\n",
        "        self.auto_deploy_to_production = False\n",
        "        self.required_success_rate = 95.0\n",
        "        self.max_security_issues = 2\n",
        "\n",
        "    def trigger_build(self, changes: List[CodeChange]) -> BuildResult:\n",
        "        \"\"\"Trigger a new build for the given changes\"\"\"\n",
        "        build_id = f\"build_{len(self.build_history) + 1:04d}\"\n",
        "\n",
        "        self.current_build = BuildResult(\n",
        "            build_id=build_id,\n",
        "            status=BuildStatus.RUNNING,\n",
        "            stages={},\n",
        "            duration=0.0,\n",
        "            logs=[],\n",
        "            artifacts=[],\n",
        "            test_results=None,\n",
        "            security_issues=[],\n",
        "        )\n",
        "\n",
        "        print(f\"=== Starting Build {build_id} ===\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Execute pipeline stages\n",
        "            self._execute_stage(PipelineStage.SOURCE, self._source_stage, changes)\n",
        "            self._execute_stage(PipelineStage.BUILD, self._build_stage)\n",
        "            self._execute_stage(PipelineStage.TEST, self._test_stage)\n",
        "            self._execute_stage(PipelineStage.SECURITY_SCAN, self._security_scan_stage)\n",
        "\n",
        "            # Only proceed if previous stages were successful\n",
        "            if self.current_build.status == BuildStatus.SUCCESS:\n",
        "                self._execute_stage(PipelineStage.DEPLOY_STAGING, self._deploy_staging_stage)\n",
        "                self._execute_stage(PipelineStage.INTEGRATION_TEST, self._integration_test_stage)\n",
        "\n",
        "            # Deploy to production if enabled and all checks pass\n",
        "            if self.auto_deploy_to_production and self.current_build.status == BuildStatus.SUCCESS:\n",
        "                self._execute_stage(PipelineStage.DEPLOY_PRODUCTION, self._deploy_production_stage)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.current_build.status = BuildStatus.FAILED\n",
        "            self.current_build.logs.append(f\"Pipeline failed with error: {e}\")\n",
        "\n",
        "        # Calculate total duration\n",
        "        self.current_build.duration = time.time() - start_time\n",
        "\n",
        "        # Add to build history\n",
        "        self.build_history.append(self.current_build)\n",
        "\n",
        "        print(f\"=== Build {build_id} completed with status: {self.current_build.status.value} ===\")\n",
        "        return self.current_build\n",
        "\n",
        "    def _execute_stage(self, stage: PipelineStage, stage_func: Callable, *args):\n",
        "        \"\"\"Execute a pipeline stage and update build status\"\"\"\n",
        "        if self.current_build.status != BuildStatus.RUNNING:\n",
        "            return\n",
        "\n",
        "        self.current_build.stages[stage] = BuildStatus.RUNNING\n",
        "        self.current_build.logs.append(f\"Starting {stage.value} stage...\")\n",
        "\n",
        "        try:\n",
        "            result = stage_func(*args) if args else stage_func()\n",
        "            if result:\n",
        "                self.current_build.stages[stage] = BuildStatus.SUCCESS\n",
        "                self.current_build.logs.append(f\"{stage.value} stage completed successfully\")\n",
        "                # if all stages so far succeeded, keep build as success; otherwise remains running\n",
        "                if all(s == BuildStatus.SUCCESS for s in self.current_build.stages.values()):\n",
        "                    self.current_build.status = BuildStatus.SUCCESS\n",
        "            else:\n",
        "                self.current_build.stages[stage] = BuildStatus.FAILED\n",
        "                self.current_build.status = BuildStatus.FAILED\n",
        "                self.current_build.logs.append(f\"{stage.value} stage failed\")\n",
        "        except Exception as e:\n",
        "            self.current_build.stages[stage] = BuildStatus.FAILED\n",
        "            self.current_build.status = BuildStatus.FAILED\n",
        "            self.current_build.logs.append(f\"{stage.value} stage failed with error: {e}\")\n",
        "\n",
        "    def _source_stage(self, changes: List[CodeChange]) -> bool:\n",
        "        \"\"\"Source stage: fetch and validate code changes\"\"\"\n",
        "        time.sleep(0.05)\n",
        "        self.current_build.logs.extend([\n",
        "            f\"Processing {len(changes)} commit(s)\",\n",
        "            f\"Latest commit: {changes[0].message if changes else 'No changes'}\",\n",
        "        ])\n",
        "        return True\n",
        "\n",
        "    def _build_stage(self) -> bool:\n",
        "        \"\"\"Build stage: compile and package application\"\"\"\n",
        "        time.sleep(random.uniform(0.05, 0.2))\n",
        "        success = random.random() > 0.05  # 95% success rate\n",
        "\n",
        "        if success:\n",
        "            artifact = f\"app_{self.current_build.build_id}.zip\"\n",
        "            self.current_build.artifacts.append(artifact)\n",
        "            self.current_build.logs.append(f\"Created build artifact: {artifact}\")\n",
        "        else:\n",
        "            self.current_build.logs.append(\"Build failed: compilation errors\")\n",
        "\n",
        "        return success\n",
        "\n",
        "    def _test_stage(self) -> bool:\n",
        "        \"\"\"Test stage: run automated tests\"\"\"\n",
        "        test_results = self.test_runner.run_unit_tests()\n",
        "        self.current_build.test_results = test_results\n",
        "\n",
        "        self.current_build.logs.extend([\n",
        "            f\"Unit tests: {test_results['passed']}/{test_results['total_tests']} passed\",\n",
        "            f\"Success rate: {test_results['success_rate']:.1f}%\",\n",
        "        ])\n",
        "\n",
        "        # Check if success rate meets requirement\n",
        "        if test_results['success_rate'] < self.required_success_rate:\n",
        "            self.current_build.logs.append(\n",
        "                f\"Test success rate {test_results['success_rate']:.1f}% below required {self.required_success_rate}%\"\n",
        "            )\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _security_scan_stage(self) -> bool:\n",
        "        \"\"\"Security scan stage: check for vulnerabilities\"\"\"\n",
        "        code_issues = self.security_scanner.scan_code()\n",
        "        dependency_issues = self.security_scanner.scan_dependencies()\n",
        "\n",
        "        all_issues = code_issues + dependency_issues\n",
        "        self.current_build.security_issues = all_issues\n",
        "\n",
        "        high_severity_issues = [issue for issue in all_issues if issue.get(\"severity\") == \"high\"]\n",
        "\n",
        "        self.current_build.logs.append(\n",
        "            f\"Security scan: {len(all_issues)} issues found ({len(high_severity_issues)} high severity)\"\n",
        "        )\n",
        "\n",
        "        # Fail if too many high severity security issues\n",
        "        if len(high_severity_issues) > self.max_security_issues:\n",
        "            self.current_build.logs.append(f\"Too many high severity security issues: {len(high_severity_issues)}\")\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _deploy_staging_stage(self) -> bool:\n",
        "        \"\"\"Deploy to staging environment\"\"\"\n",
        "        if not self.current_build.artifacts:\n",
        "            return False\n",
        "        artifact = self.current_build.artifacts[0]\n",
        "        return self.deployment_manager.deploy_to_staging(artifact)\n",
        "\n",
        "    def _integration_test_stage(self) -> bool:\n",
        "        \"\"\"Run integration tests in staging\"\"\"\n",
        "        test_results = self.test_runner.run_integration_tests()\n",
        "        if self.current_build.test_results is None:\n",
        "            self.current_build.test_results = {}\n",
        "        self.current_build.test_results[\"integration\"] = test_results\n",
        "\n",
        "        self.current_build.logs.extend([\n",
        "            f\"Integration tests: {test_results['passed']}/{test_results['total_tests']} passed\",\n",
        "            f\"Success rate: {test_results['success_rate']:.1f}%\",\n",
        "        ])\n",
        "\n",
        "        return test_results['success_rate'] >= self.required_success_rate\n",
        "\n",
        "    def _deploy_production_stage(self) -> bool:\n",
        "        \"\"\"Deploy to production environment\"\"\"\n",
        "        if not self.current_build.artifacts:\n",
        "            return False\n",
        "        artifact = self.current_build.artifacts[0]\n",
        "        return self.deployment_manager.deploy_to_production(artifact)\n",
        "\n",
        "    def get_pipeline_metrics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get pipeline performance metrics\"\"\"\n",
        "        if not self.build_history:\n",
        "            return {}\n",
        "\n",
        "        successful_builds = [b for b in self.build_history if b.status == BuildStatus.SUCCESS]\n",
        "        failed_builds = [b for b in self.build_history if b.status == BuildStatus.FAILED]\n",
        "\n",
        "        total_duration = sum(b.duration for b in self.build_history)\n",
        "        avg_duration = total_duration / len(self.build_history) if self.build_history else 0\n",
        "\n",
        "        success_rate = (len(successful_builds) / len(self.build_history)) * 100\n",
        "\n",
        "        # Stage success rates\n",
        "        stage_success_rates: Dict[str, float] = {}\n",
        "        for stage in PipelineStage:\n",
        "            stage_builds = [b for b in self.build_history if stage in b.stages]\n",
        "            if stage_builds:\n",
        "                successful_stage = [b for b in stage_builds if b.stages[stage] == BuildStatus.SUCCESS]\n",
        "                stage_success_rates[stage.value] = (len(successful_stage) / len(stage_builds)) * 100\n",
        "\n",
        "        return {\n",
        "            \"total_builds\": len(self.build_history),\n",
        "            \"successful_builds\": len(successful_builds),\n",
        "            \"failed_builds\": len(failed_builds),\n",
        "            \"success_rate\": success_rate,\n",
        "            \"average_duration\": avg_duration,\n",
        "            \"stage_success_rates\": stage_success_rates,\n",
        "        }\n",
        "\n",
        "    def print_build_report(self, build: BuildResult):\n",
        "        \"\"\"Print detailed build report\"\"\"\n",
        "        print(f\"\\n=== Build Report: {build.build_id} ===\")\n",
        "        print(f\"Status: {build.status.value}\")\n",
        "        print(f\"Duration: {build.duration:.2f} seconds\")\n",
        "\n",
        "        print(\"\\nStages:\")\n",
        "        for stage, status in build.stages.items():\n",
        "            print(f\"  {stage.value}: {status.value}\")\n",
        "\n",
        "        if build.test_results:\n",
        "            print(\"\\nTest Results:\")\n",
        "            # If a single suite returned as dict with 'type' key\n",
        "            if isinstance(build.test_results, dict) and \"type\" in build.test_results:\n",
        "                tr = build.test_results\n",
        "                print(f\"  {tr['type']}: {tr['passed']}/{tr['total_tests']} ({tr['success_rate']:.1f}%)\")\n",
        "            else:\n",
        "                for test_type, results in build.test_results.items():\n",
        "                    if isinstance(results, dict):\n",
        "                        print(f\"  {test_type}: {results['passed']}/{results['total_tests']} ({results['success_rate']:.1f}%)\")\n",
        "\n",
        "        if build.security_issues:\n",
        "            print(f\"\\nSecurity Issues: {len(build.security_issues)}\")\n",
        "            for issue in build.security_issues[:3]:\n",
        "                print(f\"  {issue.get('severity','').upper()}: {issue.get('type')} - {issue.get('description')}\")\n",
        "\n",
        "        print(\"\\nLogs (last 5):\")\n",
        "        for log in build.logs[-5:]:\n",
        "            print(f\"  {log}\")\n",
        "\n",
        "\n",
        "class DevOpsMonitor:\n",
        "    \"\"\"Monitor for tracking DevOps metrics and trends\"\"\"\n",
        "\n",
        "    def __init__(self, pipelines: List[CICDPipeline]):\n",
        "        self.pipelines = pipelines\n",
        "        self.metrics_history: List[Dict[str, Any]] = []\n",
        "\n",
        "    def collect_metrics(self):\n",
        "        \"\"\"Collect metrics from all pipelines\"\"\"\n",
        "        timestamp = datetime.now()\n",
        "        metrics_snapshot: Dict[str, Any] = {\n",
        "            \"timestamp\": timestamp,\n",
        "            \"pipelines\": {},\n",
        "        }\n",
        "\n",
        "        for pipeline in self.pipelines:\n",
        "            metrics = pipeline.get_pipeline_metrics()\n",
        "            metrics_snapshot[\"pipelines\"][pipeline.name] = metrics\n",
        "\n",
        "        self.metrics_history.append(metrics_snapshot)\n",
        "\n",
        "        # Keep only last 100 snapshots\n",
        "        if len(self.metrics_history) > 100:\n",
        "            self.metrics_history.pop(0)\n",
        "\n",
        "    def generate_devops_report(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate comprehensive DevOps report\"\"\"\n",
        "        if not self.metrics_history:\n",
        "            return {}\n",
        "\n",
        "        latest_snapshot = self.metrics_history[-1]\n",
        "\n",
        "        report = {\n",
        "            \"report_time\": datetime.now().isoformat(),\n",
        "            \"summary\": {\n",
        "                \"total_pipelines\": len(self.pipelines),\n",
        "                \"monitoring_period_hours\": len(self.metrics_history),\n",
        "            },\n",
        "            \"pipeline_performance\": {},\n",
        "            \"trends\": self._calculate_trends(),\n",
        "        }\n",
        "\n",
        "        for pipeline_name, metrics in latest_snapshot[\"pipelines\"].items():\n",
        "            report[\"pipeline_performance\"][pipeline_name] = {\n",
        "                \"success_rate\": metrics.get(\"success_rate\", 0),\n",
        "                \"average_duration\": metrics.get(\"average_duration\", 0),\n",
        "                \"throughput\": metrics.get(\"total_builds\", 0) / max(len(self.metrics_history), 1),\n",
        "                \"reliability\": self._calculate_reliability_score(pipeline_name),\n",
        "            }\n",
        "\n",
        "        return report\n",
        "\n",
        "    def _calculate_trends(self) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate performance trends over time\"\"\"\n",
        "        if len(self.metrics_history) < 2:\n",
        "            return {}\n",
        "\n",
        "        first_snapshot = self.metrics_history[0]\n",
        "        last_snapshot = self.metrics_history[-1]\n",
        "\n",
        "        trends: Dict[str, Any] = {}\n",
        "        for pipeline_name in last_snapshot[\"pipelines\"]:\n",
        "            if pipeline_name in first_snapshot[\"pipelines\"]:\n",
        "                first_metrics = first_snapshot[\"pipelines\"][pipeline_name]\n",
        "                last_metrics = last_snapshot[\"pipelines\"][pipeline_name]\n",
        "\n",
        "                success_rate_change = (last_metrics.get(\"success_rate\", 0) - first_metrics.get(\"success_rate\", 0))\n",
        "                duration_change = (last_metrics.get(\"average_duration\", 0) - first_metrics.get(\"average_duration\", 0))\n",
        "\n",
        "                trends[pipeline_name] = {\n",
        "                    \"success_rate_trend\": \"improving\" if success_rate_change > 0 else \"declining\",\n",
        "                    \"success_rate_change\": success_rate_change,\n",
        "                    \"duration_trend\": \"faster\" if duration_change < 0 else \"slower\",\n",
        "                    \"duration_change\": abs(duration_change),\n",
        "                }\n",
        "        return trends\n",
        "\n",
        "    def _calculate_reliability_score(self, pipeline_name: str) -> float:\n",
        "        \"\"\"Calculate reliability score for a pipeline (0-100)\"\"\"\n",
        "        relevant_snapshots = [\n",
        "            snapshot for snapshot in self.metrics_history\n",
        "            if pipeline_name in snapshot[\"pipelines\"]\n",
        "        ]\n",
        "\n",
        "        if not relevant_snapshots:\n",
        "            return 0.0\n",
        "\n",
        "        success_rates = [\n",
        "            snapshot[\"pipelines\"][pipeline_name].get(\"success_rate\", 0)\n",
        "            for snapshot in relevant_snapshots\n",
        "        ]\n",
        "\n",
        "        avg_success_rate = sum(success_rates) / len(success_rates)\n",
        "\n",
        "        # Consider stability (consistency of success rates)\n",
        "        if len(success_rates) > 1:\n",
        "            stability = 1 - (statistics.stdev(success_rates) / 100)\n",
        "            reliability = avg_success_rate * stability\n",
        "        else:\n",
        "            reliability = avg_success_rate\n",
        "\n",
        "        return min(100, max(0, reliability))\n",
        "\n",
        "\n",
        "# Demonstration\n",
        "def simulate_ci_cd_workflow():\n",
        "    \"\"\"Simulate a complete CI/CD workflow\"\"\"\n",
        "    print(\"=== CI/CD Pipeline Simulation ===\")\n",
        "\n",
        "    # Create pipelines\n",
        "    main_pipeline = CICDPipeline(\"main-pipeline\")\n",
        "    feature_pipeline = CICDPipeline(\"feature-pipeline\")\n",
        "\n",
        "    # Enable auto-deploy for main pipeline\n",
        "    main_pipeline.auto_deploy_to_production = True\n",
        "\n",
        "    # Create monitor\n",
        "    monitor = DevOpsMonitor([main_pipeline, feature_pipeline])\n",
        "\n",
        "    # Simulate multiple builds\n",
        "    print(\"\\n=== Running Builds ===\")\n",
        "    for i in range(5):\n",
        "        print(f\"\\n--- Build Cycle {i + 1} ---\")\n",
        "        # Get code changes\n",
        "        changes = main_pipeline.vcs.get_latest_changes()\n",
        "\n",
        "        # Trigger builds\n",
        "        main_build = main_pipeline.trigger_build(changes)\n",
        "        feature_build = feature_pipeline.trigger_build(changes)\n",
        "\n",
        "        # Print build reports\n",
        "        main_pipeline.print_build_report(main_build)\n",
        "\n",
        "        # Collect metrics\n",
        "        monitor.collect_metrics()\n",
        "\n",
        "        # Wait between builds\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    # Generate DevOps report\n",
        "    print(\"\\n=== DevOps Metrics Report ===\")\n",
        "    devops_report = monitor.generate_devops_report()\n",
        "\n",
        "    print(f\"Monitoring Period: {devops_report['summary']['monitoring_period_hours']} snapshots\")\n",
        "    print(f\"Total Pipelines: {devops_report['summary']['total_pipelines']}\")\n",
        "\n",
        "    print(\"\\nPipeline Performance:\")\n",
        "    for pipeline_name, performance in devops_report[\"pipeline_performance\"].items():\n",
        "        print(f\"\\n{pipeline_name}:\")\n",
        "        print(f\"  Success Rate: {performance['success_rate']:.1f}%\")\n",
        "        print(f\"  Average Duration: {performance['average_duration']:.2f}s\")\n",
        "        print(f\"  Reliability Score: {performance['reliability']:.1f}/100\")\n",
        "\n",
        "    print(\"\\nTrends:\")\n",
        "    for pipeline_name, trend in devops_report[\"trends\"].items():\n",
        "        print(f\"\\n{pipeline_name}:\")\n",
        "        print(f\"  Success Rate: {trend['success_rate_trend']} ({trend['success_rate_change']:+.1f}%)\")\n",
        "        print(f\"  Duration: {trend['duration_trend']} ({trend['duration_change']:.2f}s change)\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    simulate_ci_cd_workflow()\n"
      ],
      "metadata": {
        "id": "zZxkOoRtEbt7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}