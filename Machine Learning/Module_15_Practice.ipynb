{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "14a5e2f5",
      "metadata": {
        "id": "14a5e2f5"
      },
      "source": [
        "# Module 15 – SVM Practice Notebook\n",
        "\n",
        "This practice notebook is focused only on **Support Vector Machine (SVM)** for classification.\n",
        "\n",
        "You will work with:\n",
        "- A synthetic **circles** dataset for non linear decision boundaries\n",
        "- A real world **wine classification** dataset (from `sklearn.datasets.load_wine`)\n",
        "\n",
        "Complete the `TODO` parts yourself to practice implementing SVM from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ba95230",
      "metadata": {
        "id": "9ba95230"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df1c5ec2",
      "metadata": {
        "id": "df1c5ec2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_circles, load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "np.random.seed(42)\n",
        "plt.rcParams['figure.figsize'] = (6, 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59fcb066",
      "metadata": {
        "id": "59fcb066"
      },
      "source": [
        "## 2. SVM on Circles Dataset with Different Kernels\n",
        "\n",
        "In this section you will:\n",
        "- Generate a **non linearly separable** dataset using `make_circles`\n",
        "- Train SVM with different kernels: `linear`, `poly`, and `rbf`\n",
        "- Compare how the decision boundary changes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d710f5d5",
      "metadata": {
        "id": "d710f5d5"
      },
      "outputs": [],
      "source": [
        "# 2.1 Generate circles dataset\n",
        "# TODO: use make_circles to generate a dataset with 500 samples\n",
        "# Hint: use noise around 0.2 and factor around 0.5\n",
        "\n",
        "# X_circ, y_circ = make_circles(...)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c840f35",
      "metadata": {
        "id": "6c840f35"
      },
      "outputs": [],
      "source": [
        "# 2.2 Visualise the raw circles dataset\n",
        "# TODO: create a scatter plot of the circles dataset\n",
        "# Hint: use plt.scatter with c=y_circ and cmap='bwr'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12f7b06",
      "metadata": {
        "id": "b12f7b06"
      },
      "outputs": [],
      "source": [
        "# 2.3 Train test split and scaling\n",
        "# TODO: split the data into train and test sets\n",
        "# Then scale the features using StandardScaler\n",
        "\n",
        "# Xc_train, Xc_test, yc_train, yc_test = train_test_split(...)\n",
        "# scaler_circ = StandardScaler()\n",
        "# Xc_train_scaled = scaler_circ.fit_transform(Xc_train)\n",
        "# Xc_test_scaled = scaler_circ.transform(Xc_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd0c87d",
      "metadata": {
        "id": "3cd0c87d"
      },
      "outputs": [],
      "source": [
        "# Helper function to plot decision boundary for 2D data\n",
        "def plot_decision_boundary(model, X, y, title='Decision boundary'):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(\n",
        "        np.linspace(x_min, x_max, 300),\n",
        "        np.linspace(y_min, y_max, 300)\n",
        "    )\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    Z = model.predict(grid)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.contourf(xx, yy, Z, alpha=0.25, cmap='bwr')\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolors='k', alpha=0.8)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf1ffa7",
      "metadata": {
        "id": "dbf1ffa7"
      },
      "outputs": [],
      "source": [
        "# 2.4 Train linear, polynomial, and RBF SVM on circles data\n",
        "# TODO: create three SVC models with kernels 'linear', 'poly', and 'rbf'\n",
        "# Train each on Xc_train_scaled and yc_train\n",
        "# Then evaluate accuracy on Xc_test_scaled and yc_test\n",
        "# Finally, call plot_decision_boundary for each model on the TRAIN set\n",
        "\n",
        "# Example structure (fill in):\n",
        "# svc_lin = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "# svc_lin.fit(Xc_train_scaled, yc_train)\n",
        "# y_pred_lin = svc_lin.predict(Xc_test_scaled)\n",
        "# print('Linear kernel accuracy:', accuracy_score(yc_test, y_pred_lin))\n",
        "# plot_decision_boundary(svc_lin, Xc_train_scaled, yc_train, 'Linear kernel on circles')\n",
        "\n",
        "# Repeat similarly for polynomial and RBF kernels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4049db4a",
      "metadata": {
        "id": "4049db4a"
      },
      "source": [
        "### Reflection\n",
        "- কোন kernel circles ডেটাতে সবচেয়ে ভালো কাজ করল?\n",
        "- linear kernel কেন এই ডেটাতে struggle করে?\n",
        "- polynomial আর RBF kernel এর boundary shape কেমন পরিবর্তন হয়, বোঝার চেষ্টা করুন।"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8334ea21",
      "metadata": {
        "id": "8334ea21"
      },
      "source": [
        "## 3. SVM on Real Data: Wine Classification\n",
        "\n",
        "এখানে আমরা `sklearn.datasets.load_wine` ব্যবহার করব।\n",
        "- এটি একটি **multi class classification** সমস্যা।\n",
        "- প্রতিটি sample একটি wine, আর target হলো wine এর class (৩ ধরনের)।\n",
        "\n",
        "উদ্দেশ্য:\n",
        "- ডেটা explore করা\n",
        "- SVM train করা\n",
        "- Accuracy এবং classification report দেখা\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9af6c4d",
      "metadata": {
        "id": "c9af6c4d"
      },
      "outputs": [],
      "source": [
        "# 3.1 Load the wine dataset (Done for you)\n",
        "wine = load_wine()\n",
        "X_wine = wine.data\n",
        "y_wine = wine.target\n",
        "\n",
        "print('Shape of X:', X_wine.shape)\n",
        "print('Classes:', np.unique(y_wine))\n",
        "print('Feature names:', wine.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11f344a",
      "metadata": {
        "id": "c11f344a"
      },
      "outputs": [],
      "source": [
        "# 3.2 Train test split and scaling\n",
        "# TODO: split X_wine, y_wine into train and test sets\n",
        "# Use test_size around 0.2 and random_state=42\n",
        "\n",
        "# Then apply StandardScaler on the features\n",
        "\n",
        "# Xw_train, Xw_test, yw_train, yw_test = train_test_split(...)\n",
        "# scaler_wine = StandardScaler()\n",
        "# Xw_train_scaled = scaler_wine.fit_transform(Xw_train)\n",
        "# Xw_test_scaled = scaler_wine.transform(Xw_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e43cd74",
      "metadata": {
        "id": "5e43cd74"
      },
      "outputs": [],
      "source": [
        "# 3.3 Train an SVM classifier with RBF kernel\n",
        "# TODO: create an SVC with kernel='rbf', C=1.0, gamma='scale'\n",
        "# Train it on the scaled training data\n",
        "# Then predict on the test set and compute accuracy\n",
        "\n",
        "# svc_wine = SVC(...)\n",
        "# svc_wine.fit(Xw_train_scaled, yw_train)\n",
        "# yw_pred = svc_wine.predict(Xw_test_scaled)\n",
        "# acc_wine = accuracy_score(yw_test, yw_pred)\n",
        "# print(f'Test accuracy (wine, RBF SVM): {acc_wine:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a2f5f4",
      "metadata": {
        "id": "b5a2f5f4"
      },
      "outputs": [],
      "source": [
        "# 3.4 Classification report and confusion matrix\n",
        "# TODO: print classification_report and confusion_matrix for the wine dataset\n",
        "\n",
        "# print(classification_report(yw_test, yw_pred))\n",
        "# print(confusion_matrix(yw_test, yw_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56003267",
      "metadata": {
        "id": "56003267"
      },
      "source": [
        "### Optional Extension\n",
        "- C এবং gamma এর ভ্যালু পরিবর্তন করে দেখুন accuracy কিভাবে বদলায়।\n",
        "- বিভিন্ন kernel (linear, poly, rbf) ব্যবহার করে performance compare করুন।"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2100be7a",
      "metadata": {
        "id": "2100be7a"
      },
      "source": [
        "## 4. Mini Hyperparameter Experiment (Wine Data)\n",
        "\n",
        "এখন wine ডেটার জন্য ছোট একটা grid search টাইপ experiment করবেন।\n",
        "- কয়েকটা C এর ভ্যালু\n",
        "- কয়েকটা gamma এর ভ্যালু\n",
        "- সব combination এর জন্য accuracy বের করুন।\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2378d56",
      "metadata": {
        "id": "f2378d56"
      },
      "outputs": [],
      "source": [
        "# 4.1 Manual loop over C and gamma\n",
        "# TODO: create small lists for C_values and gamma_values\n",
        "# For example: C_values = [0.1, 1, 10]\n",
        "# and gamma_values = [0.01, 0.1, 'scale']\n",
        "\n",
        "# For each pair (C, gamma), train an RBF SVM on the wine data\n",
        "# Store the test accuracy in a list of dictionaries\n",
        "# Finally, convert it to a DataFrame and sort by accuracy\n",
        "\n",
        "# C_values = [...]\n",
        "# gamma_values = [...]\n",
        "# results = []\n",
        "# for C in C_values:\n",
        "#     for gamma in gamma_values:\n",
        "#         model = SVC(kernel='rbf', C=C, gamma=gamma, random_state=42)\n",
        "#         model.fit(Xw_train_scaled, yw_train)\n",
        "#         y_pred = model.predict(Xw_test_scaled)\n",
        "#         acc = accuracy_score(yw_test, y_pred)\n",
        "#         results.append({'C': C, 'gamma': gamma, 'accuracy': acc})\n",
        "\n",
        "# df_results = pd.DataFrame(results)\n",
        "# df_results.sort_values('accuracy', ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f3d28b",
      "metadata": {
        "id": "68f3d28b"
      },
      "source": [
        "### Reflection\n",
        "- কোন C এবং gamma combination সবচেয়ে ভালো কাজ করল?\n",
        "- খুব বেশি বড় C বা খুব বেশি বড় gamma দিলে কি overfitting মনে হচ্ছে?\n",
        "- wine ডেটা কি linear SVM এর জন্য যথেষ্ট সহজ, নাকি RBF noticeably ভালো কাজ করছে?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c867afa5",
      "metadata": {
        "id": "c867afa5"
      },
      "source": [
        "## 5. Summary\n",
        "\n",
        "এই practice notebook এ আপনি:\n",
        "- circles ডেটাতে বিভিন্ন kernel এর effect দেখেছেন।\n",
        "- wine ডেটাতে SVM train করে multi class classification করেছেন।\n",
        "- hyperparameter C এবং gamma এর impact বুঝেছেন।\n",
        "\n",
        "এগুলো clear হলে SVM নিয়ে আপনার হাতে কলমে practice ভালোই হয়ে যাবে।\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}