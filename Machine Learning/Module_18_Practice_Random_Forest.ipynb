{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1d94e7de",
      "metadata": {
        "id": "1d94e7de"
      },
      "source": [
        "\n",
        "# Module 18 Practice Notebook\n",
        "\n",
        "**Dataset used here:** `sklearn.datasets.load_wine()`\n",
        "\n",
        "### What you will practice\n",
        "- Train/test split with stratification\n",
        "- Baseline Random Forest training\n",
        "- Evaluation (accuracy, classification report, confusion matrix)\n",
        "- Feature importance\n",
        "- Hyperparameter tuning with GridSearchCV\n",
        "- Comparing baseline vs tuned model\n",
        "- Regression Implementation and it's Analysis\n",
        "\n",
        "> **Rule for this notebook:** Every section has TODO tasks. Fill them in and run.\n",
        "\n",
        "This notebook has two parts:\n",
        "- **Part A:** Classification (Breast Cancer)\n",
        "- **Part B:** Regression (California Housing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part A: Random Forest for Classification"
      ],
      "metadata": {
        "id": "j1MPmcl23t0U"
      },
      "id": "j1MPmcl23t0U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "674cc371",
      "metadata": {
        "id": "674cc371"
      },
      "outputs": [],
      "source": [
        "# TODO: Run this cell first (imports)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "167ad6ff",
      "metadata": {
        "id": "167ad6ff"
      },
      "source": [
        "\n",
        "### 1) Load the dataset (Wine dataset)\n",
        "\n",
        "The Wine dataset is a **multiclass classification** problem:\n",
        "- 3 classes (wine cultivars)\n",
        "- 13 numeric features\n",
        "\n",
        "Your job:\n",
        "- Load the dataset\n",
        "- Create a DataFrame for features `X`\n",
        "- Create a Series for target `y`\n",
        "- Print shapes and class distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05b6a8c8",
      "metadata": {
        "id": "05b6a8c8"
      },
      "outputs": [],
      "source": [
        "# TODO: Load the wine dataset\n",
        "# Hint: data = load_wine()\n",
        "\n",
        "data = None  # TODO\n",
        "# TODO: Create X and y\n",
        "X = None  # TODO (DataFrame)\n",
        "y = None  # TODO (Series)\n",
        "\n",
        "# TODO: Print shapes\n",
        "# print(\"X shape:\", ...)\n",
        "# print(\"y shape:\", ...)\n",
        "\n",
        "# TODO: Show class distribution\n",
        "# print(y.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5374f523",
      "metadata": {
        "id": "5374f523"
      },
      "source": [
        "\n",
        "### 2) Train-test split\n",
        "\n",
        "Requirements:\n",
        "- test_size = 0.25\n",
        "- random_state = 42\n",
        "- stratify by y (important for class balance)\n",
        "\n",
        "Your job:\n",
        "- Create X_train, X_test, y_train, y_test\n",
        "- Print the train/test sizes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ead780",
      "metadata": {
        "id": "d9ead780"
      },
      "outputs": [],
      "source": [
        "# TODO: Split the dataset\n",
        "X_train, X_test, y_train, y_test = None, None, None, None  # TODO\n",
        "\n",
        "# TODO: Print sizes\n",
        "# print(\"Train:\", X_train.shape, y_train.shape)\n",
        "# print(\"Test :\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ebc5882",
      "metadata": {
        "id": "1ebc5882"
      },
      "source": [
        "\n",
        "### 3) Baseline Random Forest model\n",
        "\n",
        "Requirements:\n",
        "- Use RandomForestClassifier\n",
        "- n_estimators = 200 (slightly larger than default)\n",
        "- random_state = 42\n",
        "\n",
        "Your job:\n",
        "- Initialize the model\n",
        "- Fit on training data\n",
        "- Predict on test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085b27b6",
      "metadata": {
        "id": "085b27b6"
      },
      "outputs": [],
      "source": [
        "# TODO: Baseline model\n",
        "rf_baseline = None  # TODO\n",
        "\n",
        "# TODO: Fit\n",
        "# rf_baseline.fit(X_train, y_train)\n",
        "\n",
        "# TODO: Predict\n",
        "y_pred_baseline = None  # TODO\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc0b424",
      "metadata": {
        "id": "9dc0b424"
      },
      "source": [
        "\n",
        "### 4) Evaluate baseline model\n",
        "\n",
        "Your job:\n",
        "1. Compute accuracy\n",
        "2. Print classification report\n",
        "3. Build confusion matrix\n",
        "4. Plot confusion matrix using matplotlib (no seaborn)\n",
        "\n",
        "Note:\n",
        "- This is multiclass, so confusion matrix is 3x3.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195b1ec3",
      "metadata": {
        "id": "195b1ec3"
      },
      "outputs": [],
      "source": [
        "# TODO: Accuracy\n",
        "# acc = accuracy_score(y_test, y_pred_baseline)\n",
        "# print(\"Baseline accuracy:\", acc)\n",
        "\n",
        "# TODO: Classification report\n",
        "# print(classification_report(y_test, y_pred_baseline, target_names=data.target_names))\n",
        "\n",
        "# TODO: Confusion matrix\n",
        "cm = None  # TODO\n",
        "\n",
        "# TODO: Plot confusion matrix (matplotlib)\n",
        "# plt.figure(figsize=(5,4))\n",
        "# plt.imshow(cm, interpolation=\"nearest\")\n",
        "# plt.title(\"Confusion Matrix (Baseline)\")\n",
        "# plt.colorbar()\n",
        "# tick_marks = np.arange(len(data.target_names))\n",
        "# plt.xticks(tick_marks, data.target_names, rotation=45, ha=\"right\")\n",
        "# plt.yticks(tick_marks, data.target_names)\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"Actual\")\n",
        "# for i in range(cm.shape[0]):\n",
        "#     for j in range(cm.shape[1]):\n",
        "#         plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403ecbcd",
      "metadata": {
        "id": "403ecbcd"
      },
      "source": [
        "\n",
        "### 5) Feature importance (baseline)\n",
        "\n",
        "Your job:\n",
        "1. Extract `feature_importances_`\n",
        "2. Create a DataFrame of feature names and importances\n",
        "3. Sort and show top 5 features\n",
        "4. Plot top 5 importances using matplotlib\n",
        "\n",
        "Reminder:\n",
        "- Feature importance is **global**, not per individual prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0074f61a",
      "metadata": {
        "id": "0074f61a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO: Extract feature importances\n",
        "importances = None  # TODO\n",
        "\n",
        "# TODO: Build a sorted DataFrame\n",
        "feat_imp = None  # TODO DataFrame with columns: feature, importance\n",
        "\n",
        "# TODO: Print top 5\n",
        "# display(feat_imp.head(5))\n",
        "\n",
        "# TODO: Plot top 5\n",
        "# plt.figure(figsize=(8,4))\n",
        "# plt.bar(feat_imp[\"feature\"].head(5), feat_imp[\"importance\"].head(5))\n",
        "# plt.xticks(rotation=45, ha=\"right\")\n",
        "# plt.title(\"Top 5 Feature Importances (Baseline)\")\n",
        "# plt.ylabel(\"Importance\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c338f15",
      "metadata": {
        "id": "0c338f15"
      },
      "source": [
        "\n",
        "### 6) Hyperparameter tuning with GridSearchCV\n",
        "\n",
        "Tune these parameters:\n",
        "- n_estimators\n",
        "- max_depth\n",
        "- min_samples_split\n",
        "- max_features\n",
        "\n",
        "Requirements:\n",
        "- cv = 5\n",
        "- scoring = \"accuracy\"\n",
        "- n_jobs = -1\n",
        "- random_state = 42 in the estimator\n",
        "\n",
        "Your job:\n",
        "1. Define param_grid\n",
        "2. Run GridSearchCV\n",
        "3. Print best_params_\n",
        "4. Create best model and predict on test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12c3c37",
      "metadata": {
        "id": "b12c3c37"
      },
      "outputs": [],
      "source": [
        "# TODO: Define param grid\n",
        "param_grid = {\n",
        "    # \"n_estimators\": [...],\n",
        "    # \"max_depth\": [...],\n",
        "    # \"min_samples_split\": [...],\n",
        "    # \"max_features\": [...]\n",
        "}\n",
        "\n",
        "# TODO: Create GridSearchCV\n",
        "grid = None  # TODO\n",
        "\n",
        "# TODO: Fit grid search\n",
        "# grid.fit(X_train, y_train)\n",
        "\n",
        "# TODO: Print best params\n",
        "# print(\"Best params:\", grid.best_params_)\n",
        "\n",
        "# TODO: Best estimator and prediction\n",
        "best_rf = None  # TODO\n",
        "y_pred_tuned = None  # TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5249a08c",
      "metadata": {
        "id": "5249a08c"
      },
      "source": [
        "\n",
        "### 7) Evaluate tuned model and compare with baseline\n",
        "\n",
        "Your job:\n",
        "1. Compute tuned accuracy\n",
        "2. Print tuned classification report\n",
        "3. Compare baseline vs tuned accuracy in one print block\n",
        "4. (Optional) Plot tuned confusion matrix like before\n",
        "\n",
        "Write a 2-3 line conclusion:\n",
        "- Did tuning help?\n",
        "- If not, why might that happen?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8847c42a",
      "metadata": {
        "id": "8847c42a"
      },
      "outputs": [],
      "source": [
        "# TODO: Tuned accuracy\n",
        "# acc_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "# print(\"Tuned accuracy:\", acc_tuned)\n",
        "\n",
        "# TODO: Report\n",
        "# print(classification_report(y_test, y_pred_tuned, target_names=data.target_names))\n",
        "\n",
        "# TODO: Compare\n",
        "# baseline_acc = accuracy_score(y_test, y_pred_baseline)\n",
        "# print(f\"Baseline accuracy: {baseline_acc:.4f}\")\n",
        "# print(f\"Tuned accuracy   : {acc_tuned:.4f}\")\n",
        "\n",
        "# TODO: Short written conclusion (as a print or markdown)\n",
        "# print(\"Conclusion: ...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c58748",
      "metadata": {
        "id": "c6c58748"
      },
      "source": [
        "\n",
        "### 8) Challenge Tasks (Optional but recommended)\n",
        "\n",
        "**Challenge A:** Change `random_state` and rerun. Does the accuracy change a lot? Why?  \n",
        "**Challenge B:** Increase `n_estimators` to 500. Does it improve? What happens to runtime?  \n",
        "**Challenge C:** Try `class_weight=\"balanced\"` and compare results (even if classes are not extremely imbalanced).\n",
        "\n",
        "Write your observations briefly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part B: Random Forest for Regression\n",
        "\n",
        "In regression, the target is **continuous numeric**, not class labels.\n",
        "\n",
        "You will use **California Housing** dataset:\n",
        "- Features: information about California districts (e.g., median income, house age, rooms, etc.)\n",
        "- Target: median house value (a numeric value)\n",
        "\n",
        "### Your goals for regression part\n",
        "\n",
        "- Load a regression dataset (X_reg, y_reg)\n",
        "- Split train and test sets\n",
        "- Train a RandomForestRegressor\n",
        "- Evaluate using regression metrics:\n",
        "  - **MAE** (Mean Absolute Error)\n",
        "  - **MSE** (Mean Squared Error)\n",
        "  - **RMSE** (Root Mean Squared Error)\n",
        "  - **R-squared** (coefficient of determination)\n",
        "- Do a simple residual analysis\n"
      ],
      "metadata": {
        "id": "i0HOzkcL4E8S"
      },
      "id": "i0HOzkcL4E8S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step B1: Imports for Regression\n",
        "\n",
        "You will need these extra imports:\n",
        "- fetch_california_housing\n",
        "- RandomForestRegressor\n",
        "- mean_absolute_error, mean_squared_error, r2_score\n"
      ],
      "metadata": {
        "id": "rbcO2isU4d9S"
      },
      "id": "rbcO2isU4d9S"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B1): Import regression-specific tools\n",
        "# from sklearn.datasets import fetch_california_housing\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "uRHarSBO4gvN"
      },
      "id": "uRHarSBO4gvN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B2: Load the California Housing Dataset\n",
        "\n",
        "Tasks:\n",
        "1. Load the dataset using fetch_california_housing()\n",
        "2. Convert feature matrix into a pandas DataFrame\n",
        "3. Convert target into a pandas Series\n",
        "4. Print shapes to confirm:\n",
        "   - X_reg shape should be (n_samples, n_features)\n",
        "   - y_reg shape should be (n_samples,)\n"
      ],
      "metadata": {
        "id": "hborBI9N4lEO"
      },
      "id": "hborBI9N4lEO"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B2): Load California Housing dataset\n",
        "# data_reg = fetch_california_housing()\n",
        "\n",
        "# TODO: Create X_reg DataFrame and y_reg Series\n",
        "# Hint: data_reg.data, data_reg.feature_names, data_reg.target\n",
        "\n",
        "# TODO: Print shapes\n",
        "# print(X_reg.shape)\n",
        "# print(y_reg.shape)"
      ],
      "metadata": {
        "id": "FMjgdqg94miZ"
      },
      "id": "FMjgdqg94miZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B3: Quick Data Check (Very Important)\n",
        "\n",
        "Before modeling, always inspect:\n",
        "- First few rows\n",
        "- Summary statistics\n",
        "- Missing values\n",
        "\n",
        "Random Forest can handle non-linear patterns, but it cannot handle missing values magically.\n"
      ],
      "metadata": {
        "id": "fnzGPeKn4rz2"
      },
      "id": "fnzGPeKn4rz2"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B3): Basic inspection\n",
        "# 1) X_reg.head()\n",
        "# 2) X_reg.describe()\n",
        "# 3) X_reg.isna().sum().sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "id": "2Cy0Jgji4vdw"
      },
      "id": "2Cy0Jgji4vdw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B4: Train-test Split for Regression\n",
        "\n",
        "Use the same split style:\n",
        "- test_size = 0.25\n",
        "- random_state = 42\n",
        "\n",
        "In regression, we typically do NOT use stratify.\n"
      ],
      "metadata": {
        "id": "2ebS_b3x4zaP"
      },
      "id": "2ebS_b3x4zaP"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B4): Split X_reg and y_reg\n",
        "# X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(...)"
      ],
      "metadata": {
        "id": "MP7pg9TS40-K"
      },
      "id": "MP7pg9TS40-K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B5: Train a Baseline RandomForestRegressor\n",
        "\n",
        "Start with a baseline model first. Use reasonable defaults.\n",
        "\n",
        "Recommended baseline settings:\n",
        "- n_estimators = 300  (more trees = smoother prediction, but slower)\n",
        "- random_state = 42\n",
        "- n_jobs = -1 (use all CPU cores if available)\n",
        "\n",
        "Note: We are not tuning yet. This is the baseline.\n"
      ],
      "metadata": {
        "id": "pfuL99by46zZ"
      },
      "id": "pfuL99by46zZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B5): Initialize and train RandomForestRegressor\n",
        "# rf_reg = RandomForestRegressor(\n",
        "#     n_estimators=300,\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "# rf_reg.fit(X_train_reg, y_train_reg)\n"
      ],
      "metadata": {
        "id": "l0szhcF_48Ep"
      },
      "id": "l0szhcF_48Ep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B6: Make Predictions\n",
        "\n",
        "After fitting, predict on the test set and store predictions in y_pred_reg.\n"
      ],
      "metadata": {
        "id": "raQCX00B5AJU"
      },
      "id": "raQCX00B5AJU"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B6): Predict using the trained regressor\n",
        "# y_pred_reg = rf_reg.predict(X_test_reg)"
      ],
      "metadata": {
        "id": "SLdyfYEf5C-1"
      },
      "id": "SLdyfYEf5C-1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B7: Evaluate Regression Performance (Step-by-step)\n",
        "\n",
        "We will compute:\n",
        "\n",
        "1) **MAE**: average absolute error  \n",
        "   - Easy to interpret (same units as target)\n",
        "\n",
        "2) **MSE**: average squared error  \n",
        "   - Penalizes large errors more\n",
        "\n",
        "3) **RMSE**: square root of MSE  \n",
        "   - Same unit as target, but still penalizes large errors\n",
        "\n",
        "4) **R-squared**: fraction of variance explained  \n",
        "   - 1.0 is perfect\n",
        "   - 0.0 means “no better than predicting the mean”\n",
        "   - can be negative if the model is very poor\n",
        "\n",
        "Print all four clearly.\n"
      ],
      "metadata": {
        "id": "_vYpC1te5G43"
      },
      "id": "_vYpC1te5G43"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B7): Compute metrics\n",
        "# mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "# mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "# rmse = np.sqrt(mse)\n",
        "# r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "# TODO: Print metrics nicely\n",
        "# print(\"MAE:\", mae)\n",
        "# print(\"MSE:\", mse)\n",
        "# print(\"RMSE:\", rmse)\n",
        "# print(\"R2:\", r2)"
      ],
      "metadata": {
        "id": "ZrNbcCM55Is_"
      },
      "id": "ZrNbcCM55Is_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B8: Visual Check (Predicted vs Actual)\n",
        "\n",
        "A quick sanity plot:\n",
        "- x-axis: actual values (y_test_reg)\n",
        "- y-axis: predicted values (y_pred_reg)\n",
        "\n",
        "If the model is strong, points should roughly follow the diagonal line.\n"
      ],
      "metadata": {
        "id": "mNe4izAY5Nf2"
      },
      "id": "mNe4izAY5Nf2"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B8): Scatter plot: Actual vs Predicted\n",
        "# plt.figure(figsize=(6,6))\n",
        "# plt.scatter(y_test_reg, y_pred_reg, alpha=0.4)\n",
        "# plt.xlabel(\"Actual\")\n",
        "# plt.ylabel(\"Predicted\")\n",
        "# plt.title(\"Random Forest Regression: Actual vs Predicted\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "yVJO9SlK5O5h"
      },
      "id": "yVJO9SlK5O5h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B9: Residual Analysis\n",
        "\n",
        "Residual = Actual - Predicted\n",
        "\n",
        "A good model should have residuals centered around 0 with no obvious pattern.\n"
      ],
      "metadata": {
        "id": "2PqAQK7A5S-F"
      },
      "id": "2PqAQK7A5S-F"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B9): Residual plot\n",
        "# residuals = y_test_reg - y_pred_reg\n",
        "# plt.figure(figsize=(7,4))\n",
        "# plt.scatter(y_pred_reg, residuals, alpha=0.4)\n",
        "# plt.axhline(0)\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"Residual (Actual - Predicted)\")\n",
        "# plt.title(\"Residual Plot\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "qbiNr3Qb5W_M"
      },
      "id": "qbiNr3Qb5W_M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step B10: One Mini Experiment\n",
        "\n",
        "Change ONE hyperparameter and observe the effect.\n",
        "\n",
        "Choose one:\n",
        "- max_depth\n",
        "- min_samples_split\n",
        "- max_features\n",
        "\n",
        "Task:\n",
        "1. Train a second model with your chosen change\n",
        "2. Compute MAE, RMSE, and R2 again\n",
        "3. Compare with baseline\n",
        "\n",
        "Keep everything else identical.\n"
      ],
      "metadata": {
        "id": "7XLg8PJU5cGe"
      },
      "id": "7XLg8PJU5cGe"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (B10): Mini experiment\n",
        "# Example:\n",
        "# rf_reg2 = RandomForestRegressor(\n",
        "#     n_estimators=300,\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1,\n",
        "#     max_depth=10\n",
        "# )\n",
        "# rf_reg2.fit(X_train_reg, y_train_reg)\n",
        "# y_pred_reg2 = rf_reg2.predict(X_test_reg)\n",
        "\n",
        "# TODO: Compute and print MAE/RMSE/R2 for rf_reg2"
      ],
      "metadata": {
        "id": "YxdF5Ht55ekY"
      },
      "id": "YxdF5Ht55ekY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Reflection (Write answers, no coding)\n",
        "\n",
        "1) In regression, why do we use MAE/RMSE instead of accuracy?  \n",
        "2) What does R-squared mean in simple language?  \n",
        "3) Which parameter seems most related to overfitting: max_depth or n_estimators? Why?  \n",
        "4) If your RMSE is high, list two possible reasons."
      ],
      "metadata": {
        "id": "rOOI6Tlm5iij"
      },
      "id": "rOOI6Tlm5iij"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}