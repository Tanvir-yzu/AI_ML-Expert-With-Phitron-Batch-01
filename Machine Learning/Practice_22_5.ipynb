{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJnz0uuk73KJ"
   },
   "source": [
    "## Run below code cell to load dataset to colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RMXTSHB97_fB"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxY0NW2F8QvZ"
   },
   "source": [
    "## Task 1.1\n",
    "### Train an AdaBoostClassifier with n_estimators=1 (just one tree).\n",
    "\n",
    "## Task 1.2\n",
    "### Train an AdaBoostClassifier with n_estimators=50 (multiple trees).\n",
    "\n",
    "## Task 1.3\n",
    "### Compare both of them , which one is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6WqCxCff8qjy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost (1 estimator) Test Accuracy: 0.8947\n",
      "AdaBoost (50 estimators) Test Accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost with n_estimators=1 (essentially a single weak learner - decision stump by default)\n",
    "ada_single = AdaBoostClassifier(n_estimators=1, random_state=42)\n",
    "ada_single.fit(X_train, y_train)\n",
    "y_pred_single = ada_single.predict(X_test)\n",
    "acc_single = accuracy_score(y_test, y_pred_single)\n",
    "print(f\"AdaBoost (1 estimator) Test Accuracy: {acc_single:.4f}\")\n",
    "\n",
    "# AdaBoost with n_estimators=50\n",
    "ada_multi = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "ada_multi.fit(X_train, y_train)\n",
    "y_pred_multi = ada_multi.predict(X_test)\n",
    "acc_multi = accuracy_score(y_test, y_pred_multi)\n",
    "print(f\"AdaBoost (50 estimators) Test Accuracy: {acc_multi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iL0cw9NW9Drx"
   },
   "source": [
    "## Task 2.1\n",
    "### Train a model with Gradient Boost with both low and high learning rate.\n",
    "\n",
    "## Task 2.2\n",
    "### Compare  \"Fast Learner\" (high learning rate) vs. a \"Slow Learner\" (low learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SUX7oZFn9aEZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Fast Learner (lr=1.0) Test Accuracy: 0.9649\n",
      "GB Slow Learner (lr=0.01) Test Accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# \"Fast Learner\" - high learning rate\n",
    "gb_fast = GradientBoostingClassifier(learning_rate=1.0, n_estimators=100, random_state=42)\n",
    "gb_fast.fit(X_train, y_train)\n",
    "y_pred_fast = gb_fast.predict(X_test)\n",
    "acc_fast = accuracy_score(y_test, y_pred_fast)\n",
    "print(f\"GB Fast Learner (lr=1.0) Test Accuracy: {acc_fast:.4f}\")\n",
    "\n",
    "# \"Slow Learner\" - low learning rate\n",
    "gb_slow = GradientBoostingClassifier(learning_rate=0.01, n_estimators=100, random_state=42)\n",
    "gb_slow.fit(X_train, y_train)\n",
    "y_pred_slow = gb_slow.predict(X_test)\n",
    "acc_slow = accuracy_score(y_test, y_pred_slow)\n",
    "print(f\"GB Slow Learner (lr=0.01) Test Accuracy: {acc_slow:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7ZKe4YO-Hz5"
   },
   "source": [
    "## Task 3.2\n",
    "### Train a model with XGBoost with both shallow and deep tree\n",
    "\n",
    "## Task 3.2\n",
    "### Compare a \"Shallow\" tree (depth=2) vs. a \"Deep\" tree (depth=15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nMoYaI9V-TLa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Shallow (depth=2) Test Accuracy: 0.9649\n",
      "XGBoost Deep (depth=15) Test Accuracy: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:51:45] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:51:45] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Shallow trees\n",
    "xgb_shallow = xgb.XGBClassifier(max_depth=2, n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_shallow.fit(X_train, y_train)\n",
    "y_pred_shallow = xgb_shallow.predict(X_test)\n",
    "acc_shallow = accuracy_score(y_test, y_pred_shallow)\n",
    "print(f\"XGBoost Shallow (depth=2) Test Accuracy: {acc_shallow:.4f}\")\n",
    "\n",
    "# Deep trees\n",
    "xgb_deep = xgb.XGBClassifier(max_depth=15, n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_deep.fit(X_train, y_train)\n",
    "y_pred_deep = xgb_deep.predict(X_test)\n",
    "acc_deep = accuracy_score(y_test, y_pred_deep)\n",
    "print(f\"XGBoost Deep (depth=15) Test Accuracy: {acc_deep:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
